{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNyTgwwaZzNZYzcTCfq2epu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElahehJafarigol/Federated-Learning-GANs/blob/main/SMOTE_based_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Deep Imbalanced Learning for Weather Data: A Federated Learning Approach**"
      ],
      "metadata": {
        "id": "1e58c1bIO21P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The high-level algorithm for the Conditional Generative Adversarial Network (CGAN) is as follows:**\n",
        "\n",
        "1. Load and preprocess the dataset\n",
        "2. Define the generator and discriminator models\n",
        "3. Define the CGAN model by combining the generator and discriminator models\n",
        "4. Train the discriminator by feeding it real and generated data while adjusting its weights to improve classification accuracy\n",
        "5. Train the generator by generating synthetic data and feeding it into the discriminator while adjusting its weights to maximize the probability of the generated data being classified as real\n",
        "6. Repeat steps 4 and 5 for a fixed number of epochs\n",
        "7. Save the trained generator model\n",
        "8. Use the generator to generate synthetic data\n",
        "9. Combine the synthetic data with the real data to create a balanced dataset\n",
        "10. Train a classification model on the balanced dataset to evaluate its performance."
      ],
      "metadata": {
        "id": "KREZz3l-yfkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet keras==2.9.0\n",
        "!pip install --quiet tensorflow==2.9.2"
      ],
      "metadata": {
        "id": "2q1py7JjP3ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet imbalanced-learn"
      ],
      "metadata": {
        "id": "obQ8Fi137uwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from  IPython import display\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "import warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "warnings.filterwarnings('ignore')\n",
        "from pandas.core.common import random_state\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn import preprocessing\n",
        "\n",
        "random_state = 42\n",
        "random_seed = 42\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import datasets, layers, models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras import backend as K\n",
        "from keras import datasets, layers, models, metrics\n",
        "from keras.layers import GaussianNoise\n",
        "from keras import regularizers\n",
        "\n",
        "from keras.layers.serialization import activation\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.activation import ReLU\n",
        "from pandas.core.indexes.datetimes import Resolution\n",
        "from keras.layers import Concatenate\n",
        "\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.activation import ReLU\n",
        "from pandas.core.indexes.datetimes import Resolution"
      ],
      "metadata": {
        "id": "oLj8mMEvPO4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Multiple Datasets**"
      ],
      "metadata": {
        "id": "vxEp9vzG8w6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load and preprocess the data"
      ],
      "metadata": {
        "id": "Ugg0q56f8yu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrvpniNfI8l-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ea0a9858-2b9d-4ec1-9665-0ea0cb6e50a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a2ac585-29c6-4bbd-91ef-884e719816c0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a2ac585-29c6-4bbd-91ef-884e719816c0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WeatherAUS.csv to WeatherAUS.csv\n",
            "User uploaded file \"WeatherAUS.csv\" with length 14159645 bytes\n"
          ]
        }
      ],
      "source": [
        "# Uploading the data in Google colab\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. It imports the weather dataset as a pandas dataframe and preprocesses it. It drops columns that are not useful for the model and replaces the binary labels \"RainToday\" and \"RainTomorrow\" with 1 for \"Yes\" and 0 for \"No.\" It also fills in missing data with the mean of the respective feature.\n",
        "\n",
        "2. It separates the features and the labels into X and y, respectively, and normalizes the features using MinMaxScaler."
      ],
      "metadata": {
        "id": "_XHmvqFnxQwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data file as a dataframe\n",
        "import io\n",
        "weather_df = pd.read_csv(io.BytesIO(uploaded['WeatherAUS.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "weather_df.shape\n",
        "\n",
        "Data = weather_df\n",
        "Data.RainToday = [1 if each==\"Yes\" else 0 for each in Data.RainToday]\n",
        "Data.RainTomorrow = [1 if each==\"Yes\" else 0 for each in Data.RainTomorrow]\n",
        "#Data.head()\n",
        "\n",
        "Data = Data.drop(['Sunshine','Evaporation','Cloud3pm','Cloud9am','RISK_MM','Location','Date','WindGustDir',\n",
        "       'WindDir9am', 'WindDir3pm'],axis=1)\n",
        "Data.shape\n",
        "\n",
        "# replace rest of the nulls with respective means\n",
        "fill_feat = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed','WindSpeed9am', 'WindSpeed3pm',\n",
        "             'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm','Temp9am', 'Temp3pm',\n",
        "             'RainToday', 'RainTomorrow']\n",
        "for i in fill_feat:\n",
        "    Data[i].fillna(np.mean(Data[i]),inplace=True)\n",
        "\n",
        "Data.shape\n",
        "\n",
        "Data.dropna(inplace=True)\n",
        "\n",
        "# Separate the features and labels\n",
        "X = Data.drop('RainTomorrow', axis=1)\n",
        "y = Data['RainTomorrow']\n",
        "\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "# Normalize the features\n",
        "scalar = preprocessing.MinMaxScaler(feature_range=(0, 12))\n",
        "norm_data = scalar.fit_transform(X)\n",
        "X = pd.DataFrame(norm_data, columns=[X.columns])\n",
        "X = pd.DataFrame(X.reset_index(drop=True))\n",
        "X.shape"
      ],
      "metadata": {
        "id": "LxxJb_aOMJdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41649f7-3cd8-4c15-f48d-e5580095046f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (142193, 13)\n",
            "y: (142193,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142193, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. It imports the SMOTE module from the imblearn library and oversamples the minority class (i.e., samples where it rained tomorrow) in the dataset to balance the classes."
      ],
      "metadata": {
        "id": "hEoc7PPex36f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "X = pd.DataFrame(X.reset_index(drop=True))\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")"
      ],
      "metadata": {
        "id": "uBGyZMhz6R_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da41134-5322-4263-ed08-05a006b09cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (220632, 13)\n",
            "y: (220632,)\n",
            "X shape: (220632, 13)\n",
            "y shape: (220632,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. It imports the SMOTE module from the imblearn library and oversamples the minority class (i.e., samples where it rained tomorrow) in the dataset to balance the classes. The discriminator is trained to maximize the probability of correctly classifying real data and minimizing the probability of incorrectly classifying synthetic data, while the generator is trained to maximize the probability of the discriminator incorrectly classifying the synthetic data as real.\n",
        "\n",
        "5. It defines the CGANs model, which is the combination of the generator and discriminator. The input to the model is a latent vector, and the output is the probability of the data being real.\n",
        "\n",
        "6. It trains the CGANs model using the adversarial training algorithm. In each epoch, the discriminator and the generator are trained alternately. The discriminator is trained on a combination of real and synthetic data with corresponding labels of 1 and 0, respectively, while the generator is trained to produce synthetic data that the discriminator will classify as real.\n",
        "\n",
        "7. After training, the generator is saved, and synthetic data is generated by passing a latent vector to the generator's predict() method."
      ],
      "metadata": {
        "id": "NICH34a6x54f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "latent_dim = 13\n",
        "\n",
        "# Define the generator model\n",
        "def define_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(X.shape[1], activation='sigmoid'))\n",
        "\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "# Define the discriminator model\n",
        "def define_discriminator(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_dim=input_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=keras.optimizers.SGD(0.0003, 0.5),\n",
        "                  metrics=['accuracy'])\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "# Train the CGANs model\n",
        "def train(X, y, epochs, batch_size, latent_dim):\n",
        "\n",
        "    # Remove rows with missing data\n",
        "    X = X.dropna()\n",
        "\n",
        "    # Get the set of valid indices\n",
        "    valid_indices = set(X.index)\n",
        "\n",
        "    # Define the CGANs model\n",
        "\n",
        "    # Instantiate the generator\n",
        "    generator = define_generator(latent_dim)\n",
        "\n",
        "    discriminator = define_discriminator(X.shape[1])\n",
        "    cgan_input = Input(shape=(latent_dim,))\n",
        "    discriminator_output = discriminator(generator(cgan_input))\n",
        "    cgan = Model(cgan_input, discriminator_output)\n",
        "    cgan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(0.0003, 0.5))\n",
        "\n",
        "    # Train the CGANs model\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "    # Train the discriminator\n",
        "        try:\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            generated_data = generator.predict(noise)\n",
        "\n",
        "            # Sample indices from the valid range of indices in the dataset\n",
        "            real_indices = np.random.choice(list(valid_indices), size=batch_size, replace=False)\n",
        "            real_data = X.loc[real_indices]\n",
        "            combined_data = np.concatenate([generated_data, real_data])\n",
        "            labels = np.concatenate([np.zeros((batch_size, 1)), np.ones((batch_size, 1))])\n",
        "            d_loss = discriminator.train_on_batch(combined_data, labels)\n",
        "        except KeyError as e:\n",
        "            print(f\"Skipping row {id} due to KeyError: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Train the generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        g_loss = cgan.train_on_batch(noise, misleading_targets)\n",
        "\n",
        "        # Print the progress\n",
        "        print(f\"Epoch {epoch} Discriminator Loss: {d_loss} Generator Loss: {g_loss}\")"
      ],
      "metadata": {
        "id": "ukWk5Rn-oLPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(X, y, epochs = 20, batch_size = 128, latent_dim = 13)"
      ],
      "metadata": {
        "id": "QCIrjSxVbG5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09e3346-a0ca-4c82-a85c-f9adfba3fdd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 3s 2ms/step\n",
            "Epoch 0 Discriminator Loss: [0.587205171585083, 0.5859375] Generator Loss: 0.6613437533378601\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 1 Discriminator Loss: [0.578474760055542, 0.53125] Generator Loss: 0.6616266369819641\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 2 Discriminator Loss: [0.5573899745941162, 0.57421875] Generator Loss: 0.656248927116394\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 3 Discriminator Loss: [0.5455784201622009, 0.56640625] Generator Loss: 0.6468992829322815\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 4 Discriminator Loss: [0.5292125940322876, 0.515625] Generator Loss: 0.6535479426383972\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 5 Discriminator Loss: [0.5347127318382263, 0.578125] Generator Loss: 0.6493207216262817\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 6 Discriminator Loss: [0.5448351502418518, 0.5078125] Generator Loss: 0.6478530168533325\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 7 Discriminator Loss: [0.539601743221283, 0.49609375] Generator Loss: 0.6404591202735901\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 8 Discriminator Loss: [0.5087827444076538, 0.546875] Generator Loss: 0.6370512247085571\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 9 Discriminator Loss: [0.5058771967887878, 0.546875] Generator Loss: 0.6403098106384277\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 10 Discriminator Loss: [0.5066400766372681, 0.5234375] Generator Loss: 0.6376227736473083\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 11 Discriminator Loss: [0.5072991847991943, 0.5234375] Generator Loss: 0.6311407089233398\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 12 Discriminator Loss: [0.4881967604160309, 0.546875] Generator Loss: 0.6279199123382568\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 13 Discriminator Loss: [0.49850648641586304, 0.52734375] Generator Loss: 0.6230382919311523\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 14 Discriminator Loss: [0.4922638237476349, 0.5390625] Generator Loss: 0.6190140247344971\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 15 Discriminator Loss: [0.47017133235931396, 0.54296875] Generator Loss: 0.6224581003189087\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 16 Discriminator Loss: [0.47988542914390564, 0.50390625] Generator Loss: 0.6202266812324524\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 17 Discriminator Loss: [0.48450422286987305, 0.5390625] Generator Loss: 0.6194048523902893\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 18 Discriminator Loss: [0.5143605470657349, 0.51953125] Generator Loss: 0.6093001961708069\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 19 Discriminator Loss: [0.4685733914375305, 0.546875] Generator Loss: 0.6122473478317261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_indices = set(Data.index)\n",
        "current_indices = set(X.index)\n",
        "\n",
        "missing_indices = original_indices - current_indices\n",
        "print(missing_indices)"
      ],
      "metadata": {
        "id": "vg0-hoGIu4bK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31375e0-240e-4145-9f85-8a87915cbbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "# Calculate the class ratio in the balanced dataset\n",
        "class_ratio = sum(y_train == 0) / len(y_train)\n",
        "class_ratio"
      ],
      "metadata": {
        "id": "5jgTuI5z6R8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8c46ed-aa62-450a-c083-e827290e8370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.500393756550806"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generator\n",
        "generator = define_generator(latent_dim)\n",
        "\n",
        "# Use the generator to create synthetic data\n",
        "synthetic_data = generator.predict(np.random.normal(0, 1, (len(X_train), latent_dim)))\n",
        "\n",
        "# Combine the real and synthetic data to create a balanced dataset\n",
        "X_balanced = np.concatenate([X_train, synthetic_data])\n",
        "y_balanced = np.concatenate([y_train, np.zeros(len(X_train))])\n",
        "\n",
        "# Calculate the class ratio in the balanced dataset\n",
        "class_ratio = sum(y_balanced == 0) / len(y_balanced)\n",
        "print(class_ratio)\n",
        "\n",
        "print(X_balanced.shape)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "1Vfw2E_FfVrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8011c56-a4ee-4f97-a7c1-272e7f984095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5516/5516 [==============================] - 7s 1ms/step\n",
            "0.7501968782754029\n",
            "(353010, 13)\n",
            "(176505, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Training Federated Learning"
      ],
      "metadata": {
        "id": "O_wz9sSh_H6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define data shape and number of classes\n",
        "input_shape = (13,)\n",
        "num_classes = 2\n",
        "num_test_samples = len(X_test)\n",
        "num_train_samples = len(X_train)\n",
        "Batch_size = 64\n",
        "communication_round = 10\n",
        "Learning_rate = 0.001\n",
        "Momentum = 0.9\n",
        "Epochs = 30\n",
        "data_shape = (13,)"
      ],
      "metadata": {
        "id": "vlA66yGglAM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_clients(X_train, y_train, num_clients, initial='client'):\n",
        "    # create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "    # randomize the data before splitting the data between clients\n",
        "    indices = np.random.permutation(len(X_train))\n",
        "    X_shuffled = X_train[indices]\n",
        "    y_shuffled = y_train[indices]\n",
        "\n",
        "    # shard data and place at each client\n",
        "    size = len(X_train) // num_clients\n",
        "    remainder = len(X_train) % num_clients\n",
        "    shards = [(X_shuffled[i:i+size], y_shuffled[i:i+size]) for i in range(0, size*num_clients, size)]\n",
        "    if remainder:\n",
        "        shards[-1] = (np.concatenate([shards[-1][0], X_shuffled[-remainder:]]),\n",
        "                      np.concatenate([shards[-1][1], y_shuffled[-remainder:]]))\n",
        "\n",
        "    # number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    # create dictionary of clients and their shards\n",
        "    clients = {}\n",
        "    for i in range(len(client_names)):\n",
        "        # create dictionary entry with client name and data shape\n",
        "        clients[client_names[i]] = (shards[i][0].shape, shards[i][1].shape)\n",
        "\n",
        "    return clients\n",
        "\n",
        "def batch_data(data_shard, batchsize=Batch_size):\n",
        "    # unpack data shard into data and labels arrays\n",
        "    X, y = data_shard\n",
        "\n",
        "    # create a tensorflow dataset object from the data and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "\n",
        "    # shuffle and batch the dataset\n",
        "    return dataset.shuffle(len(y)).batch(batchsize)\n",
        "\n",
        "# create clients from training data and associated labels\n",
        "X_train = X_balanced\n",
        "y_train = y_balanced\n",
        "clients = create_clients(X_train, y_train, num_clients=10, initial='client')\n",
        "for client in clients:\n",
        "    print(f\"{client}: X={clients[client][0]}, y={clients[client][1]}\")\n",
        "\n",
        "# You can access the shards for each client by indexing the dictionary returned\n",
        "# by create_clients(), like so:\n",
        "client_1_shard = clients['client_1']\n",
        "client_1_shard\n",
        "\n",
        "# create a batched dataset for each client's data shard\n",
        "clients_batched = {}\n",
        "for client in clients:\n",
        "    client_data_shard = (X_train, y_train)\n",
        "    batched_data = batch_data(client_data_shard)\n",
        "    clients_batched[client] = batched_data\n",
        "\n",
        "#process and batch the test set\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
        "\n",
        "# Federated Averaging: aggregation method\n",
        "def weight_scalling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "    #get the batch_size\n",
        "    batch_size = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    #first calculate the total training data points across clinets\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*batch_size\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*batch_size\n",
        "    return local_count/global_count\n",
        "\n",
        "\n",
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final\n",
        "\n",
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    # Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "\n",
        "    return avg_grad\n",
        "\n",
        "def test_model(X_test, Y_test, model, communication_round):\n",
        "    cce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    logits = model.predict(X_test, batch_size=Batch_size)\n",
        "    logits = tf.squeeze(logits, axis=1) # remove last dimension from logits\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score(tf.round(logits), Y_test)\n",
        "    auc = roc_auc_score(Y_test, logits)\n",
        "    tn, fp, fn, tp = confusion_matrix(Y_test, tf.round(logits)).ravel()\n",
        "    g_mean = np.sqrt(tp/(tp+fn)*tn/(tn+fp))\n",
        "    print('communication_round: {} | global_accuracy: {:.3%} | global_loss: {} | global_AUC: {:.3%} | global_G-mean: {:.3%}'.format(communication_round, acc, loss, auc, g_mean))\n",
        "    return acc, loss, auc, g_mean"
      ],
      "metadata": {
        "id": "eJ2--l2ZzfuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47379550-98fd-4145-f4c7-db9b339584d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client_1: X=(35301, 13), y=(35301,)\n",
            "client_2: X=(35301, 13), y=(35301,)\n",
            "client_3: X=(35301, 13), y=(35301,)\n",
            "client_4: X=(35301, 13), y=(35301,)\n",
            "client_5: X=(35301, 13), y=(35301,)\n",
            "client_6: X=(35301, 13), y=(35301,)\n",
            "client_7: X=(35301, 13), y=(35301,)\n",
            "client_8: X=(35301, 13), y=(35301,)\n",
            "client_9: X=(35301, 13), y=(35301,)\n",
            "client_10: X=(35301, 13), y=(35301,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = Epochs\n",
        "learning_rate = Learning_rate\n",
        "momentum = Momentum\n",
        "batch_size = Batch_size\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01,\n",
        "                                 momentum = momentum,\n",
        "                                 nesterov = False)\n",
        "loss = \"binary_crossentropy\"\n",
        "\n",
        "metrics = [keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "      ]\n",
        "\n",
        "class MyModel:\n",
        "    @staticmethod\n",
        "    def build(shape, classes):\n",
        "        model = tf.keras.Sequential([\n",
        "        layers.Dense(256, activation='relu', input_shape=(13,)),\n",
        "        layers.GaussianNoise(stddev = 0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.GaussianNoise(stddev = 0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.GaussianNoise(stddev = 0.1),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        return model"
      ],
      "metadata": {
        "id": "KjJGuKT7YdcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smlp_global = MyModel()\n",
        "global_model = smlp_global.build(shape=(13,), classes=2)\n",
        "global_model.summary()\n",
        "\n",
        "global_acc_list = []\n",
        "global_loss_list = []\n",
        "global_auc_list = []\n",
        "global_gmean_list = []\n",
        "\n",
        "# commence global training loop\n",
        "for communication_round in range(communication_round):\n",
        "\n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    # initial list to collect local model weights after scaling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    # randomize client data - using keys\n",
        "    client_names = list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "\n",
        "    # loop through each client and create new local model\n",
        "    for client in client_names:\n",
        "        smlp_local = MyModel()\n",
        "        local_model = smlp_local.build(shape=(13,), classes=2)\n",
        "        #local_model = smlp_local.build()\n",
        "        local_model.compile(loss=loss,\n",
        "                            optimizer=optimizer,\n",
        "                            metrics=metrics)\n",
        "\n",
        "        # set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        # fit local model with client's data\n",
        "        model_history = local_model.fit(clients_batched[client], epochs=epochs, verbose=1)\n",
        "\n",
        "        # evaluate local model on test data\n",
        "        # test_loss, test_accuracy = local_model.evaluate(X_test, y_test)\n",
        "        # print(f'Local model {client} - test_loss: {test_loss} - test_accuracy: {test_accuracy}')\n",
        "\n",
        "        # scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "\n",
        "        # clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "\n",
        "    # to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    avg_grad = sum_scaled_weights(scaled_local_weight_list)\n",
        "\n",
        "    # update global model\n",
        "    global_model.set_weights(avg_grad)\n",
        "\n",
        "    # test global model and print out metrics after each communications round\n",
        "    for X_test, y_test in test_batched:\n",
        "        global_acc, global_loss, global_auc, global_gmean = test_model(X_test, y_test, global_model, communication_round)\n",
        "        global_acc_list.append(global_acc)\n",
        "        global_loss_list.append(global_loss)\n",
        "        global_auc_list.append(global_auc)\n",
        "        global_gmean_list.append(global_gmean)"
      ],
      "metadata": {
        "id": "AgS2AdJxDyG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589a9254-719d-4f29-93f5-5a1f3aef36f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 256)               3584      \n",
            "                                                                 \n",
            " gaussian_noise (GaussianNoi  (None, 256)              0         \n",
            " se)                                                             \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " gaussian_noise_1 (GaussianN  (None, 128)              0         \n",
            " oise)                                                           \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " gaussian_noise_2 (GaussianN  (None, 64)               0         \n",
            " oise)                                                           \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,849\n",
            "Trainable params: 46,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2474 - tp: 65482.0000 - fp: 19498.0000 - tn: 245329.0000 - fn: 22701.0000 - accuracy: 0.8805 - precision: 0.7706 - recall: 0.7426 - auc: 0.9466 - prc: 0.8432\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2387 - tp: 66547.0000 - fp: 19130.0000 - tn: 245697.0000 - fn: 21636.0000 - accuracy: 0.8845 - precision: 0.7767 - recall: 0.7546 - auc: 0.9505 - prc: 0.8539\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2366 - tp: 66777.0000 - fp: 18715.0000 - tn: 246112.0000 - fn: 21406.0000 - accuracy: 0.8863 - precision: 0.7811 - recall: 0.7573 - auc: 0.9514 - prc: 0.8568\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2353 - tp: 67051.0000 - fp: 18798.0000 - tn: 246029.0000 - fn: 21132.0000 - accuracy: 0.8869 - precision: 0.7810 - recall: 0.7604 - auc: 0.9520 - prc: 0.8587\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2341 - tp: 67148.0000 - fp: 18801.0000 - tn: 246026.0000 - fn: 21035.0000 - accuracy: 0.8872 - precision: 0.7813 - recall: 0.7615 - auc: 0.9525 - prc: 0.8602\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2333 - tp: 67028.0000 - fp: 18397.0000 - tn: 246430.0000 - fn: 21155.0000 - accuracy: 0.8880 - precision: 0.7846 - recall: 0.7601 - auc: 0.9529 - prc: 0.8615\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2327 - tp: 67306.0000 - fp: 18548.0000 - tn: 246279.0000 - fn: 20877.0000 - accuracy: 0.8883 - precision: 0.7840 - recall: 0.7633 - auc: 0.9532 - prc: 0.8623\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2318 - tp: 67547.0000 - fp: 18560.0000 - tn: 246267.0000 - fn: 20636.0000 - accuracy: 0.8890 - precision: 0.7845 - recall: 0.7660 - auc: 0.9536 - prc: 0.8634\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2315 - tp: 67628.0000 - fp: 18557.0000 - tn: 246270.0000 - fn: 20555.0000 - accuracy: 0.8892 - precision: 0.7847 - recall: 0.7669 - auc: 0.9538 - prc: 0.8636\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2308 - tp: 67656.0000 - fp: 18337.0000 - tn: 246490.0000 - fn: 20527.0000 - accuracy: 0.8899 - precision: 0.7868 - recall: 0.7672 - auc: 0.9541 - prc: 0.8645\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2305 - tp: 67595.0000 - fp: 18341.0000 - tn: 246486.0000 - fn: 20588.0000 - accuracy: 0.8897 - precision: 0.7866 - recall: 0.7665 - auc: 0.9542 - prc: 0.8651\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2301 - tp: 67847.0000 - fp: 18542.0000 - tn: 246285.0000 - fn: 20336.0000 - accuracy: 0.8899 - precision: 0.7854 - recall: 0.7694 - auc: 0.9544 - prc: 0.8658\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2297 - tp: 67830.0000 - fp: 18380.0000 - tn: 246447.0000 - fn: 20353.0000 - accuracy: 0.8903 - precision: 0.7868 - recall: 0.7692 - auc: 0.9546 - prc: 0.8658\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2296 - tp: 67927.0000 - fp: 18492.0000 - tn: 246335.0000 - fn: 20256.0000 - accuracy: 0.8902 - precision: 0.7860 - recall: 0.7703 - auc: 0.9546 - prc: 0.8663\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2290 - tp: 68238.0000 - fp: 18639.0000 - tn: 246188.0000 - fn: 19945.0000 - accuracy: 0.8907 - precision: 0.7855 - recall: 0.7738 - auc: 0.9549 - prc: 0.8669\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2287 - tp: 68043.0000 - fp: 18467.0000 - tn: 246360.0000 - fn: 20140.0000 - accuracy: 0.8906 - precision: 0.7865 - recall: 0.7716 - auc: 0.9550 - prc: 0.8675\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2282 - tp: 68204.0000 - fp: 18616.0000 - tn: 246211.0000 - fn: 19979.0000 - accuracy: 0.8907 - precision: 0.7856 - recall: 0.7734 - auc: 0.9552 - prc: 0.8677\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2283 - tp: 68104.0000 - fp: 18374.0000 - tn: 246453.0000 - fn: 20079.0000 - accuracy: 0.8911 - precision: 0.7875 - recall: 0.7723 - auc: 0.9552 - prc: 0.8678\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2278 - tp: 68125.0000 - fp: 18506.0000 - tn: 246321.0000 - fn: 20058.0000 - accuracy: 0.8908 - precision: 0.7864 - recall: 0.7725 - auc: 0.9554 - prc: 0.8683\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2278 - tp: 68299.0000 - fp: 18477.0000 - tn: 246350.0000 - fn: 19884.0000 - accuracy: 0.8913 - precision: 0.7871 - recall: 0.7745 - auc: 0.9554 - prc: 0.8684\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2272 - tp: 68122.0000 - fp: 18169.0000 - tn: 246658.0000 - fn: 20061.0000 - accuracy: 0.8917 - precision: 0.7894 - recall: 0.7725 - auc: 0.9556 - prc: 0.8694\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2271 - tp: 68389.0000 - fp: 18368.0000 - tn: 246459.0000 - fn: 19794.0000 - accuracy: 0.8919 - precision: 0.7883 - recall: 0.7755 - auc: 0.9557 - prc: 0.8692\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2268 - tp: 68450.0000 - fp: 18506.0000 - tn: 246321.0000 - fn: 19733.0000 - accuracy: 0.8917 - precision: 0.7872 - recall: 0.7762 - auc: 0.9558 - prc: 0.8698\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2265 - tp: 68351.0000 - fp: 18349.0000 - tn: 246478.0000 - fn: 19832.0000 - accuracy: 0.8918 - precision: 0.7884 - recall: 0.7751 - auc: 0.9559 - prc: 0.8702\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2263 - tp: 68431.0000 - fp: 18489.0000 - tn: 246338.0000 - fn: 19752.0000 - accuracy: 0.8917 - precision: 0.7873 - recall: 0.7760 - auc: 0.9560 - prc: 0.8706\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2258 - tp: 68783.0000 - fp: 18596.0000 - tn: 246231.0000 - fn: 19400.0000 - accuracy: 0.8924 - precision: 0.7872 - recall: 0.7800 - auc: 0.9562 - prc: 0.8707\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2258 - tp: 68536.0000 - fp: 18420.0000 - tn: 246407.0000 - fn: 19647.0000 - accuracy: 0.8922 - precision: 0.7882 - recall: 0.7772 - auc: 0.9562 - prc: 0.8708\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2257 - tp: 68386.0000 - fp: 18211.0000 - tn: 246616.0000 - fn: 19797.0000 - accuracy: 0.8923 - precision: 0.7897 - recall: 0.7755 - auc: 0.9563 - prc: 0.8708\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2254 - tp: 68472.0000 - fp: 18116.0000 - tn: 246711.0000 - fn: 19711.0000 - accuracy: 0.8928 - precision: 0.7908 - recall: 0.7765 - auc: 0.9564 - prc: 0.8713\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2251 - tp: 68450.0000 - fp: 18135.0000 - tn: 246692.0000 - fn: 19733.0000 - accuracy: 0.8927 - precision: 0.7906 - recall: 0.7762 - auc: 0.9565 - prc: 0.8715\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2482 - tp: 133894.0000 - fp: 37501.0000 - tn: 492153.0000 - fn: 42472.0000 - accuracy: 0.8867 - precision: 0.7812 - recall: 0.7592 - auc: 0.9516 - prc: 0.8571\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2391 - tp: 66438.0000 - fp: 18997.0000 - tn: 245830.0000 - fn: 21745.0000 - accuracy: 0.8846 - precision: 0.7776 - recall: 0.7534 - auc: 0.9503 - prc: 0.8529\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2372 - tp: 66745.0000 - fp: 18824.0000 - tn: 246003.0000 - fn: 21438.0000 - accuracy: 0.8859 - precision: 0.7800 - recall: 0.7569 - auc: 0.9512 - prc: 0.8555\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2357 - tp: 67049.0000 - fp: 18938.0000 - tn: 245889.0000 - fn: 21134.0000 - accuracy: 0.8865 - precision: 0.7798 - recall: 0.7603 - auc: 0.9518 - prc: 0.8580\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2346 - tp: 67080.0000 - fp: 18724.0000 - tn: 246103.0000 - fn: 21103.0000 - accuracy: 0.8872 - precision: 0.7818 - recall: 0.7607 - auc: 0.9524 - prc: 0.8595\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2338 - tp: 67043.0000 - fp: 18554.0000 - tn: 246273.0000 - fn: 21140.0000 - accuracy: 0.8876 - precision: 0.7832 - recall: 0.7603 - auc: 0.9527 - prc: 0.8607\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2332 - tp: 67388.0000 - fp: 18677.0000 - tn: 246150.0000 - fn: 20795.0000 - accuracy: 0.8882 - precision: 0.7830 - recall: 0.7642 - auc: 0.9529 - prc: 0.8613\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2322 - tp: 67336.0000 - fp: 18531.0000 - tn: 246296.0000 - fn: 20847.0000 - accuracy: 0.8885 - precision: 0.7842 - recall: 0.7636 - auc: 0.9534 - prc: 0.8628\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2317 - tp: 67851.0000 - fp: 18842.0000 - tn: 245985.0000 - fn: 20332.0000 - accuracy: 0.8890 - precision: 0.7827 - recall: 0.7694 - auc: 0.9537 - prc: 0.8638\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2313 - tp: 67790.0000 - fp: 18842.0000 - tn: 245985.0000 - fn: 20393.0000 - accuracy: 0.8889 - precision: 0.7825 - recall: 0.7687 - auc: 0.9538 - prc: 0.8641\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2308 - tp: 67627.0000 - fp: 18588.0000 - tn: 246239.0000 - fn: 20556.0000 - accuracy: 0.8891 - precision: 0.7844 - recall: 0.7669 - auc: 0.9540 - prc: 0.8648\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2304 - tp: 68096.0000 - fp: 18814.0000 - tn: 246013.0000 - fn: 20087.0000 - accuracy: 0.8898 - precision: 0.7835 - recall: 0.7722 - auc: 0.9543 - prc: 0.8650\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2302 - tp: 67751.0000 - fp: 18406.0000 - tn: 246421.0000 - fn: 20432.0000 - accuracy: 0.8900 - precision: 0.7864 - recall: 0.7683 - auc: 0.9543 - prc: 0.8655\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2297 - tp: 68040.0000 - fp: 18864.0000 - tn: 245963.0000 - fn: 20143.0000 - accuracy: 0.8895 - precision: 0.7829 - recall: 0.7716 - auc: 0.9545 - prc: 0.8657\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2294 - tp: 68149.0000 - fp: 18679.0000 - tn: 246148.0000 - fn: 20034.0000 - accuracy: 0.8903 - precision: 0.7849 - recall: 0.7728 - auc: 0.9546 - prc: 0.8665\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2288 - tp: 68027.0000 - fp: 18551.0000 - tn: 246276.0000 - fn: 20156.0000 - accuracy: 0.8904 - precision: 0.7857 - recall: 0.7714 - auc: 0.9549 - prc: 0.8673\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2291 - tp: 68061.0000 - fp: 18520.0000 - tn: 246307.0000 - fn: 20122.0000 - accuracy: 0.8905 - precision: 0.7861 - recall: 0.7718 - auc: 0.9548 - prc: 0.8670\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2287 - tp: 68048.0000 - fp: 18473.0000 - tn: 246354.0000 - fn: 20135.0000 - accuracy: 0.8906 - precision: 0.7865 - recall: 0.7717 - auc: 0.9550 - prc: 0.8675\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2283 - tp: 68302.0000 - fp: 18586.0000 - tn: 246241.0000 - fn: 19881.0000 - accuracy: 0.8910 - precision: 0.7861 - recall: 0.7745 - auc: 0.9552 - prc: 0.8680\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2279 - tp: 68231.0000 - fp: 18502.0000 - tn: 246325.0000 - fn: 19952.0000 - accuracy: 0.8911 - precision: 0.7867 - recall: 0.7737 - auc: 0.9553 - prc: 0.8685\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2277 - tp: 68526.0000 - fp: 18636.0000 - tn: 246191.0000 - fn: 19657.0000 - accuracy: 0.8915 - precision: 0.7862 - recall: 0.7771 - auc: 0.9554 - prc: 0.8685\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2271 - tp: 68261.0000 - fp: 18295.0000 - tn: 246532.0000 - fn: 19922.0000 - accuracy: 0.8917 - precision: 0.7886 - recall: 0.7741 - auc: 0.9557 - prc: 0.8694\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2270 - tp: 68419.0000 - fp: 18558.0000 - tn: 246269.0000 - fn: 19764.0000 - accuracy: 0.8914 - precision: 0.7866 - recall: 0.7759 - auc: 0.9557 - prc: 0.8693\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2269 - tp: 68623.0000 - fp: 18683.0000 - tn: 246144.0000 - fn: 19560.0000 - accuracy: 0.8917 - precision: 0.7860 - recall: 0.7782 - auc: 0.9558 - prc: 0.8697\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2266 - tp: 68582.0000 - fp: 18480.0000 - tn: 246347.0000 - fn: 19601.0000 - accuracy: 0.8921 - precision: 0.7877 - recall: 0.7777 - auc: 0.9559 - prc: 0.8699\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2264 - tp: 68491.0000 - fp: 18374.0000 - tn: 246453.0000 - fn: 19692.0000 - accuracy: 0.8922 - precision: 0.7885 - recall: 0.7767 - auc: 0.9560 - prc: 0.8700\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2261 - tp: 68367.0000 - fp: 18227.0000 - tn: 246600.0000 - fn: 19816.0000 - accuracy: 0.8922 - precision: 0.7895 - recall: 0.7753 - auc: 0.9561 - prc: 0.8705\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2260 - tp: 68358.0000 - fp: 18122.0000 - tn: 246705.0000 - fn: 19825.0000 - accuracy: 0.8925 - precision: 0.7904 - recall: 0.7752 - auc: 0.9561 - prc: 0.8707\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2255 - tp: 68552.0000 - fp: 18296.0000 - tn: 246531.0000 - fn: 19631.0000 - accuracy: 0.8926 - precision: 0.7893 - recall: 0.7774 - auc: 0.9564 - prc: 0.8711\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2251 - tp: 68554.0000 - fp: 18156.0000 - tn: 246671.0000 - fn: 19629.0000 - accuracy: 0.8930 - precision: 0.7906 - recall: 0.7774 - auc: 0.9566 - prc: 0.8718\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2474 - tp: 134330.0000 - fp: 37839.0000 - tn: 491815.0000 - fn: 42036.0000 - accuracy: 0.8869 - precision: 0.7802 - recall: 0.7617 - auc: 0.9518 - prc: 0.8577\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2391 - tp: 66356.0000 - fp: 19010.0000 - tn: 245817.0000 - fn: 21827.0000 - accuracy: 0.8843 - precision: 0.7773 - recall: 0.7525 - auc: 0.9504 - prc: 0.8532\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2365 - tp: 66773.0000 - fp: 18712.0000 - tn: 246115.0000 - fn: 21410.0000 - accuracy: 0.8863 - precision: 0.7811 - recall: 0.7572 - auc: 0.9515 - prc: 0.8566\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2353 - tp: 66895.0000 - fp: 18647.0000 - tn: 246180.0000 - fn: 21288.0000 - accuracy: 0.8869 - precision: 0.7820 - recall: 0.7586 - auc: 0.9520 - prc: 0.8584\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2342 - tp: 67035.0000 - fp: 18570.0000 - tn: 246257.0000 - fn: 21148.0000 - accuracy: 0.8875 - precision: 0.7831 - recall: 0.7602 - auc: 0.9525 - prc: 0.8603\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2335 - tp: 67131.0000 - fp: 18509.0000 - tn: 246318.0000 - fn: 21052.0000 - accuracy: 0.8879 - precision: 0.7839 - recall: 0.7613 - auc: 0.9528 - prc: 0.8612\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2325 - tp: 67425.0000 - fp: 18650.0000 - tn: 246177.0000 - fn: 20758.0000 - accuracy: 0.8884 - precision: 0.7833 - recall: 0.7646 - auc: 0.9533 - prc: 0.8623\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2320 - tp: 67524.0000 - fp: 18666.0000 - tn: 246161.0000 - fn: 20659.0000 - accuracy: 0.8886 - precision: 0.7834 - recall: 0.7657 - auc: 0.9535 - prc: 0.8632\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2314 - tp: 67423.0000 - fp: 18369.0000 - tn: 246458.0000 - fn: 20760.0000 - accuracy: 0.8892 - precision: 0.7859 - recall: 0.7646 - auc: 0.9537 - prc: 0.8637\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2308 - tp: 67703.0000 - fp: 18495.0000 - tn: 246332.0000 - fn: 20480.0000 - accuracy: 0.8896 - precision: 0.7854 - recall: 0.7678 - auc: 0.9540 - prc: 0.8649\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2302 - tp: 67678.0000 - fp: 18424.0000 - tn: 246403.0000 - fn: 20505.0000 - accuracy: 0.8897 - precision: 0.7860 - recall: 0.7675 - auc: 0.9543 - prc: 0.8654\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2297 - tp: 68107.0000 - fp: 18627.0000 - tn: 246200.0000 - fn: 20076.0000 - accuracy: 0.8904 - precision: 0.7852 - recall: 0.7723 - auc: 0.9545 - prc: 0.8659\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2301 - tp: 68014.0000 - fp: 18698.0000 - tn: 246129.0000 - fn: 20169.0000 - accuracy: 0.8899 - precision: 0.7844 - recall: 0.7713 - auc: 0.9544 - prc: 0.8655\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2292 - tp: 68100.0000 - fp: 18673.0000 - tn: 246154.0000 - fn: 20083.0000 - accuracy: 0.8902 - precision: 0.7848 - recall: 0.7723 - auc: 0.9548 - prc: 0.8666\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2289 - tp: 68336.0000 - fp: 18687.0000 - tn: 246140.0000 - fn: 19847.0000 - accuracy: 0.8908 - precision: 0.7853 - recall: 0.7749 - auc: 0.9549 - prc: 0.8671\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2289 - tp: 68314.0000 - fp: 18623.0000 - tn: 246204.0000 - fn: 19869.0000 - accuracy: 0.8910 - precision: 0.7858 - recall: 0.7747 - auc: 0.9549 - prc: 0.8672\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2284 - tp: 68268.0000 - fp: 18560.0000 - tn: 246267.0000 - fn: 19915.0000 - accuracy: 0.8910 - precision: 0.7862 - recall: 0.7742 - auc: 0.9551 - prc: 0.8677\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2282 - tp: 68475.0000 - fp: 18733.0000 - tn: 246094.0000 - fn: 19708.0000 - accuracy: 0.8911 - precision: 0.7852 - recall: 0.7765 - auc: 0.9552 - prc: 0.8679\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2278 - tp: 68372.0000 - fp: 18544.0000 - tn: 246283.0000 - fn: 19811.0000 - accuracy: 0.8913 - precision: 0.7866 - recall: 0.7753 - auc: 0.9554 - prc: 0.8682\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2274 - tp: 68412.0000 - fp: 18513.0000 - tn: 246314.0000 - fn: 19771.0000 - accuracy: 0.8915 - precision: 0.7870 - recall: 0.7758 - auc: 0.9556 - prc: 0.8691\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2272 - tp: 68474.0000 - fp: 18547.0000 - tn: 246280.0000 - fn: 19709.0000 - accuracy: 0.8916 - precision: 0.7869 - recall: 0.7765 - auc: 0.9556 - prc: 0.8692\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2271 - tp: 68521.0000 - fp: 18508.0000 - tn: 246319.0000 - fn: 19662.0000 - accuracy: 0.8919 - precision: 0.7873 - recall: 0.7770 - auc: 0.9557 - prc: 0.8692\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2270 - tp: 68356.0000 - fp: 18424.0000 - tn: 246403.0000 - fn: 19827.0000 - accuracy: 0.8916 - precision: 0.7877 - recall: 0.7752 - auc: 0.9558 - prc: 0.8695\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2267 - tp: 68546.0000 - fp: 18512.0000 - tn: 246315.0000 - fn: 19637.0000 - accuracy: 0.8919 - precision: 0.7874 - recall: 0.7773 - auc: 0.9559 - prc: 0.8698\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2262 - tp: 68627.0000 - fp: 18458.0000 - tn: 246369.0000 - fn: 19556.0000 - accuracy: 0.8923 - precision: 0.7880 - recall: 0.7782 - auc: 0.9561 - prc: 0.8706\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2259 - tp: 68647.0000 - fp: 18471.0000 - tn: 246356.0000 - fn: 19536.0000 - accuracy: 0.8923 - precision: 0.7880 - recall: 0.7785 - auc: 0.9562 - prc: 0.8708\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2257 - tp: 68655.0000 - fp: 18596.0000 - tn: 246231.0000 - fn: 19528.0000 - accuracy: 0.8920 - precision: 0.7869 - recall: 0.7786 - auc: 0.9563 - prc: 0.8710\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2256 - tp: 68599.0000 - fp: 18162.0000 - tn: 246665.0000 - fn: 19584.0000 - accuracy: 0.8931 - precision: 0.7907 - recall: 0.7779 - auc: 0.9563 - prc: 0.8712\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2251 - tp: 68788.0000 - fp: 18459.0000 - tn: 246368.0000 - fn: 19395.0000 - accuracy: 0.8928 - precision: 0.7884 - recall: 0.7801 - auc: 0.9565 - prc: 0.8719\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2250 - tp: 68749.0000 - fp: 18511.0000 - tn: 246316.0000 - fn: 19434.0000 - accuracy: 0.8925 - precision: 0.7879 - recall: 0.7796 - auc: 0.9566 - prc: 0.8718\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2479 - tp: 134232.0000 - fp: 38247.0000 - tn: 491407.0000 - fn: 42134.0000 - accuracy: 0.8861 - precision: 0.7783 - recall: 0.7611 - auc: 0.9517 - prc: 0.8576\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2389 - tp: 66442.0000 - fp: 18772.0000 - tn: 246055.0000 - fn: 21741.0000 - accuracy: 0.8852 - precision: 0.7797 - recall: 0.7535 - auc: 0.9504 - prc: 0.8529\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2368 - tp: 66731.0000 - fp: 18915.0000 - tn: 245912.0000 - fn: 21452.0000 - accuracy: 0.8856 - precision: 0.7791 - recall: 0.7567 - auc: 0.9514 - prc: 0.8566\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2355 - tp: 67069.0000 - fp: 18930.0000 - tn: 245897.0000 - fn: 21114.0000 - accuracy: 0.8866 - precision: 0.7799 - recall: 0.7606 - auc: 0.9519 - prc: 0.8581\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2344 - tp: 67233.0000 - fp: 18758.0000 - tn: 246069.0000 - fn: 20950.0000 - accuracy: 0.8875 - precision: 0.7819 - recall: 0.7624 - auc: 0.9524 - prc: 0.8599\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2339 - tp: 67553.0000 - fp: 19017.0000 - tn: 245810.0000 - fn: 20630.0000 - accuracy: 0.8877 - precision: 0.7803 - recall: 0.7661 - auc: 0.9527 - prc: 0.8602\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2327 - tp: 67291.0000 - fp: 18593.0000 - tn: 246234.0000 - fn: 20892.0000 - accuracy: 0.8881 - precision: 0.7835 - recall: 0.7631 - auc: 0.9532 - prc: 0.8625\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2323 - tp: 67499.0000 - fp: 18615.0000 - tn: 246212.0000 - fn: 20684.0000 - accuracy: 0.8887 - precision: 0.7838 - recall: 0.7654 - auc: 0.9534 - prc: 0.8627\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2319 - tp: 67823.0000 - fp: 18938.0000 - tn: 245889.0000 - fn: 20360.0000 - accuracy: 0.8887 - precision: 0.7817 - recall: 0.7691 - auc: 0.9536 - prc: 0.8632\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2313 - tp: 67773.0000 - fp: 18638.0000 - tn: 246189.0000 - fn: 20410.0000 - accuracy: 0.8894 - precision: 0.7843 - recall: 0.7685 - auc: 0.9538 - prc: 0.8642\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2308 - tp: 67623.0000 - fp: 18401.0000 - tn: 246426.0000 - fn: 20560.0000 - accuracy: 0.8896 - precision: 0.7861 - recall: 0.7668 - auc: 0.9541 - prc: 0.8644\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2305 - tp: 67902.0000 - fp: 18683.0000 - tn: 246144.0000 - fn: 20281.0000 - accuracy: 0.8896 - precision: 0.7842 - recall: 0.7700 - auc: 0.9542 - prc: 0.8650\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2300 - tp: 67991.0000 - fp: 18636.0000 - tn: 246191.0000 - fn: 20192.0000 - accuracy: 0.8900 - precision: 0.7849 - recall: 0.7710 - auc: 0.9544 - prc: 0.8658\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2298 - tp: 68126.0000 - fp: 18727.0000 - tn: 246100.0000 - fn: 20057.0000 - accuracy: 0.8901 - precision: 0.7844 - recall: 0.7726 - auc: 0.9545 - prc: 0.8662\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2293 - tp: 68036.0000 - fp: 18530.0000 - tn: 246297.0000 - fn: 20147.0000 - accuracy: 0.8904 - precision: 0.7859 - recall: 0.7715 - auc: 0.9547 - prc: 0.8667\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2292 - tp: 68284.0000 - fp: 18828.0000 - tn: 245999.0000 - fn: 19899.0000 - accuracy: 0.8903 - precision: 0.7839 - recall: 0.7743 - auc: 0.9548 - prc: 0.8669\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2288 - tp: 68156.0000 - fp: 18494.0000 - tn: 246333.0000 - fn: 20027.0000 - accuracy: 0.8909 - precision: 0.7866 - recall: 0.7729 - auc: 0.9549 - prc: 0.8674\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2283 - tp: 68107.0000 - fp: 18450.0000 - tn: 246377.0000 - fn: 20076.0000 - accuracy: 0.8909 - precision: 0.7868 - recall: 0.7723 - auc: 0.9552 - prc: 0.8679\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2281 - tp: 68334.0000 - fp: 18587.0000 - tn: 246240.0000 - fn: 19849.0000 - accuracy: 0.8911 - precision: 0.7862 - recall: 0.7749 - auc: 0.9552 - prc: 0.8682\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2280 - tp: 68190.0000 - fp: 18433.0000 - tn: 246394.0000 - fn: 19993.0000 - accuracy: 0.8911 - precision: 0.7872 - recall: 0.7733 - auc: 0.9553 - prc: 0.8682\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2277 - tp: 68162.0000 - fp: 18365.0000 - tn: 246462.0000 - fn: 20021.0000 - accuracy: 0.8913 - precision: 0.7878 - recall: 0.7730 - auc: 0.9554 - prc: 0.8685\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2274 - tp: 68438.0000 - fp: 18671.0000 - tn: 246156.0000 - fn: 19745.0000 - accuracy: 0.8912 - precision: 0.7857 - recall: 0.7761 - auc: 0.9555 - prc: 0.8692\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2269 - tp: 68522.0000 - fp: 18469.0000 - tn: 246358.0000 - fn: 19661.0000 - accuracy: 0.8920 - precision: 0.7877 - recall: 0.7770 - auc: 0.9558 - prc: 0.8695\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2266 - tp: 68267.0000 - fp: 18164.0000 - tn: 246663.0000 - fn: 19916.0000 - accuracy: 0.8921 - precision: 0.7898 - recall: 0.7742 - auc: 0.9559 - prc: 0.8704\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2264 - tp: 68460.0000 - fp: 18265.0000 - tn: 246562.0000 - fn: 19723.0000 - accuracy: 0.8924 - precision: 0.7894 - recall: 0.7763 - auc: 0.9559 - prc: 0.8703\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2262 - tp: 68621.0000 - fp: 18419.0000 - tn: 246408.0000 - fn: 19562.0000 - accuracy: 0.8924 - precision: 0.7884 - recall: 0.7782 - auc: 0.9560 - prc: 0.8705\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2260 - tp: 68526.0000 - fp: 18419.0000 - tn: 246408.0000 - fn: 19657.0000 - accuracy: 0.8921 - precision: 0.7882 - recall: 0.7771 - auc: 0.9562 - prc: 0.8709\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2256 - tp: 68734.0000 - fp: 18513.0000 - tn: 246314.0000 - fn: 19449.0000 - accuracy: 0.8925 - precision: 0.7878 - recall: 0.7794 - auc: 0.9563 - prc: 0.8713\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2254 - tp: 68674.0000 - fp: 18523.0000 - tn: 246304.0000 - fn: 19509.0000 - accuracy: 0.8923 - precision: 0.7876 - recall: 0.7788 - auc: 0.9564 - prc: 0.8715\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2251 - tp: 68709.0000 - fp: 18322.0000 - tn: 246505.0000 - fn: 19474.0000 - accuracy: 0.8929 - precision: 0.7895 - recall: 0.7792 - auc: 0.9565 - prc: 0.8719\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2481 - tp: 133706.0000 - fp: 37598.0000 - tn: 492056.0000 - fn: 42660.0000 - accuracy: 0.8863 - precision: 0.7805 - recall: 0.7581 - auc: 0.9516 - prc: 0.8576\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2387 - tp: 66343.0000 - fp: 18893.0000 - tn: 245934.0000 - fn: 21840.0000 - accuracy: 0.8846 - precision: 0.7783 - recall: 0.7523 - auc: 0.9505 - prc: 0.8539\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2367 - tp: 66772.0000 - fp: 18749.0000 - tn: 246078.0000 - fn: 21411.0000 - accuracy: 0.8862 - precision: 0.7808 - recall: 0.7572 - auc: 0.9513 - prc: 0.8565\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2355 - tp: 66902.0000 - fp: 18798.0000 - tn: 246029.0000 - fn: 21281.0000 - accuracy: 0.8865 - precision: 0.7807 - recall: 0.7587 - auc: 0.9519 - prc: 0.8581\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2344 - tp: 67103.0000 - fp: 18664.0000 - tn: 246163.0000 - fn: 21080.0000 - accuracy: 0.8874 - precision: 0.7824 - recall: 0.7610 - auc: 0.9524 - prc: 0.8598\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2336 - tp: 67281.0000 - fp: 18678.0000 - tn: 246149.0000 - fn: 20902.0000 - accuracy: 0.8879 - precision: 0.7827 - recall: 0.7630 - auc: 0.9528 - prc: 0.8609\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2325 - tp: 67546.0000 - fp: 18708.0000 - tn: 246119.0000 - fn: 20637.0000 - accuracy: 0.8885 - precision: 0.7831 - recall: 0.7660 - auc: 0.9533 - prc: 0.8625\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2318 - tp: 67582.0000 - fp: 18547.0000 - tn: 246280.0000 - fn: 20601.0000 - accuracy: 0.8891 - precision: 0.7847 - recall: 0.7664 - auc: 0.9536 - prc: 0.8634\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2313 - tp: 67530.0000 - fp: 18528.0000 - tn: 246299.0000 - fn: 20653.0000 - accuracy: 0.8890 - precision: 0.7847 - recall: 0.7658 - auc: 0.9538 - prc: 0.8637\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2307 - tp: 67721.0000 - fp: 18579.0000 - tn: 246248.0000 - fn: 20462.0000 - accuracy: 0.8894 - precision: 0.7847 - recall: 0.7680 - auc: 0.9541 - prc: 0.8647\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2306 - tp: 67821.0000 - fp: 18600.0000 - tn: 246227.0000 - fn: 20362.0000 - accuracy: 0.8896 - precision: 0.7848 - recall: 0.7691 - auc: 0.9541 - prc: 0.8650\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2301 - tp: 67760.0000 - fp: 18370.0000 - tn: 246457.0000 - fn: 20423.0000 - accuracy: 0.8901 - precision: 0.7867 - recall: 0.7684 - auc: 0.9544 - prc: 0.8656\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2295 - tp: 67880.0000 - fp: 18406.0000 - tn: 246421.0000 - fn: 20303.0000 - accuracy: 0.8903 - precision: 0.7867 - recall: 0.7698 - auc: 0.9546 - prc: 0.8663\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2292 - tp: 68200.0000 - fp: 18486.0000 - tn: 246341.0000 - fn: 19983.0000 - accuracy: 0.8910 - precision: 0.7867 - recall: 0.7734 - auc: 0.9548 - prc: 0.8670\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2290 - tp: 67942.0000 - fp: 18446.0000 - tn: 246381.0000 - fn: 20241.0000 - accuracy: 0.8904 - precision: 0.7865 - recall: 0.7705 - auc: 0.9548 - prc: 0.8671\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2286 - tp: 67987.0000 - fp: 18446.0000 - tn: 246381.0000 - fn: 20196.0000 - accuracy: 0.8905 - precision: 0.7866 - recall: 0.7710 - auc: 0.9550 - prc: 0.8675\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2282 - tp: 68194.0000 - fp: 18610.0000 - tn: 246217.0000 - fn: 19989.0000 - accuracy: 0.8907 - precision: 0.7856 - recall: 0.7733 - auc: 0.9552 - prc: 0.8680\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2280 - tp: 68149.0000 - fp: 18403.0000 - tn: 246424.0000 - fn: 20034.0000 - accuracy: 0.8911 - precision: 0.7874 - recall: 0.7728 - auc: 0.9553 - prc: 0.8682\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2277 - tp: 68207.0000 - fp: 18610.0000 - tn: 246217.0000 - fn: 19976.0000 - accuracy: 0.8907 - precision: 0.7856 - recall: 0.7735 - auc: 0.9554 - prc: 0.8686\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2277 - tp: 68100.0000 - fp: 18347.0000 - tn: 246480.0000 - fn: 20083.0000 - accuracy: 0.8911 - precision: 0.7878 - recall: 0.7723 - auc: 0.9554 - prc: 0.8685\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2274 - tp: 68190.0000 - fp: 18369.0000 - tn: 246458.0000 - fn: 19993.0000 - accuracy: 0.8913 - precision: 0.7878 - recall: 0.7733 - auc: 0.9556 - prc: 0.8691\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2269 - tp: 68477.0000 - fp: 18535.0000 - tn: 246292.0000 - fn: 19706.0000 - accuracy: 0.8917 - precision: 0.7870 - recall: 0.7765 - auc: 0.9557 - prc: 0.8698\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2268 - tp: 68650.0000 - fp: 18695.0000 - tn: 246132.0000 - fn: 19533.0000 - accuracy: 0.8917 - precision: 0.7860 - recall: 0.7785 - auc: 0.9558 - prc: 0.8697\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2264 - tp: 68594.0000 - fp: 18575.0000 - tn: 246252.0000 - fn: 19589.0000 - accuracy: 0.8919 - precision: 0.7869 - recall: 0.7779 - auc: 0.9560 - prc: 0.8700\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2260 - tp: 68645.0000 - fp: 18625.0000 - tn: 246202.0000 - fn: 19538.0000 - accuracy: 0.8919 - precision: 0.7866 - recall: 0.7784 - auc: 0.9562 - prc: 0.8708\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2257 - tp: 68866.0000 - fp: 18685.0000 - tn: 246142.0000 - fn: 19317.0000 - accuracy: 0.8923 - precision: 0.7866 - recall: 0.7809 - auc: 0.9563 - prc: 0.8715\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2257 - tp: 68849.0000 - fp: 18620.0000 - tn: 246207.0000 - fn: 19334.0000 - accuracy: 0.8925 - precision: 0.7871 - recall: 0.7808 - auc: 0.9563 - prc: 0.8708\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2254 - tp: 68933.0000 - fp: 18767.0000 - tn: 246060.0000 - fn: 19250.0000 - accuracy: 0.8923 - precision: 0.7860 - recall: 0.7817 - auc: 0.9564 - prc: 0.8713\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2254 - tp: 68887.0000 - fp: 18665.0000 - tn: 246162.0000 - fn: 19296.0000 - accuracy: 0.8925 - precision: 0.7868 - recall: 0.7812 - auc: 0.9565 - prc: 0.8711\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2248 - tp: 68839.0000 - fp: 18429.0000 - tn: 246398.0000 - fn: 19344.0000 - accuracy: 0.8930 - precision: 0.7888 - recall: 0.7806 - auc: 0.9566 - prc: 0.8723\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2481 - tp: 134308.0000 - fp: 37984.0000 - tn: 491670.0000 - fn: 42058.0000 - accuracy: 0.8866 - precision: 0.7795 - recall: 0.7615 - auc: 0.9517 - prc: 0.8579\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2390 - tp: 66610.0000 - fp: 19131.0000 - tn: 245696.0000 - fn: 21573.0000 - accuracy: 0.8847 - precision: 0.7769 - recall: 0.7554 - auc: 0.9504 - prc: 0.8534\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2371 - tp: 66709.0000 - fp: 18768.0000 - tn: 246059.0000 - fn: 21474.0000 - accuracy: 0.8860 - precision: 0.7804 - recall: 0.7565 - auc: 0.9513 - prc: 0.8555\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2354 - tp: 67162.0000 - fp: 18806.0000 - tn: 246021.0000 - fn: 21021.0000 - accuracy: 0.8872 - precision: 0.7812 - recall: 0.7616 - auc: 0.9520 - prc: 0.8584\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2343 - tp: 67088.0000 - fp: 18724.0000 - tn: 246103.0000 - fn: 21095.0000 - accuracy: 0.8872 - precision: 0.7818 - recall: 0.7608 - auc: 0.9525 - prc: 0.8596\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2334 - tp: 67482.0000 - fp: 18762.0000 - tn: 246065.0000 - fn: 20701.0000 - accuracy: 0.8882 - precision: 0.7825 - recall: 0.7652 - auc: 0.9529 - prc: 0.8611\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2326 - tp: 67499.0000 - fp: 18813.0000 - tn: 246014.0000 - fn: 20684.0000 - accuracy: 0.8881 - precision: 0.7820 - recall: 0.7654 - auc: 0.9533 - prc: 0.8619\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2320 - tp: 67473.0000 - fp: 18421.0000 - tn: 246406.0000 - fn: 20710.0000 - accuracy: 0.8892 - precision: 0.7855 - recall: 0.7651 - auc: 0.9535 - prc: 0.8630\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2315 - tp: 67459.0000 - fp: 18423.0000 - tn: 246404.0000 - fn: 20724.0000 - accuracy: 0.8891 - precision: 0.7855 - recall: 0.7650 - auc: 0.9538 - prc: 0.8636\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2311 - tp: 67692.0000 - fp: 18535.0000 - tn: 246292.0000 - fn: 20491.0000 - accuracy: 0.8894 - precision: 0.7850 - recall: 0.7676 - auc: 0.9539 - prc: 0.8641\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2307 - tp: 67576.0000 - fp: 18427.0000 - tn: 246400.0000 - fn: 20607.0000 - accuracy: 0.8894 - precision: 0.7857 - recall: 0.7663 - auc: 0.9542 - prc: 0.8649\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2301 - tp: 67915.0000 - fp: 18542.0000 - tn: 246285.0000 - fn: 20268.0000 - accuracy: 0.8901 - precision: 0.7855 - recall: 0.7702 - auc: 0.9544 - prc: 0.8654\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2299 - tp: 68115.0000 - fp: 18753.0000 - tn: 246074.0000 - fn: 20068.0000 - accuracy: 0.8900 - precision: 0.7841 - recall: 0.7724 - auc: 0.9545 - prc: 0.8659\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2295 - tp: 68124.0000 - fp: 18731.0000 - tn: 246096.0000 - fn: 20059.0000 - accuracy: 0.8901 - precision: 0.7843 - recall: 0.7725 - auc: 0.9546 - prc: 0.8660\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2288 - tp: 67992.0000 - fp: 18559.0000 - tn: 246268.0000 - fn: 20191.0000 - accuracy: 0.8902 - precision: 0.7856 - recall: 0.7710 - auc: 0.9549 - prc: 0.8673\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2289 - tp: 68224.0000 - fp: 18606.0000 - tn: 246221.0000 - fn: 19959.0000 - accuracy: 0.8908 - precision: 0.7857 - recall: 0.7737 - auc: 0.9549 - prc: 0.8668\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2283 - tp: 67980.0000 - fp: 18148.0000 - tn: 246679.0000 - fn: 20203.0000 - accuracy: 0.8914 - precision: 0.7893 - recall: 0.7709 - auc: 0.9552 - prc: 0.8678\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2278 - tp: 67954.0000 - fp: 18296.0000 - tn: 246531.0000 - fn: 20229.0000 - accuracy: 0.8909 - precision: 0.7879 - recall: 0.7706 - auc: 0.9554 - prc: 0.8685\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2278 - tp: 68366.0000 - fp: 18504.0000 - tn: 246323.0000 - fn: 19817.0000 - accuracy: 0.8914 - precision: 0.7870 - recall: 0.7753 - auc: 0.9554 - prc: 0.8684\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2275 - tp: 68335.0000 - fp: 18421.0000 - tn: 246406.0000 - fn: 19848.0000 - accuracy: 0.8916 - precision: 0.7877 - recall: 0.7749 - auc: 0.9555 - prc: 0.8689\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2269 - tp: 68502.0000 - fp: 18485.0000 - tn: 246342.0000 - fn: 19681.0000 - accuracy: 0.8919 - precision: 0.7875 - recall: 0.7768 - auc: 0.9558 - prc: 0.8694\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2268 - tp: 68376.0000 - fp: 18384.0000 - tn: 246443.0000 - fn: 19807.0000 - accuracy: 0.8918 - precision: 0.7881 - recall: 0.7754 - auc: 0.9558 - prc: 0.8697\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2266 - tp: 68298.0000 - fp: 18211.0000 - tn: 246616.0000 - fn: 19885.0000 - accuracy: 0.8921 - precision: 0.7895 - recall: 0.7745 - auc: 0.9559 - prc: 0.8699\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2264 - tp: 68284.0000 - fp: 18237.0000 - tn: 246590.0000 - fn: 19899.0000 - accuracy: 0.8920 - precision: 0.7892 - recall: 0.7743 - auc: 0.9560 - prc: 0.8701\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2259 - tp: 68488.0000 - fp: 18379.0000 - tn: 246448.0000 - fn: 19695.0000 - accuracy: 0.8921 - precision: 0.7884 - recall: 0.7767 - auc: 0.9562 - prc: 0.8707\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2258 - tp: 68431.0000 - fp: 18187.0000 - tn: 246640.0000 - fn: 19752.0000 - accuracy: 0.8925 - precision: 0.7900 - recall: 0.7760 - auc: 0.9563 - prc: 0.8710\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2256 - tp: 68595.0000 - fp: 18283.0000 - tn: 246544.0000 - fn: 19588.0000 - accuracy: 0.8927 - precision: 0.7896 - recall: 0.7779 - auc: 0.9563 - prc: 0.8714\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2251 - tp: 68658.0000 - fp: 18284.0000 - tn: 246543.0000 - fn: 19525.0000 - accuracy: 0.8929 - precision: 0.7897 - recall: 0.7786 - auc: 0.9565 - prc: 0.8717\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2249 - tp: 68780.0000 - fp: 18312.0000 - tn: 246515.0000 - fn: 19403.0000 - accuracy: 0.8932 - precision: 0.7897 - recall: 0.7800 - auc: 0.9566 - prc: 0.8719\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2248 - tp: 68589.0000 - fp: 18236.0000 - tn: 246591.0000 - fn: 19594.0000 - accuracy: 0.8928 - precision: 0.7900 - recall: 0.7778 - auc: 0.9567 - prc: 0.8721\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2481 - tp: 134075.0000 - fp: 37918.0000 - tn: 491736.0000 - fn: 42291.0000 - accuracy: 0.8864 - precision: 0.7795 - recall: 0.7602 - auc: 0.9517 - prc: 0.8576\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2388 - tp: 66278.0000 - fp: 18731.0000 - tn: 246096.0000 - fn: 21905.0000 - accuracy: 0.8849 - precision: 0.7797 - recall: 0.7516 - auc: 0.9505 - prc: 0.8535\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2369 - tp: 66568.0000 - fp: 18612.0000 - tn: 246215.0000 - fn: 21615.0000 - accuracy: 0.8860 - precision: 0.7815 - recall: 0.7549 - auc: 0.9513 - prc: 0.8562\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2355 - tp: 66704.0000 - fp: 18548.0000 - tn: 246279.0000 - fn: 21479.0000 - accuracy: 0.8866 - precision: 0.7824 - recall: 0.7564 - auc: 0.9520 - prc: 0.8583\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2345 - tp: 66906.0000 - fp: 18565.0000 - tn: 246262.0000 - fn: 21277.0000 - accuracy: 0.8871 - precision: 0.7828 - recall: 0.7587 - auc: 0.9524 - prc: 0.8598\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2338 - tp: 66994.0000 - fp: 18487.0000 - tn: 246340.0000 - fn: 21189.0000 - accuracy: 0.8876 - precision: 0.7837 - recall: 0.7597 - auc: 0.9527 - prc: 0.8607\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2330 - tp: 67083.0000 - fp: 18417.0000 - tn: 246410.0000 - fn: 21100.0000 - accuracy: 0.8881 - precision: 0.7846 - recall: 0.7607 - auc: 0.9530 - prc: 0.8619\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2323 - tp: 67437.0000 - fp: 18590.0000 - tn: 246237.0000 - fn: 20746.0000 - accuracy: 0.8886 - precision: 0.7839 - recall: 0.7647 - auc: 0.9534 - prc: 0.8626\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2316 - tp: 67415.0000 - fp: 18536.0000 - tn: 246291.0000 - fn: 20768.0000 - accuracy: 0.8887 - precision: 0.7843 - recall: 0.7645 - auc: 0.9537 - prc: 0.8634\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2312 - tp: 67447.0000 - fp: 18494.0000 - tn: 246333.0000 - fn: 20736.0000 - accuracy: 0.8889 - precision: 0.7848 - recall: 0.7649 - auc: 0.9539 - prc: 0.8642\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2309 - tp: 67616.0000 - fp: 18513.0000 - tn: 246314.0000 - fn: 20567.0000 - accuracy: 0.8893 - precision: 0.7851 - recall: 0.7668 - auc: 0.9540 - prc: 0.8646\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2306 - tp: 67780.0000 - fp: 18568.0000 - tn: 246259.0000 - fn: 20403.0000 - accuracy: 0.8896 - precision: 0.7850 - recall: 0.7686 - auc: 0.9542 - prc: 0.8649\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2301 - tp: 67839.0000 - fp: 18594.0000 - tn: 246233.0000 - fn: 20344.0000 - accuracy: 0.8897 - precision: 0.7849 - recall: 0.7693 - auc: 0.9544 - prc: 0.8653\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2296 - tp: 68105.0000 - fp: 18649.0000 - tn: 246178.0000 - fn: 20078.0000 - accuracy: 0.8903 - precision: 0.7850 - recall: 0.7723 - auc: 0.9546 - prc: 0.8661\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2292 - tp: 68197.0000 - fp: 18673.0000 - tn: 246154.0000 - fn: 19986.0000 - accuracy: 0.8905 - precision: 0.7850 - recall: 0.7734 - auc: 0.9548 - prc: 0.8664\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2290 - tp: 67863.0000 - fp: 18430.0000 - tn: 246397.0000 - fn: 20320.0000 - accuracy: 0.8902 - precision: 0.7864 - recall: 0.7696 - auc: 0.9548 - prc: 0.8668\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2287 - tp: 67702.0000 - fp: 18149.0000 - tn: 246678.0000 - fn: 20481.0000 - accuracy: 0.8906 - precision: 0.7886 - recall: 0.7677 - auc: 0.9549 - prc: 0.8675\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2284 - tp: 68113.0000 - fp: 18485.0000 - tn: 246342.0000 - fn: 20070.0000 - accuracy: 0.8908 - precision: 0.7865 - recall: 0.7724 - auc: 0.9551 - prc: 0.8677\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2283 - tp: 68012.0000 - fp: 18269.0000 - tn: 246558.0000 - fn: 20171.0000 - accuracy: 0.8911 - precision: 0.7883 - recall: 0.7713 - auc: 0.9552 - prc: 0.8677\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2278 - tp: 68240.0000 - fp: 18504.0000 - tn: 246323.0000 - fn: 19943.0000 - accuracy: 0.8911 - precision: 0.7867 - recall: 0.7738 - auc: 0.9554 - prc: 0.8686\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2276 - tp: 68021.0000 - fp: 18272.0000 - tn: 246555.0000 - fn: 20162.0000 - accuracy: 0.8911 - precision: 0.7883 - recall: 0.7714 - auc: 0.9555 - prc: 0.8687\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2276 - tp: 68172.0000 - fp: 18458.0000 - tn: 246369.0000 - fn: 20011.0000 - accuracy: 0.8910 - precision: 0.7869 - recall: 0.7731 - auc: 0.9554 - prc: 0.8684\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2272 - tp: 68568.0000 - fp: 18578.0000 - tn: 246249.0000 - fn: 19615.0000 - accuracy: 0.8918 - precision: 0.7868 - recall: 0.7776 - auc: 0.9557 - prc: 0.8690\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2269 - tp: 68143.0000 - fp: 18205.0000 - tn: 246622.0000 - fn: 20040.0000 - accuracy: 0.8917 - precision: 0.7892 - recall: 0.7727 - auc: 0.9558 - prc: 0.8696\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2265 - tp: 68272.0000 - fp: 18259.0000 - tn: 246568.0000 - fn: 19911.0000 - accuracy: 0.8919 - precision: 0.7890 - recall: 0.7742 - auc: 0.9559 - prc: 0.8702\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2261 - tp: 68432.0000 - fp: 18471.0000 - tn: 246356.0000 - fn: 19751.0000 - accuracy: 0.8917 - precision: 0.7875 - recall: 0.7760 - auc: 0.9561 - prc: 0.8705\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2259 - tp: 68719.0000 - fp: 18578.0000 - tn: 246249.0000 - fn: 19464.0000 - accuracy: 0.8922 - precision: 0.7872 - recall: 0.7793 - auc: 0.9562 - prc: 0.8710\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2256 - tp: 68731.0000 - fp: 18588.0000 - tn: 246239.0000 - fn: 19452.0000 - accuracy: 0.8922 - precision: 0.7871 - recall: 0.7794 - auc: 0.9563 - prc: 0.8712\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2254 - tp: 68637.0000 - fp: 18451.0000 - tn: 246376.0000 - fn: 19546.0000 - accuracy: 0.8924 - precision: 0.7881 - recall: 0.7783 - auc: 0.9564 - prc: 0.8715\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2251 - tp: 68767.0000 - fp: 18545.0000 - tn: 246282.0000 - fn: 19416.0000 - accuracy: 0.8925 - precision: 0.7876 - recall: 0.7798 - auc: 0.9565 - prc: 0.8715\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2483 - tp: 134238.0000 - fp: 38296.0000 - tn: 491358.0000 - fn: 42128.0000 - accuracy: 0.8861 - precision: 0.7780 - recall: 0.7611 - auc: 0.9515 - prc: 0.8571\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2392 - tp: 66458.0000 - fp: 19021.0000 - tn: 245806.0000 - fn: 21725.0000 - accuracy: 0.8846 - precision: 0.7775 - recall: 0.7536 - auc: 0.9503 - prc: 0.8530\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2364 - tp: 66913.0000 - fp: 18780.0000 - tn: 246047.0000 - fn: 21270.0000 - accuracy: 0.8865 - precision: 0.7808 - recall: 0.7588 - auc: 0.9515 - prc: 0.8569\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2355 - tp: 67052.0000 - fp: 18842.0000 - tn: 245985.0000 - fn: 21131.0000 - accuracy: 0.8868 - precision: 0.7806 - recall: 0.7604 - auc: 0.9519 - prc: 0.8586\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2342 - tp: 67258.0000 - fp: 18767.0000 - tn: 246060.0000 - fn: 20925.0000 - accuracy: 0.8876 - precision: 0.7818 - recall: 0.7627 - auc: 0.9526 - prc: 0.8599\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2336 - tp: 67443.0000 - fp: 18855.0000 - tn: 245972.0000 - fn: 20740.0000 - accuracy: 0.8878 - precision: 0.7815 - recall: 0.7648 - auc: 0.9528 - prc: 0.8609\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2326 - tp: 67431.0000 - fp: 18741.0000 - tn: 246086.0000 - fn: 20752.0000 - accuracy: 0.8881 - precision: 0.7825 - recall: 0.7647 - auc: 0.9532 - prc: 0.8623\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2322 - tp: 67348.0000 - fp: 18622.0000 - tn: 246205.0000 - fn: 20835.0000 - accuracy: 0.8882 - precision: 0.7834 - recall: 0.7637 - auc: 0.9534 - prc: 0.8628\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2315 - tp: 67585.0000 - fp: 18613.0000 - tn: 246214.0000 - fn: 20598.0000 - accuracy: 0.8889 - precision: 0.7841 - recall: 0.7664 - auc: 0.9537 - prc: 0.8637\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2311 - tp: 67784.0000 - fp: 18644.0000 - tn: 246183.0000 - fn: 20399.0000 - accuracy: 0.8894 - precision: 0.7843 - recall: 0.7687 - auc: 0.9539 - prc: 0.8642\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2308 - tp: 67771.0000 - fp: 18584.0000 - tn: 246243.0000 - fn: 20412.0000 - accuracy: 0.8895 - precision: 0.7848 - recall: 0.7685 - auc: 0.9541 - prc: 0.8646\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2302 - tp: 67878.0000 - fp: 18569.0000 - tn: 246258.0000 - fn: 20305.0000 - accuracy: 0.8899 - precision: 0.7852 - recall: 0.7697 - auc: 0.9543 - prc: 0.8654\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2297 - tp: 67920.0000 - fp: 18552.0000 - tn: 246275.0000 - fn: 20263.0000 - accuracy: 0.8900 - precision: 0.7855 - recall: 0.7702 - auc: 0.9545 - prc: 0.8661\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2294 - tp: 68082.0000 - fp: 18570.0000 - tn: 246257.0000 - fn: 20101.0000 - accuracy: 0.8905 - precision: 0.7857 - recall: 0.7721 - auc: 0.9547 - prc: 0.8668\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2290 - tp: 68035.0000 - fp: 18364.0000 - tn: 246463.0000 - fn: 20148.0000 - accuracy: 0.8909 - precision: 0.7875 - recall: 0.7715 - auc: 0.9548 - prc: 0.8668\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2288 - tp: 68318.0000 - fp: 18745.0000 - tn: 246082.0000 - fn: 19865.0000 - accuracy: 0.8906 - precision: 0.7847 - recall: 0.7747 - auc: 0.9549 - prc: 0.8670\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2284 - tp: 67974.0000 - fp: 18364.0000 - tn: 246463.0000 - fn: 20209.0000 - accuracy: 0.8907 - precision: 0.7873 - recall: 0.7708 - auc: 0.9551 - prc: 0.8677\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2284 - tp: 68044.0000 - fp: 18430.0000 - tn: 246397.0000 - fn: 20139.0000 - accuracy: 0.8907 - precision: 0.7869 - recall: 0.7716 - auc: 0.9551 - prc: 0.8679\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2282 - tp: 67999.0000 - fp: 18297.0000 - tn: 246530.0000 - fn: 20184.0000 - accuracy: 0.8910 - precision: 0.7880 - recall: 0.7711 - auc: 0.9552 - prc: 0.8681\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2276 - tp: 68323.0000 - fp: 18536.0000 - tn: 246291.0000 - fn: 19860.0000 - accuracy: 0.8912 - precision: 0.7866 - recall: 0.7748 - auc: 0.9555 - prc: 0.8688\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2274 - tp: 68231.0000 - fp: 18276.0000 - tn: 246551.0000 - fn: 19952.0000 - accuracy: 0.8917 - precision: 0.7887 - recall: 0.7737 - auc: 0.9555 - prc: 0.8691\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2272 - tp: 68350.0000 - fp: 18439.0000 - tn: 246388.0000 - fn: 19833.0000 - accuracy: 0.8916 - precision: 0.7875 - recall: 0.7751 - auc: 0.9557 - prc: 0.8696\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2267 - tp: 68265.0000 - fp: 18315.0000 - tn: 246512.0000 - fn: 19918.0000 - accuracy: 0.8917 - precision: 0.7885 - recall: 0.7741 - auc: 0.9558 - prc: 0.8697\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2266 - tp: 68498.0000 - fp: 18467.0000 - tn: 246360.0000 - fn: 19685.0000 - accuracy: 0.8919 - precision: 0.7877 - recall: 0.7768 - auc: 0.9559 - prc: 0.8702\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2262 - tp: 68636.0000 - fp: 18423.0000 - tn: 246404.0000 - fn: 19547.0000 - accuracy: 0.8924 - precision: 0.7884 - recall: 0.7783 - auc: 0.9561 - prc: 0.8705\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2261 - tp: 68487.0000 - fp: 18279.0000 - tn: 246548.0000 - fn: 19696.0000 - accuracy: 0.8924 - precision: 0.7893 - recall: 0.7766 - auc: 0.9561 - prc: 0.8705\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2258 - tp: 68440.0000 - fp: 18095.0000 - tn: 246732.0000 - fn: 19743.0000 - accuracy: 0.8928 - precision: 0.7909 - recall: 0.7761 - auc: 0.9562 - prc: 0.8710\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2256 - tp: 68770.0000 - fp: 18383.0000 - tn: 246444.0000 - fn: 19413.0000 - accuracy: 0.8929 - precision: 0.7891 - recall: 0.7799 - auc: 0.9563 - prc: 0.8710\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2251 - tp: 68791.0000 - fp: 18412.0000 - tn: 246415.0000 - fn: 19392.0000 - accuracy: 0.8929 - precision: 0.7889 - recall: 0.7801 - auc: 0.9565 - prc: 0.8717\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2250 - tp: 68600.0000 - fp: 18204.0000 - tn: 246623.0000 - fn: 19583.0000 - accuracy: 0.8930 - precision: 0.7903 - recall: 0.7779 - auc: 0.9566 - prc: 0.8720\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2481 - tp: 133869.0000 - fp: 37677.0000 - tn: 491977.0000 - fn: 42497.0000 - accuracy: 0.8864 - precision: 0.7804 - recall: 0.7590 - auc: 0.9516 - prc: 0.8575\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2391 - tp: 66280.0000 - fp: 18892.0000 - tn: 245935.0000 - fn: 21903.0000 - accuracy: 0.8844 - precision: 0.7782 - recall: 0.7516 - auc: 0.9503 - prc: 0.8526\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2371 - tp: 66801.0000 - fp: 18868.0000 - tn: 245959.0000 - fn: 21382.0000 - accuracy: 0.8860 - precision: 0.7798 - recall: 0.7575 - auc: 0.9512 - prc: 0.8560\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2355 - tp: 66785.0000 - fp: 18520.0000 - tn: 246307.0000 - fn: 21398.0000 - accuracy: 0.8869 - precision: 0.7829 - recall: 0.7573 - auc: 0.9520 - prc: 0.8582\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2345 - tp: 67314.0000 - fp: 18959.0000 - tn: 245868.0000 - fn: 20869.0000 - accuracy: 0.8872 - precision: 0.7802 - recall: 0.7633 - auc: 0.9524 - prc: 0.8597\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2334 - tp: 67372.0000 - fp: 18665.0000 - tn: 246162.0000 - fn: 20811.0000 - accuracy: 0.8882 - precision: 0.7831 - recall: 0.7640 - auc: 0.9529 - prc: 0.8614\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2331 - tp: 67462.0000 - fp: 18810.0000 - tn: 246017.0000 - fn: 20721.0000 - accuracy: 0.8880 - precision: 0.7820 - recall: 0.7650 - auc: 0.9530 - prc: 0.8618\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2324 - tp: 67673.0000 - fp: 18919.0000 - tn: 245908.0000 - fn: 20510.0000 - accuracy: 0.8883 - precision: 0.7815 - recall: 0.7674 - auc: 0.9533 - prc: 0.8628\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2315 - tp: 67810.0000 - fp: 18764.0000 - tn: 246063.0000 - fn: 20373.0000 - accuracy: 0.8891 - precision: 0.7833 - recall: 0.7690 - auc: 0.9538 - prc: 0.8637\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2311 - tp: 67854.0000 - fp: 18700.0000 - tn: 246127.0000 - fn: 20329.0000 - accuracy: 0.8894 - precision: 0.7839 - recall: 0.7695 - auc: 0.9539 - prc: 0.8639\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2308 - tp: 68005.0000 - fp: 18854.0000 - tn: 245973.0000 - fn: 20178.0000 - accuracy: 0.8894 - precision: 0.7829 - recall: 0.7712 - auc: 0.9541 - prc: 0.8648\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2304 - tp: 67818.0000 - fp: 18539.0000 - tn: 246288.0000 - fn: 20365.0000 - accuracy: 0.8898 - precision: 0.7853 - recall: 0.7691 - auc: 0.9543 - prc: 0.8654\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2299 - tp: 68185.0000 - fp: 18841.0000 - tn: 245986.0000 - fn: 19998.0000 - accuracy: 0.8900 - precision: 0.7835 - recall: 0.7732 - auc: 0.9545 - prc: 0.8657\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2295 - tp: 68174.0000 - fp: 18791.0000 - tn: 246036.0000 - fn: 20009.0000 - accuracy: 0.8901 - precision: 0.7839 - recall: 0.7731 - auc: 0.9546 - prc: 0.8662\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2292 - tp: 68156.0000 - fp: 18680.0000 - tn: 246147.0000 - fn: 20027.0000 - accuracy: 0.8904 - precision: 0.7849 - recall: 0.7729 - auc: 0.9548 - prc: 0.8671\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2291 - tp: 68162.0000 - fp: 18800.0000 - tn: 246027.0000 - fn: 20021.0000 - accuracy: 0.8900 - precision: 0.7838 - recall: 0.7730 - auc: 0.9548 - prc: 0.8672\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2285 - tp: 68271.0000 - fp: 18546.0000 - tn: 246281.0000 - fn: 19912.0000 - accuracy: 0.8911 - precision: 0.7864 - recall: 0.7742 - auc: 0.9551 - prc: 0.8678\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2282 - tp: 68293.0000 - fp: 18597.0000 - tn: 246230.0000 - fn: 19890.0000 - accuracy: 0.8910 - precision: 0.7860 - recall: 0.7744 - auc: 0.9552 - prc: 0.8679\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2280 - tp: 68267.0000 - fp: 18457.0000 - tn: 246370.0000 - fn: 19916.0000 - accuracy: 0.8913 - precision: 0.7872 - recall: 0.7742 - auc: 0.9552 - prc: 0.8685\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2280 - tp: 68167.0000 - fp: 18487.0000 - tn: 246340.0000 - fn: 20016.0000 - accuracy: 0.8909 - precision: 0.7867 - recall: 0.7730 - auc: 0.9553 - prc: 0.8683\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2274 - tp: 68330.0000 - fp: 18419.0000 - tn: 246408.0000 - fn: 19853.0000 - accuracy: 0.8916 - precision: 0.7877 - recall: 0.7749 - auc: 0.9555 - prc: 0.8691\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2271 - tp: 68297.0000 - fp: 18443.0000 - tn: 246384.0000 - fn: 19886.0000 - accuracy: 0.8914 - precision: 0.7874 - recall: 0.7745 - auc: 0.9556 - prc: 0.8694\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2269 - tp: 68377.0000 - fp: 18497.0000 - tn: 246330.0000 - fn: 19806.0000 - accuracy: 0.8915 - precision: 0.7871 - recall: 0.7754 - auc: 0.9558 - prc: 0.8697\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2264 - tp: 68418.0000 - fp: 18237.0000 - tn: 246590.0000 - fn: 19765.0000 - accuracy: 0.8923 - precision: 0.7895 - recall: 0.7759 - auc: 0.9560 - prc: 0.8703\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2262 - tp: 68353.0000 - fp: 18249.0000 - tn: 246578.0000 - fn: 19830.0000 - accuracy: 0.8921 - precision: 0.7893 - recall: 0.7751 - auc: 0.9561 - prc: 0.8705\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2265 - tp: 68535.0000 - fp: 18348.0000 - tn: 246479.0000 - fn: 19648.0000 - accuracy: 0.8924 - precision: 0.7888 - recall: 0.7772 - auc: 0.9560 - prc: 0.8702\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2261 - tp: 68603.0000 - fp: 18540.0000 - tn: 246287.0000 - fn: 19580.0000 - accuracy: 0.8920 - precision: 0.7872 - recall: 0.7780 - auc: 0.9562 - prc: 0.8705\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2254 - tp: 68712.0000 - fp: 18512.0000 - tn: 246315.0000 - fn: 19471.0000 - accuracy: 0.8924 - precision: 0.7878 - recall: 0.7792 - auc: 0.9564 - prc: 0.8715\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2253 - tp: 68844.0000 - fp: 18321.0000 - tn: 246506.0000 - fn: 19339.0000 - accuracy: 0.8933 - precision: 0.7898 - recall: 0.7807 - auc: 0.9565 - prc: 0.8714\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2253 - tp: 68552.0000 - fp: 18195.0000 - tn: 246632.0000 - fn: 19631.0000 - accuracy: 0.8928 - precision: 0.7903 - recall: 0.7774 - auc: 0.9565 - prc: 0.8717\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2477 - tp: 133934.0000 - fp: 37718.0000 - tn: 491936.0000 - fn: 42432.0000 - accuracy: 0.8865 - precision: 0.7803 - recall: 0.7594 - auc: 0.9516 - prc: 0.8577\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2388 - tp: 66436.0000 - fp: 18976.0000 - tn: 245851.0000 - fn: 21747.0000 - accuracy: 0.8846 - precision: 0.7778 - recall: 0.7534 - auc: 0.9504 - prc: 0.8533\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2366 - tp: 66887.0000 - fp: 18974.0000 - tn: 245853.0000 - fn: 21296.0000 - accuracy: 0.8859 - precision: 0.7790 - recall: 0.7585 - auc: 0.9514 - prc: 0.8565\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2356 - tp: 66950.0000 - fp: 18786.0000 - tn: 246041.0000 - fn: 21233.0000 - accuracy: 0.8866 - precision: 0.7809 - recall: 0.7592 - auc: 0.9519 - prc: 0.8585\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2345 - tp: 67091.0000 - fp: 18705.0000 - tn: 246122.0000 - fn: 21092.0000 - accuracy: 0.8873 - precision: 0.7820 - recall: 0.7608 - auc: 0.9524 - prc: 0.8596\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2336 - tp: 67184.0000 - fp: 18623.0000 - tn: 246204.0000 - fn: 20999.0000 - accuracy: 0.8878 - precision: 0.7830 - recall: 0.7619 - auc: 0.9528 - prc: 0.8610\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2326 - tp: 67166.0000 - fp: 18470.0000 - tn: 246357.0000 - fn: 21017.0000 - accuracy: 0.8881 - precision: 0.7843 - recall: 0.7617 - auc: 0.9532 - prc: 0.8624\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2324 - tp: 67485.0000 - fp: 18735.0000 - tn: 246092.0000 - fn: 20698.0000 - accuracy: 0.8883 - precision: 0.7827 - recall: 0.7653 - auc: 0.9534 - prc: 0.8623\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2318 - tp: 67753.0000 - fp: 18744.0000 - tn: 246083.0000 - fn: 20430.0000 - accuracy: 0.8890 - precision: 0.7833 - recall: 0.7683 - auc: 0.9536 - prc: 0.8635\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2310 - tp: 67673.0000 - fp: 18592.0000 - tn: 246235.0000 - fn: 20510.0000 - accuracy: 0.8892 - precision: 0.7845 - recall: 0.7674 - auc: 0.9539 - prc: 0.8643\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2309 - tp: 67808.0000 - fp: 18679.0000 - tn: 246148.0000 - fn: 20375.0000 - accuracy: 0.8894 - precision: 0.7840 - recall: 0.7689 - auc: 0.9540 - prc: 0.8645\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2306 - tp: 67866.0000 - fp: 18777.0000 - tn: 246050.0000 - fn: 20317.0000 - accuracy: 0.8893 - precision: 0.7833 - recall: 0.7696 - auc: 0.9541 - prc: 0.8650\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2298 - tp: 67900.0000 - fp: 18679.0000 - tn: 246148.0000 - fn: 20283.0000 - accuracy: 0.8896 - precision: 0.7843 - recall: 0.7700 - auc: 0.9545 - prc: 0.8660\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2295 - tp: 68315.0000 - fp: 18846.0000 - tn: 245981.0000 - fn: 19868.0000 - accuracy: 0.8903 - precision: 0.7838 - recall: 0.7747 - auc: 0.9546 - prc: 0.8663\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2291 - tp: 68225.0000 - fp: 18765.0000 - tn: 246062.0000 - fn: 19958.0000 - accuracy: 0.8903 - precision: 0.7843 - recall: 0.7737 - auc: 0.9548 - prc: 0.8669\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2291 - tp: 67996.0000 - fp: 18561.0000 - tn: 246266.0000 - fn: 20187.0000 - accuracy: 0.8902 - precision: 0.7856 - recall: 0.7711 - auc: 0.9548 - prc: 0.8670\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2287 - tp: 68105.0000 - fp: 18503.0000 - tn: 246324.0000 - fn: 20078.0000 - accuracy: 0.8907 - precision: 0.7864 - recall: 0.7723 - auc: 0.9549 - prc: 0.8674\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2284 - tp: 68229.0000 - fp: 18627.0000 - tn: 246200.0000 - fn: 19954.0000 - accuracy: 0.8907 - precision: 0.7855 - recall: 0.7737 - auc: 0.9551 - prc: 0.8679\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2283 - tp: 68250.0000 - fp: 18530.0000 - tn: 246297.0000 - fn: 19933.0000 - accuracy: 0.8910 - precision: 0.7865 - recall: 0.7740 - auc: 0.9551 - prc: 0.8681\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2280 - tp: 68286.0000 - fp: 18576.0000 - tn: 246251.0000 - fn: 19897.0000 - accuracy: 0.8910 - precision: 0.7861 - recall: 0.7744 - auc: 0.9553 - prc: 0.8683\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2275 - tp: 68166.0000 - fp: 18274.0000 - tn: 246553.0000 - fn: 20017.0000 - accuracy: 0.8915 - precision: 0.7886 - recall: 0.7730 - auc: 0.9555 - prc: 0.8689\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2272 - tp: 68247.0000 - fp: 18304.0000 - tn: 246523.0000 - fn: 19936.0000 - accuracy: 0.8917 - precision: 0.7885 - recall: 0.7739 - auc: 0.9557 - prc: 0.8693\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2272 - tp: 68370.0000 - fp: 18562.0000 - tn: 246265.0000 - fn: 19813.0000 - accuracy: 0.8913 - precision: 0.7865 - recall: 0.7753 - auc: 0.9556 - prc: 0.8692\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2269 - tp: 68538.0000 - fp: 18573.0000 - tn: 246254.0000 - fn: 19645.0000 - accuracy: 0.8917 - precision: 0.7868 - recall: 0.7772 - auc: 0.9557 - prc: 0.8697\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2264 - tp: 68517.0000 - fp: 18450.0000 - tn: 246377.0000 - fn: 19666.0000 - accuracy: 0.8920 - precision: 0.7879 - recall: 0.7770 - auc: 0.9560 - prc: 0.8705\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2264 - tp: 68426.0000 - fp: 18380.0000 - tn: 246447.0000 - fn: 19757.0000 - accuracy: 0.8920 - precision: 0.7883 - recall: 0.7760 - auc: 0.9560 - prc: 0.8703\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2261 - tp: 68536.0000 - fp: 18341.0000 - tn: 246486.0000 - fn: 19647.0000 - accuracy: 0.8924 - precision: 0.7889 - recall: 0.7772 - auc: 0.9561 - prc: 0.8706\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2261 - tp: 68714.0000 - fp: 18595.0000 - tn: 246232.0000 - fn: 19469.0000 - accuracy: 0.8922 - precision: 0.7870 - recall: 0.7792 - auc: 0.9561 - prc: 0.8708\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2255 - tp: 68944.0000 - fp: 18669.0000 - tn: 246158.0000 - fn: 19239.0000 - accuracy: 0.8926 - precision: 0.7869 - recall: 0.7818 - auc: 0.9564 - prc: 0.8711\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2251 - tp: 68568.0000 - fp: 18256.0000 - tn: 246571.0000 - fn: 19615.0000 - accuracy: 0.8927 - precision: 0.7897 - recall: 0.7776 - auc: 0.9565 - prc: 0.8716\n",
            "690/690 [==============================] - 1s 1ms/step\n",
            "communication_round: 0 | global_accuracy: 77.243% | global_loss: 0.6573343276977539 | global_AUC: 86.407% | global_G-mean: 76.897%\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2278 - tp: 137164.0000 - fp: 37033.0000 - tn: 492621.0000 - fn: 39202.0000 - accuracy: 0.8920 - precision: 0.7874 - recall: 0.7777 - auc: 0.9559 - prc: 0.8700\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2269 - tp: 68076.0000 - fp: 18116.0000 - tn: 246711.0000 - fn: 20107.0000 - accuracy: 0.8917 - precision: 0.7898 - recall: 0.7720 - auc: 0.9558 - prc: 0.8697\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2268 - tp: 68051.0000 - fp: 18038.0000 - tn: 246789.0000 - fn: 20132.0000 - accuracy: 0.8919 - precision: 0.7905 - recall: 0.7717 - auc: 0.9558 - prc: 0.8697\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2262 - tp: 68299.0000 - fp: 18225.0000 - tn: 246602.0000 - fn: 19884.0000 - accuracy: 0.8920 - precision: 0.7894 - recall: 0.7745 - auc: 0.9561 - prc: 0.8704\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2258 - tp: 68496.0000 - fp: 18203.0000 - tn: 246624.0000 - fn: 19687.0000 - accuracy: 0.8927 - precision: 0.7900 - recall: 0.7767 - auc: 0.9562 - prc: 0.8709\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2253 - tp: 68364.0000 - fp: 18018.0000 - tn: 246809.0000 - fn: 19819.0000 - accuracy: 0.8928 - precision: 0.7914 - recall: 0.7753 - auc: 0.9565 - prc: 0.8716\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2251 - tp: 68263.0000 - fp: 17887.0000 - tn: 246940.0000 - fn: 19920.0000 - accuracy: 0.8929 - precision: 0.7924 - recall: 0.7741 - auc: 0.9566 - prc: 0.8720\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2249 - tp: 68477.0000 - fp: 18074.0000 - tn: 246753.0000 - fn: 19706.0000 - accuracy: 0.8930 - precision: 0.7912 - recall: 0.7765 - auc: 0.9566 - prc: 0.8717\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2245 - tp: 68654.0000 - fp: 18174.0000 - tn: 246653.0000 - fn: 19529.0000 - accuracy: 0.8932 - precision: 0.7907 - recall: 0.7785 - auc: 0.9568 - prc: 0.8722\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2243 - tp: 68673.0000 - fp: 18192.0000 - tn: 246635.0000 - fn: 19510.0000 - accuracy: 0.8932 - precision: 0.7906 - recall: 0.7788 - auc: 0.9569 - prc: 0.8726\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2236 - tp: 68702.0000 - fp: 18016.0000 - tn: 246811.0000 - fn: 19481.0000 - accuracy: 0.8938 - precision: 0.7922 - recall: 0.7791 - auc: 0.9572 - prc: 0.8735\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2234 - tp: 69067.0000 - fp: 18324.0000 - tn: 246503.0000 - fn: 19116.0000 - accuracy: 0.8939 - precision: 0.7903 - recall: 0.7832 - auc: 0.9572 - prc: 0.8739\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2236 - tp: 68827.0000 - fp: 18197.0000 - tn: 246630.0000 - fn: 19356.0000 - accuracy: 0.8936 - precision: 0.7909 - recall: 0.7805 - auc: 0.9572 - prc: 0.8735\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2230 - tp: 69031.0000 - fp: 18423.0000 - tn: 246404.0000 - fn: 19152.0000 - accuracy: 0.8936 - precision: 0.7893 - recall: 0.7828 - auc: 0.9574 - prc: 0.8739\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2227 - tp: 68987.0000 - fp: 18251.0000 - tn: 246576.0000 - fn: 19196.0000 - accuracy: 0.8939 - precision: 0.7908 - recall: 0.7823 - auc: 0.9575 - prc: 0.8742\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2223 - tp: 68991.0000 - fp: 18027.0000 - tn: 246800.0000 - fn: 19192.0000 - accuracy: 0.8946 - precision: 0.7928 - recall: 0.7824 - auc: 0.9577 - prc: 0.8748\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2221 - tp: 69063.0000 - fp: 18062.0000 - tn: 246765.0000 - fn: 19120.0000 - accuracy: 0.8947 - precision: 0.7927 - recall: 0.7832 - auc: 0.9578 - prc: 0.8749\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2216 - tp: 69149.0000 - fp: 18126.0000 - tn: 246701.0000 - fn: 19034.0000 - accuracy: 0.8947 - precision: 0.7923 - recall: 0.7842 - auc: 0.9580 - prc: 0.8756\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2215 - tp: 69267.0000 - fp: 18351.0000 - tn: 246476.0000 - fn: 18916.0000 - accuracy: 0.8944 - precision: 0.7906 - recall: 0.7855 - auc: 0.9580 - prc: 0.8757\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2214 - tp: 69316.0000 - fp: 18298.0000 - tn: 246529.0000 - fn: 18867.0000 - accuracy: 0.8947 - precision: 0.7912 - recall: 0.7860 - auc: 0.9581 - prc: 0.8756\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2208 - tp: 69231.0000 - fp: 18072.0000 - tn: 246755.0000 - fn: 18952.0000 - accuracy: 0.8951 - precision: 0.7930 - recall: 0.7851 - auc: 0.9583 - prc: 0.8765\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2206 - tp: 69415.0000 - fp: 18150.0000 - tn: 246677.0000 - fn: 18768.0000 - accuracy: 0.8954 - precision: 0.7927 - recall: 0.7872 - auc: 0.9584 - prc: 0.8767\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2204 - tp: 69415.0000 - fp: 18165.0000 - tn: 246662.0000 - fn: 18768.0000 - accuracy: 0.8954 - precision: 0.7926 - recall: 0.7872 - auc: 0.9585 - prc: 0.8768\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2201 - tp: 69387.0000 - fp: 18047.0000 - tn: 246780.0000 - fn: 18796.0000 - accuracy: 0.8956 - precision: 0.7936 - recall: 0.7869 - auc: 0.9586 - prc: 0.8771\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2197 - tp: 69413.0000 - fp: 18018.0000 - tn: 246809.0000 - fn: 18770.0000 - accuracy: 0.8958 - precision: 0.7939 - recall: 0.7871 - auc: 0.9587 - prc: 0.8776\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2194 - tp: 69633.0000 - fp: 18217.0000 - tn: 246610.0000 - fn: 18550.0000 - accuracy: 0.8958 - precision: 0.7926 - recall: 0.7896 - auc: 0.9589 - prc: 0.8779\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2195 - tp: 69619.0000 - fp: 18194.0000 - tn: 246633.0000 - fn: 18564.0000 - accuracy: 0.8959 - precision: 0.7928 - recall: 0.7895 - auc: 0.9588 - prc: 0.8777\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2191 - tp: 69528.0000 - fp: 18031.0000 - tn: 246796.0000 - fn: 18655.0000 - accuracy: 0.8961 - precision: 0.7941 - recall: 0.7885 - auc: 0.9590 - prc: 0.8783\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2188 - tp: 69699.0000 - fp: 18074.0000 - tn: 246753.0000 - fn: 18484.0000 - accuracy: 0.8964 - precision: 0.7941 - recall: 0.7904 - auc: 0.9591 - prc: 0.8786\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2185 - tp: 69697.0000 - fp: 18174.0000 - tn: 246653.0000 - fn: 18486.0000 - accuracy: 0.8962 - precision: 0.7932 - recall: 0.7904 - auc: 0.9592 - prc: 0.8790\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2280 - tp: 137998.0000 - fp: 36674.0000 - tn: 492980.0000 - fn: 38368.0000 - accuracy: 0.8937 - precision: 0.7900 - recall: 0.7825 - auc: 0.9573 - prc: 0.8738\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2271 - tp: 68050.0000 - fp: 18171.0000 - tn: 246656.0000 - fn: 20133.0000 - accuracy: 0.8915 - precision: 0.7893 - recall: 0.7717 - auc: 0.9557 - prc: 0.8694\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2267 - tp: 68456.0000 - fp: 18307.0000 - tn: 246520.0000 - fn: 19727.0000 - accuracy: 0.8923 - precision: 0.7890 - recall: 0.7763 - auc: 0.9559 - prc: 0.8701\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2261 - tp: 68559.0000 - fp: 18436.0000 - tn: 246391.0000 - fn: 19624.0000 - accuracy: 0.8922 - precision: 0.7881 - recall: 0.7775 - auc: 0.9561 - prc: 0.8705\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2259 - tp: 68311.0000 - fp: 18186.0000 - tn: 246641.0000 - fn: 19872.0000 - accuracy: 0.8922 - precision: 0.7897 - recall: 0.7747 - auc: 0.9562 - prc: 0.8711\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2255 - tp: 68395.0000 - fp: 18139.0000 - tn: 246688.0000 - fn: 19788.0000 - accuracy: 0.8926 - precision: 0.7904 - recall: 0.7756 - auc: 0.9564 - prc: 0.8714\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2252 - tp: 68480.0000 - fp: 18233.0000 - tn: 246594.0000 - fn: 19703.0000 - accuracy: 0.8925 - precision: 0.7897 - recall: 0.7766 - auc: 0.9565 - prc: 0.8716\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2247 - tp: 68618.0000 - fp: 18035.0000 - tn: 246792.0000 - fn: 19565.0000 - accuracy: 0.8935 - precision: 0.7919 - recall: 0.7781 - auc: 0.9567 - prc: 0.8725\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2243 - tp: 68706.0000 - fp: 18124.0000 - tn: 246703.0000 - fn: 19477.0000 - accuracy: 0.8935 - precision: 0.7913 - recall: 0.7791 - auc: 0.9569 - prc: 0.8728\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2243 - tp: 68865.0000 - fp: 18330.0000 - tn: 246497.0000 - fn: 19318.0000 - accuracy: 0.8934 - precision: 0.7898 - recall: 0.7809 - auc: 0.9569 - prc: 0.8727\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2237 - tp: 68839.0000 - fp: 18289.0000 - tn: 246538.0000 - fn: 19344.0000 - accuracy: 0.8934 - precision: 0.7901 - recall: 0.7806 - auc: 0.9571 - prc: 0.8736\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2237 - tp: 68795.0000 - fp: 18166.0000 - tn: 246661.0000 - fn: 19388.0000 - accuracy: 0.8936 - precision: 0.7911 - recall: 0.7801 - auc: 0.9572 - prc: 0.8734\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2235 - tp: 68951.0000 - fp: 18241.0000 - tn: 246586.0000 - fn: 19232.0000 - accuracy: 0.8938 - precision: 0.7908 - recall: 0.7819 - auc: 0.9572 - prc: 0.8737\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2232 - tp: 68998.0000 - fp: 18207.0000 - tn: 246620.0000 - fn: 19185.0000 - accuracy: 0.8941 - precision: 0.7912 - recall: 0.7824 - auc: 0.9573 - prc: 0.8740\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2225 - tp: 69043.0000 - fp: 18159.0000 - tn: 246668.0000 - fn: 19140.0000 - accuracy: 0.8943 - precision: 0.7918 - recall: 0.7830 - auc: 0.9576 - prc: 0.8750\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2223 - tp: 69167.0000 - fp: 18249.0000 - tn: 246578.0000 - fn: 19016.0000 - accuracy: 0.8944 - precision: 0.7912 - recall: 0.7844 - auc: 0.9577 - prc: 0.8748\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2220 - tp: 69047.0000 - fp: 18196.0000 - tn: 246631.0000 - fn: 19136.0000 - accuracy: 0.8942 - precision: 0.7914 - recall: 0.7830 - auc: 0.9578 - prc: 0.8752\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2219 - tp: 69185.0000 - fp: 18165.0000 - tn: 246662.0000 - fn: 18998.0000 - accuracy: 0.8947 - precision: 0.7920 - recall: 0.7846 - auc: 0.9578 - prc: 0.8754\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2217 - tp: 69276.0000 - fp: 18232.0000 - tn: 246595.0000 - fn: 18907.0000 - accuracy: 0.8948 - precision: 0.7917 - recall: 0.7856 - auc: 0.9580 - prc: 0.8758\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2214 - tp: 69175.0000 - fp: 18031.0000 - tn: 246796.0000 - fn: 19008.0000 - accuracy: 0.8951 - precision: 0.7932 - recall: 0.7844 - auc: 0.9580 - prc: 0.8762\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2209 - tp: 69402.0000 - fp: 18102.0000 - tn: 246725.0000 - fn: 18781.0000 - accuracy: 0.8955 - precision: 0.7931 - recall: 0.7870 - auc: 0.9583 - prc: 0.8763\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2209 - tp: 69191.0000 - fp: 18006.0000 - tn: 246821.0000 - fn: 18992.0000 - accuracy: 0.8952 - precision: 0.7935 - recall: 0.7846 - auc: 0.9582 - prc: 0.8766\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2206 - tp: 69342.0000 - fp: 18124.0000 - tn: 246703.0000 - fn: 18841.0000 - accuracy: 0.8953 - precision: 0.7928 - recall: 0.7863 - auc: 0.9584 - prc: 0.8769\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2201 - tp: 69290.0000 - fp: 17976.0000 - tn: 246851.0000 - fn: 18893.0000 - accuracy: 0.8956 - precision: 0.7940 - recall: 0.7858 - auc: 0.9586 - prc: 0.8775\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2198 - tp: 69577.0000 - fp: 18120.0000 - tn: 246707.0000 - fn: 18606.0000 - accuracy: 0.8960 - precision: 0.7934 - recall: 0.7890 - auc: 0.9587 - prc: 0.8778\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2197 - tp: 69538.0000 - fp: 18026.0000 - tn: 246801.0000 - fn: 18645.0000 - accuracy: 0.8961 - precision: 0.7941 - recall: 0.7886 - auc: 0.9588 - prc: 0.8777\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2195 - tp: 69619.0000 - fp: 18179.0000 - tn: 246648.0000 - fn: 18564.0000 - accuracy: 0.8959 - precision: 0.7929 - recall: 0.7895 - auc: 0.9588 - prc: 0.8780\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2192 - tp: 69410.0000 - fp: 17833.0000 - tn: 246994.0000 - fn: 18773.0000 - accuracy: 0.8963 - precision: 0.7956 - recall: 0.7871 - auc: 0.9590 - prc: 0.8785\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2188 - tp: 69842.0000 - fp: 18200.0000 - tn: 246627.0000 - fn: 18341.0000 - accuracy: 0.8965 - precision: 0.7933 - recall: 0.7920 - auc: 0.9591 - prc: 0.8786\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2189 - tp: 69660.0000 - fp: 18151.0000 - tn: 246676.0000 - fn: 18523.0000 - accuracy: 0.8961 - precision: 0.7933 - recall: 0.7899 - auc: 0.9591 - prc: 0.8783\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2279 - tp: 137915.0000 - fp: 36568.0000 - tn: 493086.0000 - fn: 38451.0000 - accuracy: 0.8937 - precision: 0.7904 - recall: 0.7820 - auc: 0.9572 - prc: 0.8735\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2271 - tp: 68219.0000 - fp: 18279.0000 - tn: 246548.0000 - fn: 19964.0000 - accuracy: 0.8917 - precision: 0.7887 - recall: 0.7736 - auc: 0.9557 - prc: 0.8696\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2267 - tp: 68332.0000 - fp: 18324.0000 - tn: 246503.0000 - fn: 19851.0000 - accuracy: 0.8919 - precision: 0.7885 - recall: 0.7749 - auc: 0.9559 - prc: 0.8698\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2261 - tp: 68552.0000 - fp: 18415.0000 - tn: 246412.0000 - fn: 19631.0000 - accuracy: 0.8922 - precision: 0.7883 - recall: 0.7774 - auc: 0.9561 - prc: 0.8705\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2258 - tp: 68348.0000 - fp: 18042.0000 - tn: 246785.0000 - fn: 19835.0000 - accuracy: 0.8927 - precision: 0.7912 - recall: 0.7751 - auc: 0.9562 - prc: 0.8709\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2256 - tp: 68589.0000 - fp: 18389.0000 - tn: 246438.0000 - fn: 19594.0000 - accuracy: 0.8924 - precision: 0.7886 - recall: 0.7778 - auc: 0.9563 - prc: 0.8713\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2252 - tp: 68690.0000 - fp: 18380.0000 - tn: 246447.0000 - fn: 19493.0000 - accuracy: 0.8927 - precision: 0.7889 - recall: 0.7789 - auc: 0.9565 - prc: 0.8715\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2251 - tp: 68548.0000 - fp: 18266.0000 - tn: 246561.0000 - fn: 19635.0000 - accuracy: 0.8926 - precision: 0.7896 - recall: 0.7773 - auc: 0.9565 - prc: 0.8718\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2245 - tp: 68825.0000 - fp: 18244.0000 - tn: 246583.0000 - fn: 19358.0000 - accuracy: 0.8935 - precision: 0.7905 - recall: 0.7805 - auc: 0.9568 - prc: 0.8724\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2243 - tp: 68894.0000 - fp: 18278.0000 - tn: 246549.0000 - fn: 19289.0000 - accuracy: 0.8936 - precision: 0.7903 - recall: 0.7813 - auc: 0.9569 - prc: 0.8726\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2239 - tp: 69004.0000 - fp: 18328.0000 - tn: 246499.0000 - fn: 19179.0000 - accuracy: 0.8938 - precision: 0.7901 - recall: 0.7825 - auc: 0.9570 - prc: 0.8730\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2236 - tp: 68886.0000 - fp: 18253.0000 - tn: 246574.0000 - fn: 19297.0000 - accuracy: 0.8936 - precision: 0.7905 - recall: 0.7812 - auc: 0.9572 - prc: 0.8734\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2234 - tp: 69014.0000 - fp: 18376.0000 - tn: 246451.0000 - fn: 19169.0000 - accuracy: 0.8936 - precision: 0.7897 - recall: 0.7826 - auc: 0.9572 - prc: 0.8736\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2229 - tp: 68924.0000 - fp: 18141.0000 - tn: 246686.0000 - fn: 19259.0000 - accuracy: 0.8941 - precision: 0.7916 - recall: 0.7816 - auc: 0.9575 - prc: 0.8740\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2229 - tp: 69178.0000 - fp: 18441.0000 - tn: 246386.0000 - fn: 19005.0000 - accuracy: 0.8939 - precision: 0.7895 - recall: 0.7845 - auc: 0.9574 - prc: 0.8742\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2226 - tp: 69204.0000 - fp: 18380.0000 - tn: 246447.0000 - fn: 18979.0000 - accuracy: 0.8942 - precision: 0.7901 - recall: 0.7848 - auc: 0.9576 - prc: 0.8744\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2222 - tp: 69134.0000 - fp: 18182.0000 - tn: 246645.0000 - fn: 19049.0000 - accuracy: 0.8945 - precision: 0.7918 - recall: 0.7840 - auc: 0.9577 - prc: 0.8750\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2219 - tp: 69313.0000 - fp: 18180.0000 - tn: 246647.0000 - fn: 18870.0000 - accuracy: 0.8950 - precision: 0.7922 - recall: 0.7860 - auc: 0.9579 - prc: 0.8754\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2217 - tp: 69320.0000 - fp: 18370.0000 - tn: 246457.0000 - fn: 18863.0000 - accuracy: 0.8945 - precision: 0.7905 - recall: 0.7861 - auc: 0.9580 - prc: 0.8754\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2213 - tp: 69330.0000 - fp: 18307.0000 - tn: 246520.0000 - fn: 18853.0000 - accuracy: 0.8947 - precision: 0.7911 - recall: 0.7862 - auc: 0.9581 - prc: 0.8760\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2213 - tp: 69294.0000 - fp: 18028.0000 - tn: 246799.0000 - fn: 18889.0000 - accuracy: 0.8954 - precision: 0.7935 - recall: 0.7858 - auc: 0.9581 - prc: 0.8761\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2207 - tp: 69376.0000 - fp: 18121.0000 - tn: 246706.0000 - fn: 18807.0000 - accuracy: 0.8954 - precision: 0.7929 - recall: 0.7867 - auc: 0.9584 - prc: 0.8765\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2204 - tp: 69544.0000 - fp: 18255.0000 - tn: 246572.0000 - fn: 18639.0000 - accuracy: 0.8955 - precision: 0.7921 - recall: 0.7886 - auc: 0.9585 - prc: 0.8767\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2202 - tp: 69753.0000 - fp: 18347.0000 - tn: 246480.0000 - fn: 18430.0000 - accuracy: 0.8958 - precision: 0.7917 - recall: 0.7910 - auc: 0.9586 - prc: 0.8771\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2198 - tp: 69626.0000 - fp: 18275.0000 - tn: 246552.0000 - fn: 18557.0000 - accuracy: 0.8957 - precision: 0.7921 - recall: 0.7896 - auc: 0.9587 - prc: 0.8777\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2198 - tp: 69545.0000 - fp: 18253.0000 - tn: 246574.0000 - fn: 18638.0000 - accuracy: 0.8955 - precision: 0.7921 - recall: 0.7886 - auc: 0.9587 - prc: 0.8775\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2195 - tp: 69514.0000 - fp: 18022.0000 - tn: 246805.0000 - fn: 18669.0000 - accuracy: 0.8961 - precision: 0.7941 - recall: 0.7883 - auc: 0.9589 - prc: 0.8779\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2195 - tp: 69763.0000 - fp: 18256.0000 - tn: 246571.0000 - fn: 18420.0000 - accuracy: 0.8961 - precision: 0.7926 - recall: 0.7911 - auc: 0.9588 - prc: 0.8779\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2187 - tp: 69892.0000 - fp: 18164.0000 - tn: 246663.0000 - fn: 18291.0000 - accuracy: 0.8967 - precision: 0.7937 - recall: 0.7926 - auc: 0.9592 - prc: 0.8788\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2187 - tp: 69774.0000 - fp: 18082.0000 - tn: 246745.0000 - fn: 18409.0000 - accuracy: 0.8966 - precision: 0.7942 - recall: 0.7912 - auc: 0.9592 - prc: 0.8787\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2279 - tp: 138085.0000 - fp: 36628.0000 - tn: 493026.0000 - fn: 38281.0000 - accuracy: 0.8939 - precision: 0.7904 - recall: 0.7829 - auc: 0.9573 - prc: 0.8737\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2271 - tp: 68118.0000 - fp: 18184.0000 - tn: 246643.0000 - fn: 20065.0000 - accuracy: 0.8916 - precision: 0.7893 - recall: 0.7725 - auc: 0.9557 - prc: 0.8694\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2268 - tp: 68230.0000 - fp: 18222.0000 - tn: 246605.0000 - fn: 19953.0000 - accuracy: 0.8919 - precision: 0.7892 - recall: 0.7737 - auc: 0.9558 - prc: 0.8699\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2260 - tp: 68385.0000 - fp: 18164.0000 - tn: 246663.0000 - fn: 19798.0000 - accuracy: 0.8925 - precision: 0.7901 - recall: 0.7755 - auc: 0.9562 - prc: 0.8708\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2260 - tp: 68481.0000 - fp: 18395.0000 - tn: 246432.0000 - fn: 19702.0000 - accuracy: 0.8921 - precision: 0.7883 - recall: 0.7766 - auc: 0.9562 - prc: 0.8707\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2255 - tp: 68351.0000 - fp: 17951.0000 - tn: 246876.0000 - fn: 19832.0000 - accuracy: 0.8930 - precision: 0.7920 - recall: 0.7751 - auc: 0.9564 - prc: 0.8716\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2254 - tp: 68693.0000 - fp: 18415.0000 - tn: 246412.0000 - fn: 19490.0000 - accuracy: 0.8926 - precision: 0.7886 - recall: 0.7790 - auc: 0.9564 - prc: 0.8713\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2249 - tp: 68703.0000 - fp: 18303.0000 - tn: 246524.0000 - fn: 19480.0000 - accuracy: 0.8930 - precision: 0.7896 - recall: 0.7791 - auc: 0.9566 - prc: 0.8719\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2245 - tp: 68581.0000 - fp: 18175.0000 - tn: 246652.0000 - fn: 19602.0000 - accuracy: 0.8930 - precision: 0.7905 - recall: 0.7777 - auc: 0.9567 - prc: 0.8724\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2242 - tp: 68743.0000 - fp: 18156.0000 - tn: 246671.0000 - fn: 19440.0000 - accuracy: 0.8935 - precision: 0.7911 - recall: 0.7795 - auc: 0.9569 - prc: 0.8726\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2240 - tp: 68598.0000 - fp: 18014.0000 - tn: 246813.0000 - fn: 19585.0000 - accuracy: 0.8935 - precision: 0.7920 - recall: 0.7779 - auc: 0.9570 - prc: 0.8731\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2234 - tp: 68817.0000 - fp: 18152.0000 - tn: 246675.0000 - fn: 19366.0000 - accuracy: 0.8937 - precision: 0.7913 - recall: 0.7804 - auc: 0.9572 - prc: 0.8736\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2234 - tp: 68930.0000 - fp: 18127.0000 - tn: 246700.0000 - fn: 19253.0000 - accuracy: 0.8941 - precision: 0.7918 - recall: 0.7817 - auc: 0.9573 - prc: 0.8734\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2231 - tp: 68818.0000 - fp: 18128.0000 - tn: 246699.0000 - fn: 19365.0000 - accuracy: 0.8938 - precision: 0.7915 - recall: 0.7804 - auc: 0.9574 - prc: 0.8741\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2227 - tp: 69073.0000 - fp: 18171.0000 - tn: 246656.0000 - fn: 19110.0000 - accuracy: 0.8944 - precision: 0.7917 - recall: 0.7833 - auc: 0.9575 - prc: 0.8742\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2222 - tp: 68978.0000 - fp: 17955.0000 - tn: 246872.0000 - fn: 19205.0000 - accuracy: 0.8947 - precision: 0.7935 - recall: 0.7822 - auc: 0.9578 - prc: 0.8748\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2220 - tp: 69134.0000 - fp: 18163.0000 - tn: 246664.0000 - fn: 19049.0000 - accuracy: 0.8946 - precision: 0.7919 - recall: 0.7840 - auc: 0.9578 - prc: 0.8752\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2220 - tp: 69231.0000 - fp: 18349.0000 - tn: 246478.0000 - fn: 18952.0000 - accuracy: 0.8943 - precision: 0.7905 - recall: 0.7851 - auc: 0.9578 - prc: 0.8751\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2215 - tp: 69342.0000 - fp: 18331.0000 - tn: 246496.0000 - fn: 18841.0000 - accuracy: 0.8947 - precision: 0.7909 - recall: 0.7863 - auc: 0.9580 - prc: 0.8758\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2212 - tp: 69211.0000 - fp: 18202.0000 - tn: 246625.0000 - fn: 18972.0000 - accuracy: 0.8947 - precision: 0.7918 - recall: 0.7849 - auc: 0.9581 - prc: 0.8760\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2209 - tp: 69393.0000 - fp: 18175.0000 - tn: 246652.0000 - fn: 18790.0000 - accuracy: 0.8953 - precision: 0.7924 - recall: 0.7869 - auc: 0.9583 - prc: 0.8764\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2207 - tp: 69313.0000 - fp: 18113.0000 - tn: 246714.0000 - fn: 18870.0000 - accuracy: 0.8952 - precision: 0.7928 - recall: 0.7860 - auc: 0.9583 - prc: 0.8764\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2203 - tp: 69479.0000 - fp: 18035.0000 - tn: 246792.0000 - fn: 18704.0000 - accuracy: 0.8959 - precision: 0.7939 - recall: 0.7879 - auc: 0.9586 - prc: 0.8770\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2199 - tp: 69553.0000 - fp: 18194.0000 - tn: 246633.0000 - fn: 18630.0000 - accuracy: 0.8957 - precision: 0.7927 - recall: 0.7887 - auc: 0.9587 - prc: 0.8775\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2196 - tp: 69482.0000 - fp: 18058.0000 - tn: 246769.0000 - fn: 18701.0000 - accuracy: 0.8959 - precision: 0.7937 - recall: 0.7879 - auc: 0.9588 - prc: 0.8778\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2196 - tp: 69484.0000 - fp: 18174.0000 - tn: 246653.0000 - fn: 18699.0000 - accuracy: 0.8955 - precision: 0.7927 - recall: 0.7880 - auc: 0.9588 - prc: 0.8778\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2195 - tp: 69582.0000 - fp: 18109.0000 - tn: 246718.0000 - fn: 18601.0000 - accuracy: 0.8960 - precision: 0.7935 - recall: 0.7891 - auc: 0.9589 - prc: 0.8780\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2192 - tp: 69646.0000 - fp: 18194.0000 - tn: 246633.0000 - fn: 18537.0000 - accuracy: 0.8959 - precision: 0.7929 - recall: 0.7898 - auc: 0.9589 - prc: 0.8781\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2187 - tp: 69633.0000 - fp: 18117.0000 - tn: 246710.0000 - fn: 18550.0000 - accuracy: 0.8961 - precision: 0.7935 - recall: 0.7896 - auc: 0.9592 - prc: 0.8786\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2184 - tp: 69823.0000 - fp: 18128.0000 - tn: 246699.0000 - fn: 18360.0000 - accuracy: 0.8966 - precision: 0.7939 - recall: 0.7918 - auc: 0.9593 - prc: 0.8788\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2279 - tp: 138411.0000 - fp: 36816.0000 - tn: 492838.0000 - fn: 37955.0000 - accuracy: 0.8941 - precision: 0.7899 - recall: 0.7848 - auc: 0.9573 - prc: 0.8737\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2271 - tp: 68199.0000 - fp: 18143.0000 - tn: 246684.0000 - fn: 19984.0000 - accuracy: 0.8920 - precision: 0.7899 - recall: 0.7734 - auc: 0.9557 - prc: 0.8694\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2264 - tp: 68470.0000 - fp: 18347.0000 - tn: 246480.0000 - fn: 19713.0000 - accuracy: 0.8922 - precision: 0.7887 - recall: 0.7765 - auc: 0.9560 - prc: 0.8703\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2262 - tp: 68514.0000 - fp: 18445.0000 - tn: 246382.0000 - fn: 19669.0000 - accuracy: 0.8920 - precision: 0.7879 - recall: 0.7770 - auc: 0.9561 - prc: 0.8704\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2259 - tp: 68396.0000 - fp: 18215.0000 - tn: 246612.0000 - fn: 19787.0000 - accuracy: 0.8923 - precision: 0.7897 - recall: 0.7756 - auc: 0.9562 - prc: 0.8709\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2258 - tp: 68575.0000 - fp: 18375.0000 - tn: 246452.0000 - fn: 19608.0000 - accuracy: 0.8924 - precision: 0.7887 - recall: 0.7776 - auc: 0.9563 - prc: 0.8711\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2254 - tp: 68601.0000 - fp: 18350.0000 - tn: 246477.0000 - fn: 19582.0000 - accuracy: 0.8925 - precision: 0.7890 - recall: 0.7779 - auc: 0.9565 - prc: 0.8714\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2250 - tp: 68907.0000 - fp: 18523.0000 - tn: 246304.0000 - fn: 19276.0000 - accuracy: 0.8929 - precision: 0.7881 - recall: 0.7814 - auc: 0.9566 - prc: 0.8717\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2244 - tp: 68895.0000 - fp: 18446.0000 - tn: 246381.0000 - fn: 19288.0000 - accuracy: 0.8931 - precision: 0.7888 - recall: 0.7813 - auc: 0.9568 - prc: 0.8727\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2242 - tp: 68786.0000 - fp: 18230.0000 - tn: 246597.0000 - fn: 19397.0000 - accuracy: 0.8934 - precision: 0.7905 - recall: 0.7800 - auc: 0.9569 - prc: 0.8729\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2242 - tp: 68752.0000 - fp: 18205.0000 - tn: 246622.0000 - fn: 19431.0000 - accuracy: 0.8934 - precision: 0.7906 - recall: 0.7797 - auc: 0.9570 - prc: 0.8727\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2236 - tp: 68888.0000 - fp: 18283.0000 - tn: 246544.0000 - fn: 19295.0000 - accuracy: 0.8935 - precision: 0.7903 - recall: 0.7812 - auc: 0.9572 - prc: 0.8737\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2231 - tp: 69147.0000 - fp: 18370.0000 - tn: 246457.0000 - fn: 19036.0000 - accuracy: 0.8940 - precision: 0.7901 - recall: 0.7841 - auc: 0.9574 - prc: 0.8740\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2230 - tp: 68867.0000 - fp: 18073.0000 - tn: 246754.0000 - fn: 19316.0000 - accuracy: 0.8941 - precision: 0.7921 - recall: 0.7810 - auc: 0.9574 - prc: 0.8742\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2228 - tp: 68990.0000 - fp: 18263.0000 - tn: 246564.0000 - fn: 19193.0000 - accuracy: 0.8939 - precision: 0.7907 - recall: 0.7824 - auc: 0.9575 - prc: 0.8743\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2225 - tp: 68959.0000 - fp: 18151.0000 - tn: 246676.0000 - fn: 19224.0000 - accuracy: 0.8941 - precision: 0.7916 - recall: 0.7820 - auc: 0.9576 - prc: 0.8746\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2222 - tp: 68799.0000 - fp: 17947.0000 - tn: 246880.0000 - fn: 19384.0000 - accuracy: 0.8942 - precision: 0.7931 - recall: 0.7802 - auc: 0.9577 - prc: 0.8751\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2218 - tp: 68998.0000 - fp: 18152.0000 - tn: 246675.0000 - fn: 19185.0000 - accuracy: 0.8942 - precision: 0.7917 - recall: 0.7824 - auc: 0.9579 - prc: 0.8753\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2217 - tp: 69283.0000 - fp: 18287.0000 - tn: 246540.0000 - fn: 18900.0000 - accuracy: 0.8947 - precision: 0.7912 - recall: 0.7857 - auc: 0.9579 - prc: 0.8755\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2212 - tp: 69255.0000 - fp: 18231.0000 - tn: 246596.0000 - fn: 18928.0000 - accuracy: 0.8947 - precision: 0.7916 - recall: 0.7854 - auc: 0.9582 - prc: 0.8761\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2208 - tp: 69432.0000 - fp: 18205.0000 - tn: 246622.0000 - fn: 18751.0000 - accuracy: 0.8953 - precision: 0.7923 - recall: 0.7874 - auc: 0.9583 - prc: 0.8764\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2207 - tp: 69269.0000 - fp: 18121.0000 - tn: 246706.0000 - fn: 18914.0000 - accuracy: 0.8951 - precision: 0.7926 - recall: 0.7855 - auc: 0.9583 - prc: 0.8767\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2201 - tp: 69600.0000 - fp: 18359.0000 - tn: 246468.0000 - fn: 18583.0000 - accuracy: 0.8954 - precision: 0.7913 - recall: 0.7893 - auc: 0.9586 - prc: 0.8770\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2203 - tp: 69485.0000 - fp: 18185.0000 - tn: 246642.0000 - fn: 18698.0000 - accuracy: 0.8955 - precision: 0.7926 - recall: 0.7880 - auc: 0.9585 - prc: 0.8769\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2201 - tp: 69525.0000 - fp: 18223.0000 - tn: 246604.0000 - fn: 18658.0000 - accuracy: 0.8955 - precision: 0.7923 - recall: 0.7884 - auc: 0.9586 - prc: 0.8772\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2195 - tp: 69654.0000 - fp: 18143.0000 - tn: 246684.0000 - fn: 18529.0000 - accuracy: 0.8961 - precision: 0.7934 - recall: 0.7899 - auc: 0.9589 - prc: 0.8780\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2192 - tp: 69540.0000 - fp: 18031.0000 - tn: 246796.0000 - fn: 18643.0000 - accuracy: 0.8961 - precision: 0.7941 - recall: 0.7886 - auc: 0.9590 - prc: 0.8784\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2188 - tp: 69576.0000 - fp: 17854.0000 - tn: 246973.0000 - fn: 18607.0000 - accuracy: 0.8967 - precision: 0.7958 - recall: 0.7890 - auc: 0.9591 - prc: 0.8787\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2187 - tp: 69572.0000 - fp: 18025.0000 - tn: 246802.0000 - fn: 18611.0000 - accuracy: 0.8962 - precision: 0.7942 - recall: 0.7890 - auc: 0.9591 - prc: 0.8789\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2183 - tp: 69844.0000 - fp: 18254.0000 - tn: 246573.0000 - fn: 18339.0000 - accuracy: 0.8963 - precision: 0.7928 - recall: 0.7920 - auc: 0.9593 - prc: 0.8790\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2280 - tp: 138394.0000 - fp: 36932.0000 - tn: 492722.0000 - fn: 37972.0000 - accuracy: 0.8939 - precision: 0.7894 - recall: 0.7847 - auc: 0.9573 - prc: 0.8737\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2269 - tp: 68241.0000 - fp: 18251.0000 - tn: 246576.0000 - fn: 19942.0000 - accuracy: 0.8918 - precision: 0.7890 - recall: 0.7739 - auc: 0.9557 - prc: 0.8695\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2266 - tp: 68338.0000 - fp: 18246.0000 - tn: 246581.0000 - fn: 19845.0000 - accuracy: 0.8921 - precision: 0.7893 - recall: 0.7750 - auc: 0.9559 - prc: 0.8699\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2263 - tp: 68583.0000 - fp: 18487.0000 - tn: 246340.0000 - fn: 19600.0000 - accuracy: 0.8921 - precision: 0.7877 - recall: 0.7777 - auc: 0.9560 - prc: 0.8704\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2257 - tp: 68678.0000 - fp: 18463.0000 - tn: 246364.0000 - fn: 19505.0000 - accuracy: 0.8924 - precision: 0.7881 - recall: 0.7788 - auc: 0.9563 - prc: 0.8711\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2253 - tp: 68698.0000 - fp: 18411.0000 - tn: 246416.0000 - fn: 19485.0000 - accuracy: 0.8926 - precision: 0.7886 - recall: 0.7790 - auc: 0.9564 - prc: 0.8715\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2252 - tp: 68692.0000 - fp: 18297.0000 - tn: 246530.0000 - fn: 19491.0000 - accuracy: 0.8930 - precision: 0.7897 - recall: 0.7790 - auc: 0.9565 - prc: 0.8718\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2248 - tp: 68693.0000 - fp: 18374.0000 - tn: 246453.0000 - fn: 19490.0000 - accuracy: 0.8927 - precision: 0.7890 - recall: 0.7790 - auc: 0.9566 - prc: 0.8722\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2243 - tp: 68825.0000 - fp: 18442.0000 - tn: 246385.0000 - fn: 19358.0000 - accuracy: 0.8929 - precision: 0.7887 - recall: 0.7805 - auc: 0.9569 - prc: 0.8726\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2242 - tp: 68818.0000 - fp: 18155.0000 - tn: 246672.0000 - fn: 19365.0000 - accuracy: 0.8937 - precision: 0.7913 - recall: 0.7804 - auc: 0.9569 - prc: 0.8728\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2240 - tp: 68937.0000 - fp: 18422.0000 - tn: 246405.0000 - fn: 19246.0000 - accuracy: 0.8933 - precision: 0.7891 - recall: 0.7817 - auc: 0.9570 - prc: 0.8732\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2235 - tp: 69002.0000 - fp: 18230.0000 - tn: 246597.0000 - fn: 19181.0000 - accuracy: 0.8940 - precision: 0.7910 - recall: 0.7825 - auc: 0.9572 - prc: 0.8736\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2235 - tp: 68915.0000 - fp: 18273.0000 - tn: 246554.0000 - fn: 19268.0000 - accuracy: 0.8937 - precision: 0.7904 - recall: 0.7815 - auc: 0.9572 - prc: 0.8735\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2232 - tp: 68970.0000 - fp: 18237.0000 - tn: 246590.0000 - fn: 19213.0000 - accuracy: 0.8939 - precision: 0.7909 - recall: 0.7821 - auc: 0.9573 - prc: 0.8740\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2229 - tp: 69063.0000 - fp: 18192.0000 - tn: 246635.0000 - fn: 19120.0000 - accuracy: 0.8943 - precision: 0.7915 - recall: 0.7832 - auc: 0.9574 - prc: 0.8742\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2223 - tp: 69141.0000 - fp: 18253.0000 - tn: 246574.0000 - fn: 19042.0000 - accuracy: 0.8944 - precision: 0.7911 - recall: 0.7841 - auc: 0.9577 - prc: 0.8750\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2224 - tp: 69185.0000 - fp: 18113.0000 - tn: 246714.0000 - fn: 18998.0000 - accuracy: 0.8949 - precision: 0.7925 - recall: 0.7846 - auc: 0.9577 - prc: 0.8746\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2218 - tp: 69124.0000 - fp: 18208.0000 - tn: 246619.0000 - fn: 19059.0000 - accuracy: 0.8944 - precision: 0.7915 - recall: 0.7839 - auc: 0.9579 - prc: 0.8756\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2217 - tp: 69061.0000 - fp: 17905.0000 - tn: 246922.0000 - fn: 19122.0000 - accuracy: 0.8951 - precision: 0.7941 - recall: 0.7832 - auc: 0.9580 - prc: 0.8755\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2215 - tp: 69269.0000 - fp: 18097.0000 - tn: 246730.0000 - fn: 18914.0000 - accuracy: 0.8952 - precision: 0.7929 - recall: 0.7855 - auc: 0.9580 - prc: 0.8759\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2212 - tp: 69412.0000 - fp: 18212.0000 - tn: 246615.0000 - fn: 18771.0000 - accuracy: 0.8952 - precision: 0.7922 - recall: 0.7871 - auc: 0.9582 - prc: 0.8763\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2208 - tp: 69281.0000 - fp: 18057.0000 - tn: 246770.0000 - fn: 18902.0000 - accuracy: 0.8953 - precision: 0.7933 - recall: 0.7857 - auc: 0.9583 - prc: 0.8766\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2206 - tp: 69201.0000 - fp: 17912.0000 - tn: 246915.0000 - fn: 18982.0000 - accuracy: 0.8955 - precision: 0.7944 - recall: 0.7847 - auc: 0.9584 - prc: 0.8768\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2203 - tp: 69523.0000 - fp: 18151.0000 - tn: 246676.0000 - fn: 18660.0000 - accuracy: 0.8957 - precision: 0.7930 - recall: 0.7884 - auc: 0.9585 - prc: 0.8771\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2197 - tp: 69630.0000 - fp: 18087.0000 - tn: 246740.0000 - fn: 18553.0000 - accuracy: 0.8962 - precision: 0.7938 - recall: 0.7896 - auc: 0.9588 - prc: 0.8776\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2199 - tp: 69439.0000 - fp: 18121.0000 - tn: 246706.0000 - fn: 18744.0000 - accuracy: 0.8956 - precision: 0.7930 - recall: 0.7874 - auc: 0.9587 - prc: 0.8776\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2193 - tp: 69762.0000 - fp: 18217.0000 - tn: 246610.0000 - fn: 18421.0000 - accuracy: 0.8962 - precision: 0.7929 - recall: 0.7911 - auc: 0.9590 - prc: 0.8781\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2190 - tp: 69669.0000 - fp: 18106.0000 - tn: 246721.0000 - fn: 18514.0000 - accuracy: 0.8963 - precision: 0.7937 - recall: 0.7901 - auc: 0.9591 - prc: 0.8785\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2187 - tp: 69766.0000 - fp: 18159.0000 - tn: 246668.0000 - fn: 18417.0000 - accuracy: 0.8964 - precision: 0.7935 - recall: 0.7912 - auc: 0.9592 - prc: 0.8788\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2184 - tp: 69708.0000 - fp: 18023.0000 - tn: 246804.0000 - fn: 18475.0000 - accuracy: 0.8966 - precision: 0.7946 - recall: 0.7905 - auc: 0.9593 - prc: 0.8791\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2279 - tp: 138089.0000 - fp: 36557.0000 - tn: 493097.0000 - fn: 38277.0000 - accuracy: 0.8940 - precision: 0.7907 - recall: 0.7830 - auc: 0.9573 - prc: 0.8739\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2272 - tp: 68015.0000 - fp: 18103.0000 - tn: 246724.0000 - fn: 20168.0000 - accuracy: 0.8916 - precision: 0.7898 - recall: 0.7713 - auc: 0.9557 - prc: 0.8694\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2267 - tp: 68433.0000 - fp: 18268.0000 - tn: 246559.0000 - fn: 19750.0000 - accuracy: 0.8923 - precision: 0.7893 - recall: 0.7760 - auc: 0.9559 - prc: 0.8700\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2261 - tp: 68435.0000 - fp: 18333.0000 - tn: 246494.0000 - fn: 19748.0000 - accuracy: 0.8921 - precision: 0.7887 - recall: 0.7761 - auc: 0.9561 - prc: 0.8702\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2261 - tp: 68520.0000 - fp: 18394.0000 - tn: 246433.0000 - fn: 19663.0000 - accuracy: 0.8922 - precision: 0.7884 - recall: 0.7770 - auc: 0.9561 - prc: 0.8707\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2253 - tp: 68445.0000 - fp: 18032.0000 - tn: 246795.0000 - fn: 19738.0000 - accuracy: 0.8930 - precision: 0.7915 - recall: 0.7762 - auc: 0.9565 - prc: 0.8716\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2252 - tp: 68554.0000 - fp: 18230.0000 - tn: 246597.0000 - fn: 19629.0000 - accuracy: 0.8928 - precision: 0.7899 - recall: 0.7774 - auc: 0.9565 - prc: 0.8715\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2246 - tp: 68538.0000 - fp: 17890.0000 - tn: 246937.0000 - fn: 19645.0000 - accuracy: 0.8937 - precision: 0.7930 - recall: 0.7772 - auc: 0.9568 - prc: 0.8724\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2244 - tp: 68693.0000 - fp: 18088.0000 - tn: 246739.0000 - fn: 19490.0000 - accuracy: 0.8935 - precision: 0.7916 - recall: 0.7790 - auc: 0.9568 - prc: 0.8725\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2243 - tp: 68680.0000 - fp: 18171.0000 - tn: 246656.0000 - fn: 19503.0000 - accuracy: 0.8933 - precision: 0.7908 - recall: 0.7788 - auc: 0.9569 - prc: 0.8725\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2241 - tp: 68716.0000 - fp: 18086.0000 - tn: 246741.0000 - fn: 19467.0000 - accuracy: 0.8936 - precision: 0.7916 - recall: 0.7792 - auc: 0.9570 - prc: 0.8730\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2236 - tp: 68722.0000 - fp: 17992.0000 - tn: 246835.0000 - fn: 19461.0000 - accuracy: 0.8939 - precision: 0.7925 - recall: 0.7793 - auc: 0.9572 - prc: 0.8739\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2232 - tp: 68984.0000 - fp: 18172.0000 - tn: 246655.0000 - fn: 19199.0000 - accuracy: 0.8941 - precision: 0.7915 - recall: 0.7823 - auc: 0.9573 - prc: 0.8738\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2229 - tp: 68923.0000 - fp: 18111.0000 - tn: 246716.0000 - fn: 19260.0000 - accuracy: 0.8941 - precision: 0.7919 - recall: 0.7816 - auc: 0.9574 - prc: 0.8741\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2229 - tp: 68882.0000 - fp: 18054.0000 - tn: 246773.0000 - fn: 19301.0000 - accuracy: 0.8942 - precision: 0.7923 - recall: 0.7811 - auc: 0.9575 - prc: 0.8743\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2224 - tp: 68792.0000 - fp: 17916.0000 - tn: 246911.0000 - fn: 19391.0000 - accuracy: 0.8943 - precision: 0.7934 - recall: 0.7801 - auc: 0.9577 - prc: 0.8749\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2221 - tp: 69014.0000 - fp: 18054.0000 - tn: 246773.0000 - fn: 19169.0000 - accuracy: 0.8946 - precision: 0.7926 - recall: 0.7826 - auc: 0.9578 - prc: 0.8750\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2217 - tp: 68959.0000 - fp: 17992.0000 - tn: 246835.0000 - fn: 19224.0000 - accuracy: 0.8946 - precision: 0.7931 - recall: 0.7820 - auc: 0.9579 - prc: 0.8755\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2216 - tp: 68797.0000 - fp: 17776.0000 - tn: 247051.0000 - fn: 19386.0000 - accuracy: 0.8947 - precision: 0.7947 - recall: 0.7802 - auc: 0.9580 - prc: 0.8757\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2213 - tp: 69116.0000 - fp: 18002.0000 - tn: 246825.0000 - fn: 19067.0000 - accuracy: 0.8950 - precision: 0.7934 - recall: 0.7838 - auc: 0.9581 - prc: 0.8759\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2211 - tp: 69023.0000 - fp: 17878.0000 - tn: 246949.0000 - fn: 19160.0000 - accuracy: 0.8951 - precision: 0.7943 - recall: 0.7827 - auc: 0.9582 - prc: 0.8760\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2208 - tp: 69219.0000 - fp: 17952.0000 - tn: 246875.0000 - fn: 18964.0000 - accuracy: 0.8954 - precision: 0.7941 - recall: 0.7849 - auc: 0.9583 - prc: 0.8766\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2203 - tp: 69331.0000 - fp: 18045.0000 - tn: 246782.0000 - fn: 18852.0000 - accuracy: 0.8955 - precision: 0.7935 - recall: 0.7862 - auc: 0.9585 - prc: 0.8769\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2204 - tp: 69432.0000 - fp: 18207.0000 - tn: 246620.0000 - fn: 18751.0000 - accuracy: 0.8953 - precision: 0.7923 - recall: 0.7874 - auc: 0.9585 - prc: 0.8765\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2200 - tp: 69536.0000 - fp: 18202.0000 - tn: 246625.0000 - fn: 18647.0000 - accuracy: 0.8956 - precision: 0.7925 - recall: 0.7885 - auc: 0.9586 - prc: 0.8775\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2195 - tp: 69583.0000 - fp: 18168.0000 - tn: 246659.0000 - fn: 18600.0000 - accuracy: 0.8958 - precision: 0.7930 - recall: 0.7891 - auc: 0.9588 - prc: 0.8778\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2195 - tp: 69453.0000 - fp: 18008.0000 - tn: 246819.0000 - fn: 18730.0000 - accuracy: 0.8959 - precision: 0.7941 - recall: 0.7876 - auc: 0.9588 - prc: 0.8780\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2191 - tp: 69563.0000 - fp: 18041.0000 - tn: 246786.0000 - fn: 18620.0000 - accuracy: 0.8961 - precision: 0.7941 - recall: 0.7888 - auc: 0.9590 - prc: 0.8783\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2189 - tp: 69623.0000 - fp: 18104.0000 - tn: 246723.0000 - fn: 18560.0000 - accuracy: 0.8961 - precision: 0.7936 - recall: 0.7895 - auc: 0.9591 - prc: 0.8786\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2186 - tp: 69660.0000 - fp: 18058.0000 - tn: 246769.0000 - fn: 18523.0000 - accuracy: 0.8964 - precision: 0.7941 - recall: 0.7899 - auc: 0.9592 - prc: 0.8787\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2280 - tp: 138347.0000 - fp: 36875.0000 - tn: 492779.0000 - fn: 38019.0000 - accuracy: 0.8939 - precision: 0.7896 - recall: 0.7844 - auc: 0.9573 - prc: 0.8736\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2271 - tp: 68211.0000 - fp: 18266.0000 - tn: 246561.0000 - fn: 19972.0000 - accuracy: 0.8917 - precision: 0.7888 - recall: 0.7735 - auc: 0.9557 - prc: 0.8694\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2266 - tp: 68193.0000 - fp: 18246.0000 - tn: 246581.0000 - fn: 19990.0000 - accuracy: 0.8917 - precision: 0.7889 - recall: 0.7733 - auc: 0.9559 - prc: 0.8700\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2262 - tp: 68729.0000 - fp: 18613.0000 - tn: 246214.0000 - fn: 19454.0000 - accuracy: 0.8922 - precision: 0.7869 - recall: 0.7794 - auc: 0.9560 - prc: 0.8704\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2258 - tp: 68366.0000 - fp: 18129.0000 - tn: 246698.0000 - fn: 19817.0000 - accuracy: 0.8925 - precision: 0.7904 - recall: 0.7753 - auc: 0.9563 - prc: 0.8708\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2253 - tp: 68538.0000 - fp: 18255.0000 - tn: 246572.0000 - fn: 19645.0000 - accuracy: 0.8926 - precision: 0.7897 - recall: 0.7772 - auc: 0.9565 - prc: 0.8716\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2254 - tp: 68675.0000 - fp: 18351.0000 - tn: 246476.0000 - fn: 19508.0000 - accuracy: 0.8928 - precision: 0.7891 - recall: 0.7788 - auc: 0.9564 - prc: 0.8715\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2249 - tp: 68691.0000 - fp: 18249.0000 - tn: 246578.0000 - fn: 19492.0000 - accuracy: 0.8931 - precision: 0.7901 - recall: 0.7790 - auc: 0.9566 - prc: 0.8722\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2244 - tp: 68941.0000 - fp: 18465.0000 - tn: 246362.0000 - fn: 19242.0000 - accuracy: 0.8932 - precision: 0.7887 - recall: 0.7818 - auc: 0.9568 - prc: 0.8727\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2242 - tp: 68754.0000 - fp: 18158.0000 - tn: 246669.0000 - fn: 19429.0000 - accuracy: 0.8935 - precision: 0.7911 - recall: 0.7797 - auc: 0.9570 - prc: 0.8729\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2239 - tp: 68942.0000 - fp: 18262.0000 - tn: 246565.0000 - fn: 19241.0000 - accuracy: 0.8938 - precision: 0.7906 - recall: 0.7818 - auc: 0.9571 - prc: 0.8734\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2235 - tp: 68812.0000 - fp: 18128.0000 - tn: 246699.0000 - fn: 19371.0000 - accuracy: 0.8938 - precision: 0.7915 - recall: 0.7803 - auc: 0.9572 - prc: 0.8736\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2233 - tp: 68955.0000 - fp: 18329.0000 - tn: 246498.0000 - fn: 19228.0000 - accuracy: 0.8936 - precision: 0.7900 - recall: 0.7820 - auc: 0.9573 - prc: 0.8737\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2228 - tp: 69219.0000 - fp: 18466.0000 - tn: 246361.0000 - fn: 18964.0000 - accuracy: 0.8940 - precision: 0.7894 - recall: 0.7849 - auc: 0.9575 - prc: 0.8743\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2227 - tp: 69042.0000 - fp: 18281.0000 - tn: 246546.0000 - fn: 19141.0000 - accuracy: 0.8940 - precision: 0.7907 - recall: 0.7829 - auc: 0.9575 - prc: 0.8741\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2226 - tp: 69124.0000 - fp: 18250.0000 - tn: 246577.0000 - fn: 19059.0000 - accuracy: 0.8943 - precision: 0.7911 - recall: 0.7839 - auc: 0.9576 - prc: 0.8744\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2223 - tp: 69102.0000 - fp: 18126.0000 - tn: 246701.0000 - fn: 19081.0000 - accuracy: 0.8946 - precision: 0.7922 - recall: 0.7836 - auc: 0.9577 - prc: 0.8748\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2219 - tp: 69259.0000 - fp: 18310.0000 - tn: 246517.0000 - fn: 18924.0000 - accuracy: 0.8945 - precision: 0.7909 - recall: 0.7854 - auc: 0.9578 - prc: 0.8757\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2217 - tp: 69312.0000 - fp: 18292.0000 - tn: 246535.0000 - fn: 18871.0000 - accuracy: 0.8947 - precision: 0.7912 - recall: 0.7860 - auc: 0.9580 - prc: 0.8756\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2214 - tp: 69239.0000 - fp: 18128.0000 - tn: 246699.0000 - fn: 18944.0000 - accuracy: 0.8950 - precision: 0.7925 - recall: 0.7852 - auc: 0.9581 - prc: 0.8762\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2210 - tp: 69299.0000 - fp: 18271.0000 - tn: 246556.0000 - fn: 18884.0000 - accuracy: 0.8947 - precision: 0.7914 - recall: 0.7859 - auc: 0.9582 - prc: 0.8764\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2208 - tp: 69440.0000 - fp: 18296.0000 - tn: 246531.0000 - fn: 18743.0000 - accuracy: 0.8951 - precision: 0.7915 - recall: 0.7875 - auc: 0.9583 - prc: 0.8766\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2206 - tp: 69397.0000 - fp: 18173.0000 - tn: 246654.0000 - fn: 18786.0000 - accuracy: 0.8953 - precision: 0.7925 - recall: 0.7870 - auc: 0.9584 - prc: 0.8768\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2202 - tp: 69507.0000 - fp: 18204.0000 - tn: 246623.0000 - fn: 18676.0000 - accuracy: 0.8955 - precision: 0.7925 - recall: 0.7882 - auc: 0.9586 - prc: 0.8774\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2199 - tp: 69505.0000 - fp: 18174.0000 - tn: 246653.0000 - fn: 18678.0000 - accuracy: 0.8956 - precision: 0.7927 - recall: 0.7882 - auc: 0.9586 - prc: 0.8776\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2197 - tp: 69685.0000 - fp: 18241.0000 - tn: 246586.0000 - fn: 18498.0000 - accuracy: 0.8959 - precision: 0.7925 - recall: 0.7902 - auc: 0.9588 - prc: 0.8776\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2197 - tp: 69629.0000 - fp: 18237.0000 - tn: 246590.0000 - fn: 18554.0000 - accuracy: 0.8958 - precision: 0.7924 - recall: 0.7896 - auc: 0.9588 - prc: 0.8775\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2190 - tp: 69740.0000 - fp: 18192.0000 - tn: 246635.0000 - fn: 18443.0000 - accuracy: 0.8962 - precision: 0.7931 - recall: 0.7909 - auc: 0.9591 - prc: 0.8782\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2190 - tp: 69577.0000 - fp: 18057.0000 - tn: 246770.0000 - fn: 18606.0000 - accuracy: 0.8961 - precision: 0.7939 - recall: 0.7890 - auc: 0.9590 - prc: 0.8784\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2189 - tp: 69594.0000 - fp: 17968.0000 - tn: 246859.0000 - fn: 18589.0000 - accuracy: 0.8964 - precision: 0.7948 - recall: 0.7892 - auc: 0.9591 - prc: 0.8786\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2278 - tp: 137901.0000 - fp: 36613.0000 - tn: 493041.0000 - fn: 38465.0000 - accuracy: 0.8937 - precision: 0.7902 - recall: 0.7819 - auc: 0.9573 - prc: 0.8736\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2269 - tp: 68118.0000 - fp: 18170.0000 - tn: 246657.0000 - fn: 20065.0000 - accuracy: 0.8917 - precision: 0.7894 - recall: 0.7725 - auc: 0.9558 - prc: 0.8696\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2265 - tp: 68222.0000 - fp: 18236.0000 - tn: 246591.0000 - fn: 19961.0000 - accuracy: 0.8918 - precision: 0.7891 - recall: 0.7736 - auc: 0.9559 - prc: 0.8703\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2262 - tp: 68324.0000 - fp: 18164.0000 - tn: 246663.0000 - fn: 19859.0000 - accuracy: 0.8923 - precision: 0.7900 - recall: 0.7748 - auc: 0.9560 - prc: 0.8703\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2258 - tp: 68429.0000 - fp: 18069.0000 - tn: 246758.0000 - fn: 19754.0000 - accuracy: 0.8929 - precision: 0.7911 - recall: 0.7760 - auc: 0.9563 - prc: 0.8711\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2255 - tp: 68321.0000 - fp: 18082.0000 - tn: 246745.0000 - fn: 19862.0000 - accuracy: 0.8925 - precision: 0.7907 - recall: 0.7748 - auc: 0.9564 - prc: 0.8713\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2254 - tp: 68632.0000 - fp: 18275.0000 - tn: 246552.0000 - fn: 19551.0000 - accuracy: 0.8928 - precision: 0.7897 - recall: 0.7783 - auc: 0.9564 - prc: 0.8712\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2249 - tp: 68557.0000 - fp: 18132.0000 - tn: 246695.0000 - fn: 19626.0000 - accuracy: 0.8930 - precision: 0.7908 - recall: 0.7774 - auc: 0.9566 - prc: 0.8719\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2245 - tp: 68355.0000 - fp: 17989.0000 - tn: 246838.0000 - fn: 19828.0000 - accuracy: 0.8929 - precision: 0.7917 - recall: 0.7751 - auc: 0.9568 - prc: 0.8725\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2241 - tp: 68654.0000 - fp: 18181.0000 - tn: 246646.0000 - fn: 19529.0000 - accuracy: 0.8932 - precision: 0.7906 - recall: 0.7785 - auc: 0.9570 - prc: 0.8729\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2240 - tp: 68866.0000 - fp: 18284.0000 - tn: 246543.0000 - fn: 19317.0000 - accuracy: 0.8935 - precision: 0.7902 - recall: 0.7809 - auc: 0.9570 - prc: 0.8731\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2236 - tp: 68848.0000 - fp: 18157.0000 - tn: 246670.0000 - fn: 19335.0000 - accuracy: 0.8938 - precision: 0.7913 - recall: 0.7807 - auc: 0.9571 - prc: 0.8734\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2232 - tp: 68897.0000 - fp: 18087.0000 - tn: 246740.0000 - fn: 19286.0000 - accuracy: 0.8941 - precision: 0.7921 - recall: 0.7813 - auc: 0.9573 - prc: 0.8740\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2230 - tp: 68870.0000 - fp: 17984.0000 - tn: 246843.0000 - fn: 19313.0000 - accuracy: 0.8943 - precision: 0.7929 - recall: 0.7810 - auc: 0.9574 - prc: 0.8741\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2226 - tp: 68833.0000 - fp: 17958.0000 - tn: 246869.0000 - fn: 19350.0000 - accuracy: 0.8943 - precision: 0.7931 - recall: 0.7806 - auc: 0.9576 - prc: 0.8747\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2226 - tp: 69015.0000 - fp: 18161.0000 - tn: 246666.0000 - fn: 19168.0000 - accuracy: 0.8943 - precision: 0.7917 - recall: 0.7826 - auc: 0.9576 - prc: 0.8744\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2223 - tp: 68933.0000 - fp: 18048.0000 - tn: 246779.0000 - fn: 19250.0000 - accuracy: 0.8943 - precision: 0.7925 - recall: 0.7817 - auc: 0.9577 - prc: 0.8749\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2216 - tp: 69218.0000 - fp: 18066.0000 - tn: 246761.0000 - fn: 18965.0000 - accuracy: 0.8951 - precision: 0.7930 - recall: 0.7849 - auc: 0.9580 - prc: 0.8753\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2218 - tp: 68947.0000 - fp: 17980.0000 - tn: 246847.0000 - fn: 19236.0000 - accuracy: 0.8946 - precision: 0.7932 - recall: 0.7819 - auc: 0.9579 - prc: 0.8753\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2213 - tp: 69348.0000 - fp: 18255.0000 - tn: 246572.0000 - fn: 18835.0000 - accuracy: 0.8949 - precision: 0.7916 - recall: 0.7864 - auc: 0.9581 - prc: 0.8756\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2211 - tp: 69312.0000 - fp: 18165.0000 - tn: 246662.0000 - fn: 18871.0000 - accuracy: 0.8951 - precision: 0.7923 - recall: 0.7860 - auc: 0.9582 - prc: 0.8759\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2210 - tp: 69449.0000 - fp: 18194.0000 - tn: 246633.0000 - fn: 18734.0000 - accuracy: 0.8954 - precision: 0.7924 - recall: 0.7876 - auc: 0.9582 - prc: 0.8762\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2205 - tp: 69634.0000 - fp: 18380.0000 - tn: 246447.0000 - fn: 18549.0000 - accuracy: 0.8954 - precision: 0.7912 - recall: 0.7897 - auc: 0.9584 - prc: 0.8767\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2202 - tp: 69538.0000 - fp: 18181.0000 - tn: 246646.0000 - fn: 18645.0000 - accuracy: 0.8957 - precision: 0.7927 - recall: 0.7886 - auc: 0.9586 - prc: 0.8772\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2204 - tp: 69460.0000 - fp: 18073.0000 - tn: 246754.0000 - fn: 18723.0000 - accuracy: 0.8958 - precision: 0.7935 - recall: 0.7877 - auc: 0.9585 - prc: 0.8769\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2199 - tp: 69407.0000 - fp: 17897.0000 - tn: 246930.0000 - fn: 18776.0000 - accuracy: 0.8961 - precision: 0.7950 - recall: 0.7871 - auc: 0.9587 - prc: 0.8775\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2195 - tp: 69345.0000 - fp: 17900.0000 - tn: 246927.0000 - fn: 18838.0000 - accuracy: 0.8959 - precision: 0.7948 - recall: 0.7864 - auc: 0.9588 - prc: 0.8781\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2193 - tp: 69617.0000 - fp: 18080.0000 - tn: 246747.0000 - fn: 18566.0000 - accuracy: 0.8962 - precision: 0.7938 - recall: 0.7895 - auc: 0.9589 - prc: 0.8780\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2187 - tp: 69669.0000 - fp: 17972.0000 - tn: 246855.0000 - fn: 18514.0000 - accuracy: 0.8966 - precision: 0.7949 - recall: 0.7901 - auc: 0.9592 - prc: 0.8787\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2186 - tp: 69638.0000 - fp: 17970.0000 - tn: 246857.0000 - fn: 18545.0000 - accuracy: 0.8966 - precision: 0.7949 - recall: 0.7897 - auc: 0.9592 - prc: 0.8788\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2279 - tp: 138295.0000 - fp: 36807.0000 - tn: 492847.0000 - fn: 38071.0000 - accuracy: 0.8939 - precision: 0.7898 - recall: 0.7841 - auc: 0.9573 - prc: 0.8738\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2273 - tp: 68459.0000 - fp: 18702.0000 - tn: 246125.0000 - fn: 19724.0000 - accuracy: 0.8911 - precision: 0.7854 - recall: 0.7763 - auc: 0.9556 - prc: 0.8691\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2265 - tp: 68405.0000 - fp: 18312.0000 - tn: 246515.0000 - fn: 19778.0000 - accuracy: 0.8921 - precision: 0.7888 - recall: 0.7757 - auc: 0.9560 - prc: 0.8699\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2260 - tp: 68622.0000 - fp: 18539.0000 - tn: 246288.0000 - fn: 19561.0000 - accuracy: 0.8921 - precision: 0.7873 - recall: 0.7782 - auc: 0.9562 - prc: 0.8705\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2257 - tp: 68624.0000 - fp: 18494.0000 - tn: 246333.0000 - fn: 19559.0000 - accuracy: 0.8922 - precision: 0.7877 - recall: 0.7782 - auc: 0.9563 - prc: 0.8708\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2253 - tp: 68580.0000 - fp: 18284.0000 - tn: 246543.0000 - fn: 19603.0000 - accuracy: 0.8927 - precision: 0.7895 - recall: 0.7777 - auc: 0.9564 - prc: 0.8714\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2249 - tp: 68554.0000 - fp: 18223.0000 - tn: 246604.0000 - fn: 19629.0000 - accuracy: 0.8928 - precision: 0.7900 - recall: 0.7774 - auc: 0.9566 - prc: 0.8721\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2247 - tp: 68827.0000 - fp: 18360.0000 - tn: 246467.0000 - fn: 19356.0000 - accuracy: 0.8932 - precision: 0.7894 - recall: 0.7805 - auc: 0.9567 - prc: 0.8720\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2247 - tp: 68874.0000 - fp: 18399.0000 - tn: 246428.0000 - fn: 19309.0000 - accuracy: 0.8932 - precision: 0.7892 - recall: 0.7810 - auc: 0.9567 - prc: 0.8722\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2241 - tp: 68873.0000 - fp: 18336.0000 - tn: 246491.0000 - fn: 19310.0000 - accuracy: 0.8934 - precision: 0.7897 - recall: 0.7810 - auc: 0.9570 - prc: 0.8727\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2240 - tp: 68983.0000 - fp: 18335.0000 - tn: 246492.0000 - fn: 19200.0000 - accuracy: 0.8937 - precision: 0.7900 - recall: 0.7823 - auc: 0.9570 - prc: 0.8727\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2236 - tp: 68841.0000 - fp: 18134.0000 - tn: 246693.0000 - fn: 19342.0000 - accuracy: 0.8938 - precision: 0.7915 - recall: 0.7807 - auc: 0.9572 - prc: 0.8735\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2231 - tp: 68846.0000 - fp: 18209.0000 - tn: 246618.0000 - fn: 19337.0000 - accuracy: 0.8936 - precision: 0.7908 - recall: 0.7807 - auc: 0.9573 - prc: 0.8739\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2228 - tp: 68925.0000 - fp: 18070.0000 - tn: 246757.0000 - fn: 19258.0000 - accuracy: 0.8943 - precision: 0.7923 - recall: 0.7816 - auc: 0.9575 - prc: 0.8742\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2228 - tp: 68952.0000 - fp: 18040.0000 - tn: 246787.0000 - fn: 19231.0000 - accuracy: 0.8944 - precision: 0.7926 - recall: 0.7819 - auc: 0.9575 - prc: 0.8745\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2223 - tp: 68803.0000 - fp: 17854.0000 - tn: 246973.0000 - fn: 19380.0000 - accuracy: 0.8945 - precision: 0.7940 - recall: 0.7802 - auc: 0.9577 - prc: 0.8747\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2223 - tp: 68933.0000 - fp: 17990.0000 - tn: 246837.0000 - fn: 19250.0000 - accuracy: 0.8945 - precision: 0.7930 - recall: 0.7817 - auc: 0.9577 - prc: 0.8748\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2216 - tp: 69057.0000 - fp: 18081.0000 - tn: 246746.0000 - fn: 19126.0000 - accuracy: 0.8946 - precision: 0.7925 - recall: 0.7831 - auc: 0.9580 - prc: 0.8758\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2213 - tp: 69219.0000 - fp: 18128.0000 - tn: 246699.0000 - fn: 18964.0000 - accuracy: 0.8949 - precision: 0.7925 - recall: 0.7849 - auc: 0.9581 - prc: 0.8760\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2213 - tp: 69090.0000 - fp: 17850.0000 - tn: 246977.0000 - fn: 19093.0000 - accuracy: 0.8953 - precision: 0.7947 - recall: 0.7835 - auc: 0.9581 - prc: 0.8760\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2213 - tp: 69212.0000 - fp: 18163.0000 - tn: 246664.0000 - fn: 18971.0000 - accuracy: 0.8948 - precision: 0.7921 - recall: 0.7849 - auc: 0.9581 - prc: 0.8760\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2206 - tp: 69354.0000 - fp: 18126.0000 - tn: 246701.0000 - fn: 18829.0000 - accuracy: 0.8953 - precision: 0.7928 - recall: 0.7865 - auc: 0.9584 - prc: 0.8769\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2203 - tp: 69296.0000 - fp: 18067.0000 - tn: 246760.0000 - fn: 18887.0000 - accuracy: 0.8953 - precision: 0.7932 - recall: 0.7858 - auc: 0.9585 - prc: 0.8770\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2201 - tp: 69474.0000 - fp: 18097.0000 - tn: 246730.0000 - fn: 18709.0000 - accuracy: 0.8957 - precision: 0.7933 - recall: 0.7878 - auc: 0.9586 - prc: 0.8773\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2198 - tp: 69430.0000 - fp: 17884.0000 - tn: 246943.0000 - fn: 18753.0000 - accuracy: 0.8962 - precision: 0.7952 - recall: 0.7873 - auc: 0.9587 - prc: 0.8776\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2198 - tp: 69660.0000 - fp: 18206.0000 - tn: 246621.0000 - fn: 18523.0000 - accuracy: 0.8960 - precision: 0.7928 - recall: 0.7899 - auc: 0.9587 - prc: 0.8774\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2195 - tp: 69666.0000 - fp: 18262.0000 - tn: 246565.0000 - fn: 18517.0000 - accuracy: 0.8958 - precision: 0.7923 - recall: 0.7900 - auc: 0.9588 - prc: 0.8778\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2190 - tp: 69529.0000 - fp: 18160.0000 - tn: 246667.0000 - fn: 18654.0000 - accuracy: 0.8957 - precision: 0.7929 - recall: 0.7885 - auc: 0.9590 - prc: 0.8784\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2189 - tp: 69431.0000 - fp: 17947.0000 - tn: 246880.0000 - fn: 18752.0000 - accuracy: 0.8960 - precision: 0.7946 - recall: 0.7874 - auc: 0.9591 - prc: 0.8783\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2186 - tp: 69753.0000 - fp: 18081.0000 - tn: 246746.0000 - fn: 18430.0000 - accuracy: 0.8966 - precision: 0.7941 - recall: 0.7910 - auc: 0.9592 - prc: 0.8787\n",
            "690/690 [==============================] - 1s 1ms/step\n",
            "communication_round: 1 | global_accuracy: 79.162% | global_loss: 0.6357710361480713 | global_AUC: 87.736% | global_G-mean: 79.137%\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2194 - tp: 139080.0000 - fp: 36044.0000 - tn: 493610.0000 - fn: 37286.0000 - accuracy: 0.8961 - precision: 0.7942 - recall: 0.7886 - auc: 0.9590 - prc: 0.8784\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2188 - tp: 69534.0000 - fp: 17989.0000 - tn: 246838.0000 - fn: 18649.0000 - accuracy: 0.8962 - precision: 0.7945 - recall: 0.7885 - auc: 0.9591 - prc: 0.8788\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2190 - tp: 69593.0000 - fp: 18047.0000 - tn: 246780.0000 - fn: 18590.0000 - accuracy: 0.8962 - precision: 0.7941 - recall: 0.7892 - auc: 0.9591 - prc: 0.8787\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2184 - tp: 69710.0000 - fp: 18088.0000 - tn: 246739.0000 - fn: 18473.0000 - accuracy: 0.8964 - precision: 0.7940 - recall: 0.7905 - auc: 0.9593 - prc: 0.8790\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2179 - tp: 69627.0000 - fp: 17868.0000 - tn: 246959.0000 - fn: 18556.0000 - accuracy: 0.8968 - precision: 0.7958 - recall: 0.7896 - auc: 0.9595 - prc: 0.8796\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2181 - tp: 69839.0000 - fp: 18194.0000 - tn: 246633.0000 - fn: 18344.0000 - accuracy: 0.8965 - precision: 0.7933 - recall: 0.7920 - auc: 0.9594 - prc: 0.8794\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2175 - tp: 69785.0000 - fp: 18044.0000 - tn: 246783.0000 - fn: 18398.0000 - accuracy: 0.8968 - precision: 0.7946 - recall: 0.7914 - auc: 0.9597 - prc: 0.8800\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2174 - tp: 69856.0000 - fp: 18014.0000 - tn: 246813.0000 - fn: 18327.0000 - accuracy: 0.8971 - precision: 0.7950 - recall: 0.7922 - auc: 0.9597 - prc: 0.8802\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 32s 6ms/step - loss: 0.2168 - tp: 69999.0000 - fp: 17922.0000 - tn: 246905.0000 - fn: 18184.0000 - accuracy: 0.8977 - precision: 0.7962 - recall: 0.7938 - auc: 0.9599 - prc: 0.8807\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2166 - tp: 70074.0000 - fp: 17980.0000 - tn: 246847.0000 - fn: 18109.0000 - accuracy: 0.8978 - precision: 0.7958 - recall: 0.7946 - auc: 0.9600 - prc: 0.8808\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2166 - tp: 70124.0000 - fp: 18029.0000 - tn: 246798.0000 - fn: 18059.0000 - accuracy: 0.8978 - precision: 0.7955 - recall: 0.7952 - auc: 0.9600 - prc: 0.8806\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2161 - tp: 69954.0000 - fp: 17853.0000 - tn: 246974.0000 - fn: 18229.0000 - accuracy: 0.8978 - precision: 0.7967 - recall: 0.7933 - auc: 0.9602 - prc: 0.8814\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2159 - tp: 70062.0000 - fp: 17796.0000 - tn: 247031.0000 - fn: 18121.0000 - accuracy: 0.8983 - precision: 0.7974 - recall: 0.7945 - auc: 0.9603 - prc: 0.8815\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2158 - tp: 70005.0000 - fp: 17971.0000 - tn: 246856.0000 - fn: 18178.0000 - accuracy: 0.8976 - precision: 0.7957 - recall: 0.7939 - auc: 0.9603 - prc: 0.8818\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2155 - tp: 70200.0000 - fp: 17913.0000 - tn: 246914.0000 - fn: 17983.0000 - accuracy: 0.8983 - precision: 0.7967 - recall: 0.7961 - auc: 0.9605 - prc: 0.8820\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2152 - tp: 70293.0000 - fp: 17995.0000 - tn: 246832.0000 - fn: 17890.0000 - accuracy: 0.8983 - precision: 0.7962 - recall: 0.7971 - auc: 0.9606 - prc: 0.8820\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2148 - tp: 70173.0000 - fp: 17937.0000 - tn: 246890.0000 - fn: 18010.0000 - accuracy: 0.8982 - precision: 0.7964 - recall: 0.7958 - auc: 0.9607 - prc: 0.8826\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2143 - tp: 70382.0000 - fp: 18066.0000 - tn: 246761.0000 - fn: 17801.0000 - accuracy: 0.8984 - precision: 0.7957 - recall: 0.7981 - auc: 0.9609 - prc: 0.8828\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2142 - tp: 70401.0000 - fp: 17898.0000 - tn: 246929.0000 - fn: 17782.0000 - accuracy: 0.8989 - precision: 0.7973 - recall: 0.7984 - auc: 0.9609 - prc: 0.8833\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2138 - tp: 70473.0000 - fp: 17919.0000 - tn: 246908.0000 - fn: 17710.0000 - accuracy: 0.8991 - precision: 0.7973 - recall: 0.7992 - auc: 0.9611 - prc: 0.8839\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2140 - tp: 70317.0000 - fp: 17847.0000 - tn: 246980.0000 - fn: 17866.0000 - accuracy: 0.8988 - precision: 0.7976 - recall: 0.7974 - auc: 0.9610 - prc: 0.8835\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2134 - tp: 70511.0000 - fp: 17889.0000 - tn: 246938.0000 - fn: 17672.0000 - accuracy: 0.8993 - precision: 0.7976 - recall: 0.7996 - auc: 0.9613 - prc: 0.8840\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2134 - tp: 70516.0000 - fp: 17999.0000 - tn: 246828.0000 - fn: 17667.0000 - accuracy: 0.8990 - precision: 0.7967 - recall: 0.7997 - auc: 0.9612 - prc: 0.8840\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2130 - tp: 70471.0000 - fp: 17915.0000 - tn: 246912.0000 - fn: 17712.0000 - accuracy: 0.8991 - precision: 0.7973 - recall: 0.7991 - auc: 0.9614 - prc: 0.8843\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2126 - tp: 70717.0000 - fp: 17928.0000 - tn: 246899.0000 - fn: 17466.0000 - accuracy: 0.8997 - precision: 0.7978 - recall: 0.8019 - auc: 0.9616 - prc: 0.8847\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2127 - tp: 70684.0000 - fp: 17992.0000 - tn: 246835.0000 - fn: 17499.0000 - accuracy: 0.8995 - precision: 0.7971 - recall: 0.8016 - auc: 0.9615 - prc: 0.8846\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2122 - tp: 70759.0000 - fp: 17898.0000 - tn: 246929.0000 - fn: 17424.0000 - accuracy: 0.8999 - precision: 0.7981 - recall: 0.8024 - auc: 0.9617 - prc: 0.8850\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2118 - tp: 70861.0000 - fp: 17886.0000 - tn: 246941.0000 - fn: 17322.0000 - accuracy: 0.9003 - precision: 0.7985 - recall: 0.8036 - auc: 0.9619 - prc: 0.8858\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2116 - tp: 70908.0000 - fp: 18032.0000 - tn: 246795.0000 - fn: 17275.0000 - accuracy: 0.9000 - precision: 0.7973 - recall: 0.8041 - auc: 0.9619 - prc: 0.8855\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2111 - tp: 70888.0000 - fp: 18004.0000 - tn: 246823.0000 - fn: 17295.0000 - accuracy: 0.9000 - precision: 0.7975 - recall: 0.8039 - auc: 0.9621 - prc: 0.8863\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2191 - tp: 140482.0000 - fp: 36112.0000 - tn: 493542.0000 - fn: 35884.0000 - accuracy: 0.8980 - precision: 0.7955 - recall: 0.7965 - auc: 0.9606 - prc: 0.8823\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2190 - tp: 69441.0000 - fp: 17884.0000 - tn: 246943.0000 - fn: 18742.0000 - accuracy: 0.8962 - precision: 0.7952 - recall: 0.7875 - auc: 0.9591 - prc: 0.8785\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2186 - tp: 69518.0000 - fp: 17924.0000 - tn: 246903.0000 - fn: 18665.0000 - accuracy: 0.8964 - precision: 0.7950 - recall: 0.7883 - auc: 0.9592 - prc: 0.8789\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2186 - tp: 69657.0000 - fp: 18033.0000 - tn: 246794.0000 - fn: 18526.0000 - accuracy: 0.8964 - precision: 0.7944 - recall: 0.7899 - auc: 0.9592 - prc: 0.8790\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2181 - tp: 69859.0000 - fp: 18229.0000 - tn: 246598.0000 - fn: 18324.0000 - accuracy: 0.8965 - precision: 0.7931 - recall: 0.7922 - auc: 0.9594 - prc: 0.8794\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2179 - tp: 69576.0000 - fp: 17889.0000 - tn: 246938.0000 - fn: 18607.0000 - accuracy: 0.8966 - precision: 0.7955 - recall: 0.7890 - auc: 0.9594 - prc: 0.8797\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2177 - tp: 69883.0000 - fp: 18060.0000 - tn: 246767.0000 - fn: 18300.0000 - accuracy: 0.8970 - precision: 0.7946 - recall: 0.7925 - auc: 0.9596 - prc: 0.8800\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2171 - tp: 70001.0000 - fp: 18033.0000 - tn: 246794.0000 - fn: 18182.0000 - accuracy: 0.8974 - precision: 0.7952 - recall: 0.7938 - auc: 0.9598 - prc: 0.8806\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2168 - tp: 69941.0000 - fp: 17824.0000 - tn: 247003.0000 - fn: 18242.0000 - accuracy: 0.8978 - precision: 0.7969 - recall: 0.7931 - auc: 0.9599 - prc: 0.8808\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2166 - tp: 70015.0000 - fp: 17995.0000 - tn: 246832.0000 - fn: 18168.0000 - accuracy: 0.8976 - precision: 0.7955 - recall: 0.7940 - auc: 0.9600 - prc: 0.8807\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2164 - tp: 69974.0000 - fp: 17833.0000 - tn: 246994.0000 - fn: 18209.0000 - accuracy: 0.8979 - precision: 0.7969 - recall: 0.7935 - auc: 0.9601 - prc: 0.8811\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2160 - tp: 70156.0000 - fp: 17977.0000 - tn: 246850.0000 - fn: 18027.0000 - accuracy: 0.8980 - precision: 0.7960 - recall: 0.7956 - auc: 0.9602 - prc: 0.8817\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2156 - tp: 70132.0000 - fp: 18015.0000 - tn: 246812.0000 - fn: 18051.0000 - accuracy: 0.8978 - precision: 0.7956 - recall: 0.7953 - auc: 0.9604 - prc: 0.8822\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2157 - tp: 70259.0000 - fp: 18157.0000 - tn: 246670.0000 - fn: 17924.0000 - accuracy: 0.8978 - precision: 0.7946 - recall: 0.7967 - auc: 0.9603 - prc: 0.8819\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2152 - tp: 70157.0000 - fp: 17990.0000 - tn: 246837.0000 - fn: 18026.0000 - accuracy: 0.8980 - precision: 0.7959 - recall: 0.7956 - auc: 0.9606 - prc: 0.8822\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2146 - tp: 70275.0000 - fp: 17856.0000 - tn: 246971.0000 - fn: 17908.0000 - accuracy: 0.8987 - precision: 0.7974 - recall: 0.7969 - auc: 0.9608 - prc: 0.8832\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2149 - tp: 70274.0000 - fp: 17926.0000 - tn: 246901.0000 - fn: 17909.0000 - accuracy: 0.8985 - precision: 0.7968 - recall: 0.7969 - auc: 0.9606 - prc: 0.8826\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2140 - tp: 70566.0000 - fp: 18093.0000 - tn: 246734.0000 - fn: 17617.0000 - accuracy: 0.8988 - precision: 0.7959 - recall: 0.8002 - auc: 0.9610 - prc: 0.8833\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2140 - tp: 70385.0000 - fp: 17984.0000 - tn: 246843.0000 - fn: 17798.0000 - accuracy: 0.8986 - precision: 0.7965 - recall: 0.7982 - auc: 0.9610 - prc: 0.8834\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2137 - tp: 70693.0000 - fp: 18120.0000 - tn: 246707.0000 - fn: 17490.0000 - accuracy: 0.8991 - precision: 0.7960 - recall: 0.8017 - auc: 0.9611 - prc: 0.8834\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2137 - tp: 70396.0000 - fp: 17973.0000 - tn: 246854.0000 - fn: 17787.0000 - accuracy: 0.8987 - precision: 0.7966 - recall: 0.7983 - auc: 0.9611 - prc: 0.8834\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2133 - tp: 70619.0000 - fp: 17957.0000 - tn: 246870.0000 - fn: 17564.0000 - accuracy: 0.8994 - precision: 0.7973 - recall: 0.8008 - auc: 0.9612 - prc: 0.8840\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2131 - tp: 70664.0000 - fp: 17995.0000 - tn: 246832.0000 - fn: 17519.0000 - accuracy: 0.8994 - precision: 0.7970 - recall: 0.8013 - auc: 0.9614 - prc: 0.8842\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2127 - tp: 70750.0000 - fp: 17943.0000 - tn: 246884.0000 - fn: 17433.0000 - accuracy: 0.8998 - precision: 0.7977 - recall: 0.8023 - auc: 0.9615 - prc: 0.8845\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2124 - tp: 70744.0000 - fp: 17945.0000 - tn: 246882.0000 - fn: 17439.0000 - accuracy: 0.8998 - precision: 0.7977 - recall: 0.8022 - auc: 0.9616 - prc: 0.8851\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2121 - tp: 70752.0000 - fp: 17919.0000 - tn: 246908.0000 - fn: 17431.0000 - accuracy: 0.8999 - precision: 0.7979 - recall: 0.8023 - auc: 0.9618 - prc: 0.8854\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2117 - tp: 70951.0000 - fp: 17992.0000 - tn: 246835.0000 - fn: 17232.0000 - accuracy: 0.9002 - precision: 0.7977 - recall: 0.8046 - auc: 0.9619 - prc: 0.8856\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2119 - tp: 70887.0000 - fp: 17948.0000 - tn: 246879.0000 - fn: 17296.0000 - accuracy: 0.9002 - precision: 0.7980 - recall: 0.8039 - auc: 0.9618 - prc: 0.8855\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2115 - tp: 70886.0000 - fp: 17849.0000 - tn: 246978.0000 - fn: 17297.0000 - accuracy: 0.9004 - precision: 0.7989 - recall: 0.8039 - auc: 0.9620 - prc: 0.8857\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2113 - tp: 70943.0000 - fp: 17912.0000 - tn: 246915.0000 - fn: 17240.0000 - accuracy: 0.9004 - precision: 0.7984 - recall: 0.8045 - auc: 0.9620 - prc: 0.8862\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 37s 6ms/step - loss: 0.2195 - tp: 140299.0000 - fp: 35827.0000 - tn: 493827.0000 - fn: 36067.0000 - accuracy: 0.8982 - precision: 0.7966 - recall: 0.7955 - auc: 0.9605 - prc: 0.8821\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2192 - tp: 69510.0000 - fp: 18032.0000 - tn: 246795.0000 - fn: 18673.0000 - accuracy: 0.8960 - precision: 0.7940 - recall: 0.7882 - auc: 0.9590 - prc: 0.8781\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2187 - tp: 69668.0000 - fp: 18033.0000 - tn: 246794.0000 - fn: 18515.0000 - accuracy: 0.8965 - precision: 0.7944 - recall: 0.7900 - auc: 0.9592 - prc: 0.8786\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2183 - tp: 69671.0000 - fp: 18045.0000 - tn: 246782.0000 - fn: 18512.0000 - accuracy: 0.8964 - precision: 0.7943 - recall: 0.7901 - auc: 0.9593 - prc: 0.8793\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2181 - tp: 69778.0000 - fp: 17991.0000 - tn: 246836.0000 - fn: 18405.0000 - accuracy: 0.8969 - precision: 0.7950 - recall: 0.7913 - auc: 0.9594 - prc: 0.8792\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2177 - tp: 69786.0000 - fp: 18076.0000 - tn: 246751.0000 - fn: 18397.0000 - accuracy: 0.8967 - precision: 0.7943 - recall: 0.7914 - auc: 0.9595 - prc: 0.8798\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2174 - tp: 69863.0000 - fp: 18051.0000 - tn: 246776.0000 - fn: 18320.0000 - accuracy: 0.8970 - precision: 0.7947 - recall: 0.7923 - auc: 0.9597 - prc: 0.8800\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2173 - tp: 70095.0000 - fp: 18246.0000 - tn: 246581.0000 - fn: 18088.0000 - accuracy: 0.8971 - precision: 0.7935 - recall: 0.7949 - auc: 0.9597 - prc: 0.8804\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2169 - tp: 69947.0000 - fp: 17981.0000 - tn: 246846.0000 - fn: 18236.0000 - accuracy: 0.8974 - precision: 0.7955 - recall: 0.7932 - auc: 0.9599 - prc: 0.8806\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2166 - tp: 70061.0000 - fp: 18101.0000 - tn: 246726.0000 - fn: 18122.0000 - accuracy: 0.8974 - precision: 0.7947 - recall: 0.7945 - auc: 0.9600 - prc: 0.8807\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2166 - tp: 70217.0000 - fp: 18299.0000 - tn: 246528.0000 - fn: 17966.0000 - accuracy: 0.8973 - precision: 0.7933 - recall: 0.7963 - auc: 0.9600 - prc: 0.8809\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2161 - tp: 70250.0000 - fp: 18066.0000 - tn: 246761.0000 - fn: 17933.0000 - accuracy: 0.8980 - precision: 0.7954 - recall: 0.7966 - auc: 0.9602 - prc: 0.8814\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2161 - tp: 70084.0000 - fp: 18094.0000 - tn: 246733.0000 - fn: 18099.0000 - accuracy: 0.8975 - precision: 0.7948 - recall: 0.7948 - auc: 0.9602 - prc: 0.8813\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2156 - tp: 70351.0000 - fp: 18169.0000 - tn: 246658.0000 - fn: 17832.0000 - accuracy: 0.8980 - precision: 0.7947 - recall: 0.7978 - auc: 0.9604 - prc: 0.8820\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2154 - tp: 70402.0000 - fp: 18126.0000 - tn: 246701.0000 - fn: 17781.0000 - accuracy: 0.8983 - precision: 0.7953 - recall: 0.7984 - auc: 0.9604 - prc: 0.8822\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2150 - tp: 70112.0000 - fp: 17798.0000 - tn: 247029.0000 - fn: 18071.0000 - accuracy: 0.8984 - precision: 0.7975 - recall: 0.7951 - auc: 0.9606 - prc: 0.8826\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2145 - tp: 70388.0000 - fp: 18056.0000 - tn: 246771.0000 - fn: 17795.0000 - accuracy: 0.8984 - precision: 0.7958 - recall: 0.7982 - auc: 0.9608 - prc: 0.8830\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2144 - tp: 70449.0000 - fp: 18275.0000 - tn: 246552.0000 - fn: 17734.0000 - accuracy: 0.8980 - precision: 0.7940 - recall: 0.7989 - auc: 0.9608 - prc: 0.8830\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2142 - tp: 70402.0000 - fp: 18012.0000 - tn: 246815.0000 - fn: 17781.0000 - accuracy: 0.8986 - precision: 0.7963 - recall: 0.7984 - auc: 0.9610 - prc: 0.8833\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2142 - tp: 70431.0000 - fp: 18066.0000 - tn: 246761.0000 - fn: 17752.0000 - accuracy: 0.8985 - precision: 0.7959 - recall: 0.7987 - auc: 0.9609 - prc: 0.8831\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2136 - tp: 70382.0000 - fp: 17889.0000 - tn: 246938.0000 - fn: 17801.0000 - accuracy: 0.8989 - precision: 0.7973 - recall: 0.7981 - auc: 0.9612 - prc: 0.8840\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2135 - tp: 70478.0000 - fp: 18101.0000 - tn: 246726.0000 - fn: 17705.0000 - accuracy: 0.8986 - precision: 0.7957 - recall: 0.7992 - auc: 0.9612 - prc: 0.8837\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2134 - tp: 70531.0000 - fp: 17806.0000 - tn: 247021.0000 - fn: 17652.0000 - accuracy: 0.8996 - precision: 0.7984 - recall: 0.7998 - auc: 0.9612 - prc: 0.8840\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2131 - tp: 70628.0000 - fp: 17897.0000 - tn: 246930.0000 - fn: 17555.0000 - accuracy: 0.8996 - precision: 0.7978 - recall: 0.8009 - auc: 0.9613 - prc: 0.8842\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2129 - tp: 70778.0000 - fp: 18182.0000 - tn: 246645.0000 - fn: 17405.0000 - accuracy: 0.8992 - precision: 0.7956 - recall: 0.8026 - auc: 0.9614 - prc: 0.8846\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2123 - tp: 70710.0000 - fp: 17920.0000 - tn: 246907.0000 - fn: 17473.0000 - accuracy: 0.8997 - precision: 0.7978 - recall: 0.8019 - auc: 0.9617 - prc: 0.8853\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2120 - tp: 71015.0000 - fp: 18205.0000 - tn: 246622.0000 - fn: 17168.0000 - accuracy: 0.8998 - precision: 0.7960 - recall: 0.8053 - auc: 0.9618 - prc: 0.8853\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2118 - tp: 71028.0000 - fp: 18045.0000 - tn: 246782.0000 - fn: 17155.0000 - accuracy: 0.9003 - precision: 0.7974 - recall: 0.8055 - auc: 0.9618 - prc: 0.8858\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2117 - tp: 70809.0000 - fp: 18028.0000 - tn: 246799.0000 - fn: 17374.0000 - accuracy: 0.8997 - precision: 0.7971 - recall: 0.8030 - auc: 0.9618 - prc: 0.8858\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2113 - tp: 71004.0000 - fp: 17932.0000 - tn: 246895.0000 - fn: 17179.0000 - accuracy: 0.9005 - precision: 0.7984 - recall: 0.8052 - auc: 0.9620 - prc: 0.8862\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2192 - tp: 140610.0000 - fp: 36119.0000 - tn: 493535.0000 - fn: 35756.0000 - accuracy: 0.8982 - precision: 0.7956 - recall: 0.7973 - auc: 0.9605 - prc: 0.8823\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2192 - tp: 69520.0000 - fp: 18061.0000 - tn: 246766.0000 - fn: 18663.0000 - accuracy: 0.8960 - precision: 0.7938 - recall: 0.7884 - auc: 0.9590 - prc: 0.8782\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2187 - tp: 69478.0000 - fp: 17847.0000 - tn: 246980.0000 - fn: 18705.0000 - accuracy: 0.8965 - precision: 0.7956 - recall: 0.7879 - auc: 0.9591 - prc: 0.8787\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2182 - tp: 69557.0000 - fp: 17768.0000 - tn: 247059.0000 - fn: 18626.0000 - accuracy: 0.8969 - precision: 0.7965 - recall: 0.7888 - auc: 0.9593 - prc: 0.8795\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2178 - tp: 69809.0000 - fp: 17999.0000 - tn: 246828.0000 - fn: 18374.0000 - accuracy: 0.8970 - precision: 0.7950 - recall: 0.7916 - auc: 0.9595 - prc: 0.8794\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2178 - tp: 69665.0000 - fp: 17849.0000 - tn: 246978.0000 - fn: 18518.0000 - accuracy: 0.8970 - precision: 0.7960 - recall: 0.7900 - auc: 0.9595 - prc: 0.8797\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2176 - tp: 69972.0000 - fp: 18075.0000 - tn: 246752.0000 - fn: 18211.0000 - accuracy: 0.8972 - precision: 0.7947 - recall: 0.7935 - auc: 0.9596 - prc: 0.8799\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2170 - tp: 69994.0000 - fp: 17997.0000 - tn: 246830.0000 - fn: 18189.0000 - accuracy: 0.8975 - precision: 0.7955 - recall: 0.7937 - auc: 0.9598 - prc: 0.8806\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2170 - tp: 69978.0000 - fp: 18070.0000 - tn: 246757.0000 - fn: 18205.0000 - accuracy: 0.8972 - precision: 0.7948 - recall: 0.7936 - auc: 0.9598 - prc: 0.8804\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2166 - tp: 70022.0000 - fp: 18086.0000 - tn: 246741.0000 - fn: 18161.0000 - accuracy: 0.8973 - precision: 0.7947 - recall: 0.7941 - auc: 0.9600 - prc: 0.8810\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2164 - tp: 69955.0000 - fp: 17951.0000 - tn: 246876.0000 - fn: 18228.0000 - accuracy: 0.8975 - precision: 0.7958 - recall: 0.7933 - auc: 0.9600 - prc: 0.8812\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2161 - tp: 70106.0000 - fp: 18037.0000 - tn: 246790.0000 - fn: 18077.0000 - accuracy: 0.8977 - precision: 0.7954 - recall: 0.7950 - auc: 0.9602 - prc: 0.8814\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2160 - tp: 70323.0000 - fp: 18214.0000 - tn: 246613.0000 - fn: 17860.0000 - accuracy: 0.8978 - precision: 0.7943 - recall: 0.7975 - auc: 0.9602 - prc: 0.8814\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2157 - tp: 70191.0000 - fp: 18117.0000 - tn: 246710.0000 - fn: 17992.0000 - accuracy: 0.8977 - precision: 0.7948 - recall: 0.7960 - auc: 0.9604 - prc: 0.8817\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2154 - tp: 70226.0000 - fp: 18000.0000 - tn: 246827.0000 - fn: 17957.0000 - accuracy: 0.8981 - precision: 0.7960 - recall: 0.7964 - auc: 0.9605 - prc: 0.8821\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2150 - tp: 70397.0000 - fp: 18127.0000 - tn: 246700.0000 - fn: 17786.0000 - accuracy: 0.8983 - precision: 0.7952 - recall: 0.7983 - auc: 0.9606 - prc: 0.8824\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2148 - tp: 70438.0000 - fp: 18180.0000 - tn: 246647.0000 - fn: 17745.0000 - accuracy: 0.8982 - precision: 0.7948 - recall: 0.7988 - auc: 0.9607 - prc: 0.8829\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2145 - tp: 70210.0000 - fp: 17887.0000 - tn: 246940.0000 - fn: 17973.0000 - accuracy: 0.8984 - precision: 0.7970 - recall: 0.7962 - auc: 0.9608 - prc: 0.8830\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2141 - tp: 70413.0000 - fp: 17975.0000 - tn: 246852.0000 - fn: 17770.0000 - accuracy: 0.8987 - precision: 0.7966 - recall: 0.7985 - auc: 0.9610 - prc: 0.8833\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2137 - tp: 70408.0000 - fp: 18081.0000 - tn: 246746.0000 - fn: 17775.0000 - accuracy: 0.8984 - precision: 0.7957 - recall: 0.7984 - auc: 0.9611 - prc: 0.8835\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2134 - tp: 70680.0000 - fp: 18097.0000 - tn: 246730.0000 - fn: 17503.0000 - accuracy: 0.8992 - precision: 0.7962 - recall: 0.8015 - auc: 0.9612 - prc: 0.8840\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2131 - tp: 70740.0000 - fp: 17876.0000 - tn: 246951.0000 - fn: 17443.0000 - accuracy: 0.8999 - precision: 0.7983 - recall: 0.8022 - auc: 0.9614 - prc: 0.8842\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2131 - tp: 70494.0000 - fp: 17904.0000 - tn: 246923.0000 - fn: 17689.0000 - accuracy: 0.8992 - precision: 0.7975 - recall: 0.7994 - auc: 0.9614 - prc: 0.8844\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2130 - tp: 70687.0000 - fp: 18013.0000 - tn: 246814.0000 - fn: 17496.0000 - accuracy: 0.8994 - precision: 0.7969 - recall: 0.8016 - auc: 0.9614 - prc: 0.8845\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2126 - tp: 70629.0000 - fp: 17947.0000 - tn: 246880.0000 - fn: 17554.0000 - accuracy: 0.8994 - precision: 0.7974 - recall: 0.8009 - auc: 0.9615 - prc: 0.8848\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2126 - tp: 70811.0000 - fp: 17982.0000 - tn: 246845.0000 - fn: 17372.0000 - accuracy: 0.8998 - precision: 0.7975 - recall: 0.8030 - auc: 0.9616 - prc: 0.8848\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2121 - tp: 71002.0000 - fp: 18267.0000 - tn: 246560.0000 - fn: 17181.0000 - accuracy: 0.8996 - precision: 0.7954 - recall: 0.8052 - auc: 0.9617 - prc: 0.8852\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2121 - tp: 70862.0000 - fp: 18098.0000 - tn: 246729.0000 - fn: 17321.0000 - accuracy: 0.8997 - precision: 0.7966 - recall: 0.8036 - auc: 0.9617 - prc: 0.8855\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2113 - tp: 70989.0000 - fp: 17989.0000 - tn: 246838.0000 - fn: 17194.0000 - accuracy: 0.9003 - precision: 0.7978 - recall: 0.8050 - auc: 0.9620 - prc: 0.8860\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2113 - tp: 71148.0000 - fp: 18267.0000 - tn: 246560.0000 - fn: 17035.0000 - accuracy: 0.9000 - precision: 0.7957 - recall: 0.8068 - auc: 0.9620 - prc: 0.8859\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2193 - tp: 140387.0000 - fp: 36117.0000 - tn: 493537.0000 - fn: 35979.0000 - accuracy: 0.8979 - precision: 0.7954 - recall: 0.7960 - auc: 0.9605 - prc: 0.8820\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2190 - tp: 69645.0000 - fp: 18113.0000 - tn: 246714.0000 - fn: 18538.0000 - accuracy: 0.8962 - precision: 0.7936 - recall: 0.7898 - auc: 0.9591 - prc: 0.8784\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2187 - tp: 69590.0000 - fp: 17990.0000 - tn: 246837.0000 - fn: 18593.0000 - accuracy: 0.8964 - precision: 0.7946 - recall: 0.7892 - auc: 0.9592 - prc: 0.8788\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2185 - tp: 69663.0000 - fp: 18056.0000 - tn: 246771.0000 - fn: 18520.0000 - accuracy: 0.8964 - precision: 0.7942 - recall: 0.7900 - auc: 0.9593 - prc: 0.8789\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2181 - tp: 69787.0000 - fp: 17951.0000 - tn: 246876.0000 - fn: 18396.0000 - accuracy: 0.8970 - precision: 0.7954 - recall: 0.7914 - auc: 0.9594 - prc: 0.8795\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2178 - tp: 69742.0000 - fp: 17993.0000 - tn: 246834.0000 - fn: 18441.0000 - accuracy: 0.8968 - precision: 0.7949 - recall: 0.7909 - auc: 0.9596 - prc: 0.8795\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2176 - tp: 70004.0000 - fp: 18316.0000 - tn: 246511.0000 - fn: 18179.0000 - accuracy: 0.8966 - precision: 0.7926 - recall: 0.7938 - auc: 0.9596 - prc: 0.8798\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2172 - tp: 70034.0000 - fp: 18127.0000 - tn: 246700.0000 - fn: 18149.0000 - accuracy: 0.8972 - precision: 0.7944 - recall: 0.7942 - auc: 0.9598 - prc: 0.8805\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2169 - tp: 69828.0000 - fp: 17946.0000 - tn: 246881.0000 - fn: 18355.0000 - accuracy: 0.8972 - precision: 0.7955 - recall: 0.7919 - auc: 0.9599 - prc: 0.8806\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2166 - tp: 69893.0000 - fp: 18007.0000 - tn: 246820.0000 - fn: 18290.0000 - accuracy: 0.8972 - precision: 0.7951 - recall: 0.7926 - auc: 0.9599 - prc: 0.8810\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2164 - tp: 70041.0000 - fp: 17913.0000 - tn: 246914.0000 - fn: 18142.0000 - accuracy: 0.8979 - precision: 0.7963 - recall: 0.7943 - auc: 0.9601 - prc: 0.8811\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2164 - tp: 70142.0000 - fp: 18076.0000 - tn: 246751.0000 - fn: 18041.0000 - accuracy: 0.8977 - precision: 0.7951 - recall: 0.7954 - auc: 0.9601 - prc: 0.8813\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2160 - tp: 70193.0000 - fp: 18031.0000 - tn: 246796.0000 - fn: 17990.0000 - accuracy: 0.8980 - precision: 0.7956 - recall: 0.7960 - auc: 0.9602 - prc: 0.8817\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2154 - tp: 70274.0000 - fp: 18085.0000 - tn: 246742.0000 - fn: 17909.0000 - accuracy: 0.8980 - precision: 0.7953 - recall: 0.7969 - auc: 0.9604 - prc: 0.8822\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2154 - tp: 70274.0000 - fp: 18113.0000 - tn: 246714.0000 - fn: 17909.0000 - accuracy: 0.8980 - precision: 0.7951 - recall: 0.7969 - auc: 0.9604 - prc: 0.8820\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2150 - tp: 70357.0000 - fp: 17992.0000 - tn: 246835.0000 - fn: 17826.0000 - accuracy: 0.8985 - precision: 0.7964 - recall: 0.7979 - auc: 0.9606 - prc: 0.8827\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2146 - tp: 70292.0000 - fp: 17984.0000 - tn: 246843.0000 - fn: 17891.0000 - accuracy: 0.8984 - precision: 0.7963 - recall: 0.7971 - auc: 0.9608 - prc: 0.8831\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2143 - tp: 70480.0000 - fp: 17996.0000 - tn: 246831.0000 - fn: 17703.0000 - accuracy: 0.8989 - precision: 0.7966 - recall: 0.7992 - auc: 0.9609 - prc: 0.8831\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2144 - tp: 70402.0000 - fp: 18059.0000 - tn: 246768.0000 - fn: 17781.0000 - accuracy: 0.8985 - precision: 0.7959 - recall: 0.7984 - auc: 0.9609 - prc: 0.8830\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2140 - tp: 70539.0000 - fp: 18038.0000 - tn: 246789.0000 - fn: 17644.0000 - accuracy: 0.8989 - precision: 0.7964 - recall: 0.7999 - auc: 0.9610 - prc: 0.8836\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2139 - tp: 70548.0000 - fp: 18032.0000 - tn: 246795.0000 - fn: 17635.0000 - accuracy: 0.8990 - precision: 0.7964 - recall: 0.8000 - auc: 0.9611 - prc: 0.8836\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2133 - tp: 70591.0000 - fp: 18123.0000 - tn: 246704.0000 - fn: 17592.0000 - accuracy: 0.8988 - precision: 0.7957 - recall: 0.8005 - auc: 0.9613 - prc: 0.8842\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2132 - tp: 70633.0000 - fp: 18085.0000 - tn: 246742.0000 - fn: 17550.0000 - accuracy: 0.8991 - precision: 0.7962 - recall: 0.8010 - auc: 0.9613 - prc: 0.8842\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2132 - tp: 70608.0000 - fp: 18004.0000 - tn: 246823.0000 - fn: 17575.0000 - accuracy: 0.8992 - precision: 0.7968 - recall: 0.8007 - auc: 0.9613 - prc: 0.8842\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2127 - tp: 70730.0000 - fp: 18062.0000 - tn: 246765.0000 - fn: 17453.0000 - accuracy: 0.8994 - precision: 0.7966 - recall: 0.8021 - auc: 0.9615 - prc: 0.8848\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2123 - tp: 70783.0000 - fp: 18042.0000 - tn: 246785.0000 - fn: 17400.0000 - accuracy: 0.8996 - precision: 0.7969 - recall: 0.8027 - auc: 0.9617 - prc: 0.8849\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2120 - tp: 70887.0000 - fp: 17960.0000 - tn: 246867.0000 - fn: 17296.0000 - accuracy: 0.9001 - precision: 0.7979 - recall: 0.8039 - auc: 0.9618 - prc: 0.8853\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2121 - tp: 70742.0000 - fp: 17902.0000 - tn: 246925.0000 - fn: 17441.0000 - accuracy: 0.8999 - precision: 0.7980 - recall: 0.8022 - auc: 0.9617 - prc: 0.8853\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2117 - tp: 70868.0000 - fp: 17919.0000 - tn: 246908.0000 - fn: 17315.0000 - accuracy: 0.9002 - precision: 0.7982 - recall: 0.8036 - auc: 0.9619 - prc: 0.8858\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2113 - tp: 71010.0000 - fp: 17985.0000 - tn: 246842.0000 - fn: 17173.0000 - accuracy: 0.9004 - precision: 0.7979 - recall: 0.8053 - auc: 0.9620 - prc: 0.8859\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2193 - tp: 140485.0000 - fp: 35953.0000 - tn: 493701.0000 - fn: 35881.0000 - accuracy: 0.8983 - precision: 0.7962 - recall: 0.7966 - auc: 0.9605 - prc: 0.8822\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2193 - tp: 69447.0000 - fp: 17984.0000 - tn: 246843.0000 - fn: 18736.0000 - accuracy: 0.8960 - precision: 0.7943 - recall: 0.7875 - auc: 0.9589 - prc: 0.8783\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2190 - tp: 69614.0000 - fp: 18187.0000 - tn: 246640.0000 - fn: 18569.0000 - accuracy: 0.8959 - precision: 0.7929 - recall: 0.7894 - auc: 0.9590 - prc: 0.8781\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2184 - tp: 69614.0000 - fp: 17989.0000 - tn: 246838.0000 - fn: 18569.0000 - accuracy: 0.8964 - precision: 0.7947 - recall: 0.7894 - auc: 0.9593 - prc: 0.8790\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2181 - tp: 69657.0000 - fp: 18002.0000 - tn: 246825.0000 - fn: 18526.0000 - accuracy: 0.8965 - precision: 0.7946 - recall: 0.7899 - auc: 0.9594 - prc: 0.8795\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2178 - tp: 69722.0000 - fp: 17811.0000 - tn: 247016.0000 - fn: 18461.0000 - accuracy: 0.8972 - precision: 0.7965 - recall: 0.7907 - auc: 0.9595 - prc: 0.8797\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2175 - tp: 69771.0000 - fp: 17948.0000 - tn: 246879.0000 - fn: 18412.0000 - accuracy: 0.8970 - precision: 0.7954 - recall: 0.7912 - auc: 0.9596 - prc: 0.8802\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2173 - tp: 69838.0000 - fp: 17954.0000 - tn: 246873.0000 - fn: 18345.0000 - accuracy: 0.8972 - precision: 0.7955 - recall: 0.7920 - auc: 0.9597 - prc: 0.8803\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2168 - tp: 70005.0000 - fp: 18057.0000 - tn: 246770.0000 - fn: 18178.0000 - accuracy: 0.8974 - precision: 0.7950 - recall: 0.7939 - auc: 0.9599 - prc: 0.8805\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2166 - tp: 69927.0000 - fp: 17912.0000 - tn: 246915.0000 - fn: 18256.0000 - accuracy: 0.8975 - precision: 0.7961 - recall: 0.7930 - auc: 0.9600 - prc: 0.8810\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2165 - tp: 70149.0000 - fp: 18193.0000 - tn: 246634.0000 - fn: 18034.0000 - accuracy: 0.8974 - precision: 0.7941 - recall: 0.7955 - auc: 0.9600 - prc: 0.8806\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2161 - tp: 69953.0000 - fp: 17886.0000 - tn: 246941.0000 - fn: 18230.0000 - accuracy: 0.8977 - precision: 0.7964 - recall: 0.7933 - auc: 0.9602 - prc: 0.8814\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2156 - tp: 70112.0000 - fp: 18010.0000 - tn: 246817.0000 - fn: 18071.0000 - accuracy: 0.8978 - precision: 0.7956 - recall: 0.7951 - auc: 0.9604 - prc: 0.8818\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2157 - tp: 70106.0000 - fp: 17846.0000 - tn: 246981.0000 - fn: 18077.0000 - accuracy: 0.8982 - precision: 0.7971 - recall: 0.7950 - auc: 0.9604 - prc: 0.8819\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2151 - tp: 70260.0000 - fp: 17985.0000 - tn: 246842.0000 - fn: 17923.0000 - accuracy: 0.8983 - precision: 0.7962 - recall: 0.7968 - auc: 0.9606 - prc: 0.8824\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2151 - tp: 70252.0000 - fp: 18006.0000 - tn: 246821.0000 - fn: 17931.0000 - accuracy: 0.8982 - precision: 0.7960 - recall: 0.7967 - auc: 0.9605 - prc: 0.8825\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2146 - tp: 70356.0000 - fp: 17920.0000 - tn: 246907.0000 - fn: 17827.0000 - accuracy: 0.8987 - precision: 0.7970 - recall: 0.7978 - auc: 0.9608 - prc: 0.8828\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2146 - tp: 70537.0000 - fp: 18271.0000 - tn: 246556.0000 - fn: 17646.0000 - accuracy: 0.8983 - precision: 0.7943 - recall: 0.7999 - auc: 0.9607 - prc: 0.8829\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2142 - tp: 70466.0000 - fp: 17943.0000 - tn: 246884.0000 - fn: 17717.0000 - accuracy: 0.8990 - precision: 0.7970 - recall: 0.7991 - auc: 0.9609 - prc: 0.8834\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2141 - tp: 70477.0000 - fp: 18123.0000 - tn: 246704.0000 - fn: 17706.0000 - accuracy: 0.8985 - precision: 0.7955 - recall: 0.7992 - auc: 0.9610 - prc: 0.8833\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2135 - tp: 70567.0000 - fp: 17996.0000 - tn: 246831.0000 - fn: 17616.0000 - accuracy: 0.8991 - precision: 0.7968 - recall: 0.8002 - auc: 0.9613 - prc: 0.8841\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2135 - tp: 70596.0000 - fp: 18030.0000 - tn: 246797.0000 - fn: 17587.0000 - accuracy: 0.8991 - precision: 0.7966 - recall: 0.8006 - auc: 0.9612 - prc: 0.8839\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2130 - tp: 70685.0000 - fp: 18001.0000 - tn: 246826.0000 - fn: 17498.0000 - accuracy: 0.8994 - precision: 0.7970 - recall: 0.8016 - auc: 0.9614 - prc: 0.8845\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2128 - tp: 70786.0000 - fp: 18062.0000 - tn: 246765.0000 - fn: 17397.0000 - accuracy: 0.8996 - precision: 0.7967 - recall: 0.8027 - auc: 0.9615 - prc: 0.8847\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2128 - tp: 70807.0000 - fp: 18143.0000 - tn: 246684.0000 - fn: 17376.0000 - accuracy: 0.8994 - precision: 0.7960 - recall: 0.8030 - auc: 0.9615 - prc: 0.8846\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2123 - tp: 70797.0000 - fp: 17992.0000 - tn: 246835.0000 - fn: 17386.0000 - accuracy: 0.8998 - precision: 0.7974 - recall: 0.8028 - auc: 0.9617 - prc: 0.8851\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2120 - tp: 70894.0000 - fp: 18036.0000 - tn: 246791.0000 - fn: 17289.0000 - accuracy: 0.8999 - precision: 0.7972 - recall: 0.8039 - auc: 0.9618 - prc: 0.8854\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2118 - tp: 70971.0000 - fp: 18121.0000 - tn: 246706.0000 - fn: 17212.0000 - accuracy: 0.8999 - precision: 0.7966 - recall: 0.8048 - auc: 0.9619 - prc: 0.8856\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2115 - tp: 70895.0000 - fp: 17808.0000 - tn: 247019.0000 - fn: 17288.0000 - accuracy: 0.9006 - precision: 0.7992 - recall: 0.8040 - auc: 0.9619 - prc: 0.8859\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2114 - tp: 70880.0000 - fp: 17923.0000 - tn: 246904.0000 - fn: 17303.0000 - accuracy: 0.9002 - precision: 0.7982 - recall: 0.8038 - auc: 0.9620 - prc: 0.8860\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2195 - tp: 140338.0000 - fp: 36011.0000 - tn: 493643.0000 - fn: 36028.0000 - accuracy: 0.8980 - precision: 0.7958 - recall: 0.7957 - auc: 0.9604 - prc: 0.8820\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2193 - tp: 69649.0000 - fp: 18292.0000 - tn: 246535.0000 - fn: 18534.0000 - accuracy: 0.8957 - precision: 0.7920 - recall: 0.7898 - auc: 0.9589 - prc: 0.8781\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2186 - tp: 69812.0000 - fp: 18150.0000 - tn: 246677.0000 - fn: 18371.0000 - accuracy: 0.8965 - precision: 0.7937 - recall: 0.7917 - auc: 0.9592 - prc: 0.8790\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2185 - tp: 69872.0000 - fp: 18265.0000 - tn: 246562.0000 - fn: 18311.0000 - accuracy: 0.8964 - precision: 0.7928 - recall: 0.7924 - auc: 0.9593 - prc: 0.8790\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2178 - tp: 69862.0000 - fp: 18167.0000 - tn: 246660.0000 - fn: 18321.0000 - accuracy: 0.8966 - precision: 0.7936 - recall: 0.7922 - auc: 0.9595 - prc: 0.8795\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2178 - tp: 69692.0000 - fp: 17938.0000 - tn: 246889.0000 - fn: 18491.0000 - accuracy: 0.8968 - precision: 0.7953 - recall: 0.7903 - auc: 0.9595 - prc: 0.8794\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2177 - tp: 70016.0000 - fp: 18218.0000 - tn: 246609.0000 - fn: 18167.0000 - accuracy: 0.8969 - precision: 0.7935 - recall: 0.7940 - auc: 0.9596 - prc: 0.8797\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2171 - tp: 69921.0000 - fp: 18071.0000 - tn: 246756.0000 - fn: 18262.0000 - accuracy: 0.8971 - precision: 0.7946 - recall: 0.7929 - auc: 0.9598 - prc: 0.8804\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2168 - tp: 70129.0000 - fp: 18167.0000 - tn: 246660.0000 - fn: 18054.0000 - accuracy: 0.8974 - precision: 0.7942 - recall: 0.7953 - auc: 0.9599 - prc: 0.8807\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2167 - tp: 70026.0000 - fp: 18057.0000 - tn: 246770.0000 - fn: 18157.0000 - accuracy: 0.8974 - precision: 0.7950 - recall: 0.7941 - auc: 0.9600 - prc: 0.8809\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2165 - tp: 70078.0000 - fp: 18111.0000 - tn: 246716.0000 - fn: 18105.0000 - accuracy: 0.8974 - precision: 0.7946 - recall: 0.7947 - auc: 0.9601 - prc: 0.8809\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2163 - tp: 70197.0000 - fp: 18085.0000 - tn: 246742.0000 - fn: 17986.0000 - accuracy: 0.8978 - precision: 0.7951 - recall: 0.7960 - auc: 0.9601 - prc: 0.8810\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2161 - tp: 70212.0000 - fp: 18043.0000 - tn: 246784.0000 - fn: 17971.0000 - accuracy: 0.8980 - precision: 0.7956 - recall: 0.7962 - auc: 0.9602 - prc: 0.8814\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2157 - tp: 70245.0000 - fp: 18103.0000 - tn: 246724.0000 - fn: 17938.0000 - accuracy: 0.8979 - precision: 0.7951 - recall: 0.7966 - auc: 0.9603 - prc: 0.8817\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2151 - tp: 70470.0000 - fp: 18094.0000 - tn: 246733.0000 - fn: 17713.0000 - accuracy: 0.8986 - precision: 0.7957 - recall: 0.7991 - auc: 0.9606 - prc: 0.8825\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2148 - tp: 70342.0000 - fp: 18111.0000 - tn: 246716.0000 - fn: 17841.0000 - accuracy: 0.8982 - precision: 0.7952 - recall: 0.7977 - auc: 0.9607 - prc: 0.8827\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2148 - tp: 70599.0000 - fp: 18187.0000 - tn: 246640.0000 - fn: 17584.0000 - accuracy: 0.8987 - precision: 0.7952 - recall: 0.8006 - auc: 0.9607 - prc: 0.8826\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2144 - tp: 70613.0000 - fp: 18150.0000 - tn: 246677.0000 - fn: 17570.0000 - accuracy: 0.8988 - precision: 0.7955 - recall: 0.8008 - auc: 0.9609 - prc: 0.8832\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2141 - tp: 70516.0000 - fp: 18080.0000 - tn: 246747.0000 - fn: 17667.0000 - accuracy: 0.8987 - precision: 0.7959 - recall: 0.7997 - auc: 0.9609 - prc: 0.8831\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2140 - tp: 70514.0000 - fp: 17939.0000 - tn: 246888.0000 - fn: 17669.0000 - accuracy: 0.8991 - precision: 0.7972 - recall: 0.7996 - auc: 0.9610 - prc: 0.8835\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2132 - tp: 70873.0000 - fp: 18271.0000 - tn: 246556.0000 - fn: 17310.0000 - accuracy: 0.8992 - precision: 0.7950 - recall: 0.8037 - auc: 0.9613 - prc: 0.8841\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2135 - tp: 70648.0000 - fp: 18094.0000 - tn: 246733.0000 - fn: 17535.0000 - accuracy: 0.8991 - precision: 0.7961 - recall: 0.8012 - auc: 0.9612 - prc: 0.8840\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2130 - tp: 70640.0000 - fp: 18014.0000 - tn: 246813.0000 - fn: 17543.0000 - accuracy: 0.8993 - precision: 0.7968 - recall: 0.8011 - auc: 0.9614 - prc: 0.8845\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2127 - tp: 70876.0000 - fp: 18227.0000 - tn: 246600.0000 - fn: 17307.0000 - accuracy: 0.8993 - precision: 0.7954 - recall: 0.8037 - auc: 0.9615 - prc: 0.8848\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2123 - tp: 71058.0000 - fp: 18260.0000 - tn: 246567.0000 - fn: 17125.0000 - accuracy: 0.8998 - precision: 0.7956 - recall: 0.8058 - auc: 0.9617 - prc: 0.8851\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2124 - tp: 70972.0000 - fp: 18202.0000 - tn: 246625.0000 - fn: 17211.0000 - accuracy: 0.8997 - precision: 0.7959 - recall: 0.8048 - auc: 0.9616 - prc: 0.8849\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2117 - tp: 70868.0000 - fp: 18020.0000 - tn: 246807.0000 - fn: 17315.0000 - accuracy: 0.8999 - precision: 0.7973 - recall: 0.8036 - auc: 0.9619 - prc: 0.8858\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2115 - tp: 71025.0000 - fp: 18136.0000 - tn: 246691.0000 - fn: 17158.0000 - accuracy: 0.9000 - precision: 0.7966 - recall: 0.8054 - auc: 0.9620 - prc: 0.8858\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2116 - tp: 71052.0000 - fp: 18076.0000 - tn: 246751.0000 - fn: 17131.0000 - accuracy: 0.9003 - precision: 0.7972 - recall: 0.8057 - auc: 0.9619 - prc: 0.8859\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2110 - tp: 71083.0000 - fp: 18091.0000 - tn: 246736.0000 - fn: 17100.0000 - accuracy: 0.9003 - precision: 0.7971 - recall: 0.8061 - auc: 0.9622 - prc: 0.8864\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2193 - tp: 140468.0000 - fp: 36099.0000 - tn: 493555.0000 - fn: 35898.0000 - accuracy: 0.8980 - precision: 0.7956 - recall: 0.7965 - auc: 0.9606 - prc: 0.8823\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2189 - tp: 69598.0000 - fp: 18011.0000 - tn: 246816.0000 - fn: 18585.0000 - accuracy: 0.8963 - precision: 0.7944 - recall: 0.7892 - auc: 0.9591 - prc: 0.8786\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2187 - tp: 69781.0000 - fp: 18189.0000 - tn: 246638.0000 - fn: 18402.0000 - accuracy: 0.8963 - precision: 0.7932 - recall: 0.7913 - auc: 0.9592 - prc: 0.8787\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2185 - tp: 70005.0000 - fp: 18300.0000 - tn: 246527.0000 - fn: 18178.0000 - accuracy: 0.8967 - precision: 0.7928 - recall: 0.7939 - auc: 0.9593 - prc: 0.8789\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2178 - tp: 69555.0000 - fp: 18024.0000 - tn: 246803.0000 - fn: 18628.0000 - accuracy: 0.8962 - precision: 0.7942 - recall: 0.7888 - auc: 0.9595 - prc: 0.8796\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2178 - tp: 69779.0000 - fp: 17945.0000 - tn: 246882.0000 - fn: 18404.0000 - accuracy: 0.8970 - precision: 0.7954 - recall: 0.7913 - auc: 0.9595 - prc: 0.8797\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2175 - tp: 69713.0000 - fp: 17915.0000 - tn: 246912.0000 - fn: 18470.0000 - accuracy: 0.8969 - precision: 0.7956 - recall: 0.7905 - auc: 0.9596 - prc: 0.8800\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2173 - tp: 69907.0000 - fp: 18014.0000 - tn: 246813.0000 - fn: 18276.0000 - accuracy: 0.8972 - precision: 0.7951 - recall: 0.7927 - auc: 0.9597 - prc: 0.8802\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2171 - tp: 70062.0000 - fp: 18282.0000 - tn: 246545.0000 - fn: 18121.0000 - accuracy: 0.8969 - precision: 0.7931 - recall: 0.7945 - auc: 0.9598 - prc: 0.8804\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2166 - tp: 69855.0000 - fp: 18095.0000 - tn: 246732.0000 - fn: 18328.0000 - accuracy: 0.8968 - precision: 0.7943 - recall: 0.7922 - auc: 0.9600 - prc: 0.8809\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2164 - tp: 70061.0000 - fp: 17951.0000 - tn: 246876.0000 - fn: 18122.0000 - accuracy: 0.8978 - precision: 0.7960 - recall: 0.7945 - auc: 0.9601 - prc: 0.8810\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2162 - tp: 69868.0000 - fp: 17833.0000 - tn: 246994.0000 - fn: 18315.0000 - accuracy: 0.8976 - precision: 0.7967 - recall: 0.7923 - auc: 0.9602 - prc: 0.8810\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2161 - tp: 70104.0000 - fp: 17912.0000 - tn: 246915.0000 - fn: 18079.0000 - accuracy: 0.8980 - precision: 0.7965 - recall: 0.7950 - auc: 0.9602 - prc: 0.8813\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2157 - tp: 70138.0000 - fp: 17862.0000 - tn: 246965.0000 - fn: 18045.0000 - accuracy: 0.8983 - precision: 0.7970 - recall: 0.7954 - auc: 0.9603 - prc: 0.8818\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2153 - tp: 70255.0000 - fp: 18193.0000 - tn: 246634.0000 - fn: 17928.0000 - accuracy: 0.8977 - precision: 0.7943 - recall: 0.7967 - auc: 0.9605 - prc: 0.8823\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2149 - tp: 70246.0000 - fp: 17989.0000 - tn: 246838.0000 - fn: 17937.0000 - accuracy: 0.8982 - precision: 0.7961 - recall: 0.7966 - auc: 0.9606 - prc: 0.8826\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2144 - tp: 70331.0000 - fp: 18053.0000 - tn: 246774.0000 - fn: 17852.0000 - accuracy: 0.8983 - precision: 0.7957 - recall: 0.7976 - auc: 0.9608 - prc: 0.8830\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2148 - tp: 70400.0000 - fp: 18089.0000 - tn: 246738.0000 - fn: 17783.0000 - accuracy: 0.8984 - precision: 0.7956 - recall: 0.7983 - auc: 0.9607 - prc: 0.8827\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2145 - tp: 70411.0000 - fp: 17983.0000 - tn: 246844.0000 - fn: 17772.0000 - accuracy: 0.8987 - precision: 0.7966 - recall: 0.7985 - auc: 0.9608 - prc: 0.8830\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2138 - tp: 70559.0000 - fp: 18023.0000 - tn: 246804.0000 - fn: 17624.0000 - accuracy: 0.8990 - precision: 0.7965 - recall: 0.8001 - auc: 0.9611 - prc: 0.8837\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2135 - tp: 70560.0000 - fp: 17986.0000 - tn: 246841.0000 - fn: 17623.0000 - accuracy: 0.8991 - precision: 0.7969 - recall: 0.8002 - auc: 0.9612 - prc: 0.8841\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2133 - tp: 70588.0000 - fp: 18026.0000 - tn: 246801.0000 - fn: 17595.0000 - accuracy: 0.8991 - precision: 0.7966 - recall: 0.8005 - auc: 0.9612 - prc: 0.8841\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2131 - tp: 70777.0000 - fp: 18129.0000 - tn: 246698.0000 - fn: 17406.0000 - accuracy: 0.8993 - precision: 0.7961 - recall: 0.8026 - auc: 0.9613 - prc: 0.8842\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2129 - tp: 70682.0000 - fp: 18007.0000 - tn: 246820.0000 - fn: 17501.0000 - accuracy: 0.8994 - precision: 0.7970 - recall: 0.8015 - auc: 0.9614 - prc: 0.8845\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2124 - tp: 70887.0000 - fp: 18260.0000 - tn: 246567.0000 - fn: 17296.0000 - accuracy: 0.8993 - precision: 0.7952 - recall: 0.8039 - auc: 0.9616 - prc: 0.8845\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2126 - tp: 70769.0000 - fp: 18003.0000 - tn: 246824.0000 - fn: 17414.0000 - accuracy: 0.8997 - precision: 0.7972 - recall: 0.8025 - auc: 0.9615 - prc: 0.8849\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2124 - tp: 70820.0000 - fp: 18083.0000 - tn: 246744.0000 - fn: 17363.0000 - accuracy: 0.8996 - precision: 0.7966 - recall: 0.8031 - auc: 0.9616 - prc: 0.8849\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2118 - tp: 70823.0000 - fp: 17826.0000 - tn: 247001.0000 - fn: 17360.0000 - accuracy: 0.9003 - precision: 0.7989 - recall: 0.8031 - auc: 0.9618 - prc: 0.8856\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2117 - tp: 71019.0000 - fp: 18079.0000 - tn: 246748.0000 - fn: 17164.0000 - accuracy: 0.9002 - precision: 0.7971 - recall: 0.8054 - auc: 0.9619 - prc: 0.8856\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2113 - tp: 70892.0000 - fp: 17911.0000 - tn: 246916.0000 - fn: 17291.0000 - accuracy: 0.9003 - precision: 0.7983 - recall: 0.8039 - auc: 0.9620 - prc: 0.8862\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 37s 6ms/step - loss: 0.2193 - tp: 140252.0000 - fp: 35824.0000 - tn: 493830.0000 - fn: 36114.0000 - accuracy: 0.8981 - precision: 0.7965 - recall: 0.7952 - auc: 0.9605 - prc: 0.8823\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2192 - tp: 69447.0000 - fp: 17956.0000 - tn: 246871.0000 - fn: 18736.0000 - accuracy: 0.8961 - precision: 0.7946 - recall: 0.7875 - auc: 0.9589 - prc: 0.8783\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2188 - tp: 69541.0000 - fp: 17891.0000 - tn: 246936.0000 - fn: 18642.0000 - accuracy: 0.8965 - precision: 0.7954 - recall: 0.7886 - auc: 0.9591 - prc: 0.8789\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2184 - tp: 69690.0000 - fp: 18059.0000 - tn: 246768.0000 - fn: 18493.0000 - accuracy: 0.8965 - precision: 0.7942 - recall: 0.7903 - auc: 0.9593 - prc: 0.8790\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2181 - tp: 69765.0000 - fp: 17980.0000 - tn: 246847.0000 - fn: 18418.0000 - accuracy: 0.8969 - precision: 0.7951 - recall: 0.7911 - auc: 0.9594 - prc: 0.8794\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2178 - tp: 69916.0000 - fp: 18014.0000 - tn: 246813.0000 - fn: 18267.0000 - accuracy: 0.8972 - precision: 0.7951 - recall: 0.7929 - auc: 0.9595 - prc: 0.8797\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2174 - tp: 69780.0000 - fp: 17928.0000 - tn: 246899.0000 - fn: 18403.0000 - accuracy: 0.8971 - precision: 0.7956 - recall: 0.7913 - auc: 0.9596 - prc: 0.8803\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2172 - tp: 70096.0000 - fp: 18268.0000 - tn: 246559.0000 - fn: 18087.0000 - accuracy: 0.8970 - precision: 0.7933 - recall: 0.7949 - auc: 0.9597 - prc: 0.8802\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2170 - tp: 69911.0000 - fp: 17987.0000 - tn: 246840.0000 - fn: 18272.0000 - accuracy: 0.8973 - precision: 0.7954 - recall: 0.7928 - auc: 0.9598 - prc: 0.8805\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2168 - tp: 70192.0000 - fp: 18047.0000 - tn: 246780.0000 - fn: 17991.0000 - accuracy: 0.8979 - precision: 0.7955 - recall: 0.7960 - auc: 0.9599 - prc: 0.8808\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2164 - tp: 70114.0000 - fp: 17897.0000 - tn: 246930.0000 - fn: 18069.0000 - accuracy: 0.8981 - precision: 0.7967 - recall: 0.7951 - auc: 0.9601 - prc: 0.8809\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2160 - tp: 70148.0000 - fp: 18232.0000 - tn: 246595.0000 - fn: 18035.0000 - accuracy: 0.8973 - precision: 0.7937 - recall: 0.7955 - auc: 0.9602 - prc: 0.8816\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2160 - tp: 70104.0000 - fp: 17922.0000 - tn: 246905.0000 - fn: 18079.0000 - accuracy: 0.8980 - precision: 0.7964 - recall: 0.7950 - auc: 0.9602 - prc: 0.8816\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2154 - tp: 70174.0000 - fp: 18090.0000 - tn: 246737.0000 - fn: 18009.0000 - accuracy: 0.8977 - precision: 0.7950 - recall: 0.7958 - auc: 0.9605 - prc: 0.8820\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2152 - tp: 70266.0000 - fp: 18079.0000 - tn: 246748.0000 - fn: 17917.0000 - accuracy: 0.8980 - precision: 0.7954 - recall: 0.7968 - auc: 0.9605 - prc: 0.8824\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2150 - tp: 70326.0000 - fp: 18166.0000 - tn: 246661.0000 - fn: 17857.0000 - accuracy: 0.8980 - precision: 0.7947 - recall: 0.7975 - auc: 0.9606 - prc: 0.8824\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2150 - tp: 70461.0000 - fp: 18044.0000 - tn: 246783.0000 - fn: 17722.0000 - accuracy: 0.8987 - precision: 0.7961 - recall: 0.7990 - auc: 0.9606 - prc: 0.8826\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2145 - tp: 70582.0000 - fp: 18209.0000 - tn: 246618.0000 - fn: 17601.0000 - accuracy: 0.8986 - precision: 0.7949 - recall: 0.8004 - auc: 0.9608 - prc: 0.8827\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2141 - tp: 70661.0000 - fp: 18149.0000 - tn: 246678.0000 - fn: 17522.0000 - accuracy: 0.8990 - precision: 0.7956 - recall: 0.8013 - auc: 0.9609 - prc: 0.8832\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2140 - tp: 70503.0000 - fp: 18045.0000 - tn: 246782.0000 - fn: 17680.0000 - accuracy: 0.8988 - precision: 0.7962 - recall: 0.7995 - auc: 0.9610 - prc: 0.8833\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2138 - tp: 70493.0000 - fp: 17987.0000 - tn: 246840.0000 - fn: 17690.0000 - accuracy: 0.8989 - precision: 0.7967 - recall: 0.7994 - auc: 0.9611 - prc: 0.8837\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2134 - tp: 70671.0000 - fp: 18192.0000 - tn: 246635.0000 - fn: 17512.0000 - accuracy: 0.8989 - precision: 0.7953 - recall: 0.8014 - auc: 0.9612 - prc: 0.8841\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2129 - tp: 70754.0000 - fp: 17990.0000 - tn: 246837.0000 - fn: 17429.0000 - accuracy: 0.8997 - precision: 0.7973 - recall: 0.8024 - auc: 0.9615 - prc: 0.8845\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2128 - tp: 70591.0000 - fp: 17823.0000 - tn: 247004.0000 - fn: 17592.0000 - accuracy: 0.8997 - precision: 0.7984 - recall: 0.8005 - auc: 0.9615 - prc: 0.8847\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2125 - tp: 70960.0000 - fp: 18189.0000 - tn: 246638.0000 - fn: 17223.0000 - accuracy: 0.8997 - precision: 0.7960 - recall: 0.8047 - auc: 0.9616 - prc: 0.8850\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2124 - tp: 70715.0000 - fp: 17949.0000 - tn: 246878.0000 - fn: 17468.0000 - accuracy: 0.8997 - precision: 0.7976 - recall: 0.8019 - auc: 0.9616 - prc: 0.8849\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2119 - tp: 71083.0000 - fp: 18241.0000 - tn: 246586.0000 - fn: 17100.0000 - accuracy: 0.8999 - precision: 0.7958 - recall: 0.8061 - auc: 0.9618 - prc: 0.8853\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2120 - tp: 70882.0000 - fp: 17990.0000 - tn: 246837.0000 - fn: 17301.0000 - accuracy: 0.9000 - precision: 0.7976 - recall: 0.8038 - auc: 0.9618 - prc: 0.8851\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2115 - tp: 71092.0000 - fp: 18037.0000 - tn: 246790.0000 - fn: 17091.0000 - accuracy: 0.9005 - precision: 0.7976 - recall: 0.8062 - auc: 0.9620 - prc: 0.8855\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2113 - tp: 71033.0000 - fp: 18162.0000 - tn: 246665.0000 - fn: 17150.0000 - accuracy: 0.9000 - precision: 0.7964 - recall: 0.8055 - auc: 0.9620 - prc: 0.8862\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 37s 6ms/step - loss: 0.2194 - tp: 140569.0000 - fp: 36306.0000 - tn: 493348.0000 - fn: 35797.0000 - accuracy: 0.8979 - precision: 0.7947 - recall: 0.7970 - auc: 0.9605 - prc: 0.8822\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2191 - tp: 69512.0000 - fp: 18117.0000 - tn: 246710.0000 - fn: 18671.0000 - accuracy: 0.8958 - precision: 0.7933 - recall: 0.7883 - auc: 0.9590 - prc: 0.8785\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2187 - tp: 69715.0000 - fp: 18062.0000 - tn: 246765.0000 - fn: 18468.0000 - accuracy: 0.8965 - precision: 0.7942 - recall: 0.7906 - auc: 0.9592 - prc: 0.8787\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2184 - tp: 69733.0000 - fp: 18124.0000 - tn: 246703.0000 - fn: 18450.0000 - accuracy: 0.8964 - precision: 0.7937 - recall: 0.7908 - auc: 0.9593 - prc: 0.8790\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2181 - tp: 69752.0000 - fp: 18099.0000 - tn: 246728.0000 - fn: 18431.0000 - accuracy: 0.8965 - precision: 0.7940 - recall: 0.7910 - auc: 0.9594 - prc: 0.8794\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2179 - tp: 69589.0000 - fp: 17961.0000 - tn: 246866.0000 - fn: 18594.0000 - accuracy: 0.8964 - precision: 0.7948 - recall: 0.7891 - auc: 0.9594 - prc: 0.8797\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2175 - tp: 69834.0000 - fp: 17878.0000 - tn: 246949.0000 - fn: 18349.0000 - accuracy: 0.8974 - precision: 0.7962 - recall: 0.7919 - auc: 0.9596 - prc: 0.8801\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2174 - tp: 69881.0000 - fp: 18005.0000 - tn: 246822.0000 - fn: 18302.0000 - accuracy: 0.8972 - precision: 0.7951 - recall: 0.7925 - auc: 0.9597 - prc: 0.8803\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2171 - tp: 69697.0000 - fp: 17900.0000 - tn: 246927.0000 - fn: 18486.0000 - accuracy: 0.8969 - precision: 0.7957 - recall: 0.7904 - auc: 0.9598 - prc: 0.8807\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2165 - tp: 70016.0000 - fp: 18015.0000 - tn: 246812.0000 - fn: 18167.0000 - accuracy: 0.8975 - precision: 0.7954 - recall: 0.7940 - auc: 0.9601 - prc: 0.8810\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2165 - tp: 69965.0000 - fp: 17953.0000 - tn: 246874.0000 - fn: 18218.0000 - accuracy: 0.8975 - precision: 0.7958 - recall: 0.7934 - auc: 0.9600 - prc: 0.8810\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2160 - tp: 70034.0000 - fp: 18016.0000 - tn: 246811.0000 - fn: 18149.0000 - accuracy: 0.8976 - precision: 0.7954 - recall: 0.7942 - auc: 0.9602 - prc: 0.8818\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2159 - tp: 70105.0000 - fp: 18007.0000 - tn: 246820.0000 - fn: 18078.0000 - accuracy: 0.8978 - precision: 0.7956 - recall: 0.7950 - auc: 0.9602 - prc: 0.8816\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2157 - tp: 70313.0000 - fp: 18320.0000 - tn: 246507.0000 - fn: 17870.0000 - accuracy: 0.8975 - precision: 0.7933 - recall: 0.7974 - auc: 0.9604 - prc: 0.8817\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2153 - tp: 70257.0000 - fp: 18042.0000 - tn: 246785.0000 - fn: 17926.0000 - accuracy: 0.8981 - precision: 0.7957 - recall: 0.7967 - auc: 0.9605 - prc: 0.8821\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2149 - tp: 70313.0000 - fp: 17985.0000 - tn: 246842.0000 - fn: 17870.0000 - accuracy: 0.8984 - precision: 0.7963 - recall: 0.7974 - auc: 0.9606 - prc: 0.8826\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2147 - tp: 70540.0000 - fp: 18182.0000 - tn: 246645.0000 - fn: 17643.0000 - accuracy: 0.8985 - precision: 0.7951 - recall: 0.7999 - auc: 0.9607 - prc: 0.8827\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2144 - tp: 70493.0000 - fp: 18066.0000 - tn: 246761.0000 - fn: 17690.0000 - accuracy: 0.8987 - precision: 0.7960 - recall: 0.7994 - auc: 0.9608 - prc: 0.8831\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2145 - tp: 70471.0000 - fp: 18106.0000 - tn: 246721.0000 - fn: 17712.0000 - accuracy: 0.8985 - precision: 0.7956 - recall: 0.7991 - auc: 0.9608 - prc: 0.8828\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2138 - tp: 70689.0000 - fp: 18154.0000 - tn: 246673.0000 - fn: 17494.0000 - accuracy: 0.8990 - precision: 0.7957 - recall: 0.8016 - auc: 0.9610 - prc: 0.8836\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 37s 7ms/step - loss: 0.2142 - tp: 70512.0000 - fp: 18074.0000 - tn: 246753.0000 - fn: 17671.0000 - accuracy: 0.8987 - precision: 0.7960 - recall: 0.7996 - auc: 0.9609 - prc: 0.8833\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2137 - tp: 70713.0000 - fp: 18176.0000 - tn: 246651.0000 - fn: 17470.0000 - accuracy: 0.8990 - precision: 0.7955 - recall: 0.8019 - auc: 0.9611 - prc: 0.8836\n",
            "Epoch 23/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2132 - tp: 70766.0000 - fp: 18150.0000 - tn: 246677.0000 - fn: 17417.0000 - accuracy: 0.8992 - precision: 0.7959 - recall: 0.8025 - auc: 0.9613 - prc: 0.8840\n",
            "Epoch 24/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2126 - tp: 70702.0000 - fp: 18050.0000 - tn: 246777.0000 - fn: 17481.0000 - accuracy: 0.8993 - precision: 0.7966 - recall: 0.8018 - auc: 0.9615 - prc: 0.8846\n",
            "Epoch 25/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2127 - tp: 70870.0000 - fp: 18187.0000 - tn: 246640.0000 - fn: 17313.0000 - accuracy: 0.8994 - precision: 0.7958 - recall: 0.8037 - auc: 0.9615 - prc: 0.8844\n",
            "Epoch 26/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2125 - tp: 70690.0000 - fp: 17869.0000 - tn: 246958.0000 - fn: 17493.0000 - accuracy: 0.8998 - precision: 0.7982 - recall: 0.8016 - auc: 0.9616 - prc: 0.8848\n",
            "Epoch 27/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2120 - tp: 70936.0000 - fp: 17996.0000 - tn: 246831.0000 - fn: 17247.0000 - accuracy: 0.9002 - precision: 0.7976 - recall: 0.8044 - auc: 0.9618 - prc: 0.8853\n",
            "Epoch 28/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2123 - tp: 70988.0000 - fp: 18156.0000 - tn: 246671.0000 - fn: 17195.0000 - accuracy: 0.8999 - precision: 0.7963 - recall: 0.8050 - auc: 0.9617 - prc: 0.8851\n",
            "Epoch 29/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2116 - tp: 71123.0000 - fp: 18156.0000 - tn: 246671.0000 - fn: 17060.0000 - accuracy: 0.9002 - precision: 0.7966 - recall: 0.8065 - auc: 0.9619 - prc: 0.8856\n",
            "Epoch 30/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2114 - tp: 70946.0000 - fp: 18038.0000 - tn: 246789.0000 - fn: 17237.0000 - accuracy: 0.9001 - precision: 0.7973 - recall: 0.8045 - auc: 0.9620 - prc: 0.8858\n",
            "690/690 [==============================] - 1s 1ms/step\n",
            "communication_round: 2 | global_accuracy: 79.740% | global_loss: 0.6289921402931213 | global_AUC: 88.448% | global_G-mean: 79.695%\n",
            "Epoch 1/30\n",
            "5516/5516 [==============================] - 36s 6ms/step - loss: 0.2114 - tp: 142058.0000 - fp: 36171.0000 - tn: 493483.0000 - fn: 34308.0000 - accuracy: 0.9002 - precision: 0.7971 - recall: 0.8055 - auc: 0.9620 - prc: 0.8859\n",
            "Epoch 2/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2113 - tp: 71141.0000 - fp: 18204.0000 - tn: 246623.0000 - fn: 17042.0000 - accuracy: 0.9002 - precision: 0.7963 - recall: 0.8067 - auc: 0.9620 - prc: 0.8857\n",
            "Epoch 3/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2111 - tp: 71142.0000 - fp: 18034.0000 - tn: 246793.0000 - fn: 17041.0000 - accuracy: 0.9006 - precision: 0.7978 - recall: 0.8068 - auc: 0.9621 - prc: 0.8863\n",
            "Epoch 4/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2109 - tp: 71018.0000 - fp: 18077.0000 - tn: 246750.0000 - fn: 17165.0000 - accuracy: 0.9002 - precision: 0.7971 - recall: 0.8053 - auc: 0.9622 - prc: 0.8866\n",
            "Epoch 5/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2109 - tp: 71005.0000 - fp: 18127.0000 - tn: 246700.0000 - fn: 17178.0000 - accuracy: 0.9000 - precision: 0.7966 - recall: 0.8052 - auc: 0.9622 - prc: 0.8865\n",
            "Epoch 6/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2105 - tp: 71122.0000 - fp: 17995.0000 - tn: 246832.0000 - fn: 17061.0000 - accuracy: 0.9007 - precision: 0.7981 - recall: 0.8065 - auc: 0.9623 - prc: 0.8865\n",
            "Epoch 7/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2098 - tp: 71236.0000 - fp: 17957.0000 - tn: 246870.0000 - fn: 16947.0000 - accuracy: 0.9011 - precision: 0.7987 - recall: 0.8078 - auc: 0.9626 - prc: 0.8876\n",
            "Epoch 8/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2102 - tp: 71329.0000 - fp: 18233.0000 - tn: 246594.0000 - fn: 16854.0000 - accuracy: 0.9006 - precision: 0.7964 - recall: 0.8089 - auc: 0.9624 - prc: 0.8870\n",
            "Epoch 9/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2098 - tp: 71374.0000 - fp: 18028.0000 - tn: 246799.0000 - fn: 16809.0000 - accuracy: 0.9013 - precision: 0.7983 - recall: 0.8094 - auc: 0.9626 - prc: 0.8873\n",
            "Epoch 10/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2091 - tp: 71376.0000 - fp: 17935.0000 - tn: 246892.0000 - fn: 16807.0000 - accuracy: 0.9016 - precision: 0.7992 - recall: 0.8094 - auc: 0.9629 - prc: 0.8882\n",
            "Epoch 11/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2090 - tp: 71394.0000 - fp: 17906.0000 - tn: 246921.0000 - fn: 16789.0000 - accuracy: 0.9017 - precision: 0.7995 - recall: 0.8096 - auc: 0.9629 - prc: 0.8884\n",
            "Epoch 12/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2089 - tp: 71495.0000 - fp: 18043.0000 - tn: 246784.0000 - fn: 16688.0000 - accuracy: 0.9016 - precision: 0.7985 - recall: 0.8108 - auc: 0.9629 - prc: 0.8881\n",
            "Epoch 13/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2082 - tp: 71610.0000 - fp: 18067.0000 - tn: 246760.0000 - fn: 16573.0000 - accuracy: 0.9019 - precision: 0.7985 - recall: 0.8121 - auc: 0.9632 - prc: 0.8890\n",
            "Epoch 14/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2081 - tp: 71601.0000 - fp: 18018.0000 - tn: 246809.0000 - fn: 16582.0000 - accuracy: 0.9020 - precision: 0.7989 - recall: 0.8120 - auc: 0.9632 - prc: 0.8887\n",
            "Epoch 15/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2079 - tp: 71601.0000 - fp: 18055.0000 - tn: 246772.0000 - fn: 16582.0000 - accuracy: 0.9019 - precision: 0.7986 - recall: 0.8120 - auc: 0.9633 - prc: 0.8894\n",
            "Epoch 16/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2079 - tp: 71397.0000 - fp: 17853.0000 - tn: 246974.0000 - fn: 16786.0000 - accuracy: 0.9019 - precision: 0.8000 - recall: 0.8096 - auc: 0.9633 - prc: 0.8891\n",
            "Epoch 17/30\n",
            "5516/5516 [==============================] - 35s 6ms/step - loss: 0.2076 - tp: 71668.0000 - fp: 17935.0000 - tn: 246892.0000 - fn: 16515.0000 - accuracy: 0.9024 - precision: 0.7998 - recall: 0.8127 - auc: 0.9634 - prc: 0.8895\n",
            "Epoch 18/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2070 - tp: 71702.0000 - fp: 17745.0000 - tn: 247082.0000 - fn: 16481.0000 - accuracy: 0.9030 - precision: 0.8016 - recall: 0.8131 - auc: 0.9636 - prc: 0.8899\n",
            "Epoch 19/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2070 - tp: 71655.0000 - fp: 17797.0000 - tn: 247030.0000 - fn: 16528.0000 - accuracy: 0.9028 - precision: 0.8010 - recall: 0.8126 - auc: 0.9636 - prc: 0.8900\n",
            "Epoch 20/30\n",
            "5516/5516 [==============================] - 33s 6ms/step - loss: 0.2071 - tp: 71585.0000 - fp: 17819.0000 - tn: 247008.0000 - fn: 16598.0000 - accuracy: 0.9025 - precision: 0.8007 - recall: 0.8118 - auc: 0.9636 - prc: 0.8899\n",
            "Epoch 21/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2067 - tp: 71691.0000 - fp: 17830.0000 - tn: 246997.0000 - fn: 16492.0000 - accuracy: 0.9028 - precision: 0.8008 - recall: 0.8130 - auc: 0.9637 - prc: 0.8901\n",
            "Epoch 22/30\n",
            "5516/5516 [==============================] - 34s 6ms/step - loss: 0.2065 - tp: 71795.0000 - fp: 17867.0000 - tn: 246960.0000 - fn: 16388.0000 - accuracy: 0.9030 - precision: 0.8007 - recall: 0.8142 - auc: 0.9638 - prc: 0.8906\n",
            "Epoch 23/30\n",
            "3607/5516 [==================>...........] - ETA: 11s - loss: 0.2058 - tp: 46916.0000 - fp: 11655.0000 - tn: 161610.0000 - fn: 10667.0000 - accuracy: 0.9033 - precision: 0.8010 - recall: 0.8148 - auc: 0.9640 - prc: 0.8907"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Single Dataset**"
      ],
      "metadata": {
        "id": "qMWuTO_OUxFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load and preprocess the data"
      ],
      "metadata": {
        "id": "7Yh7s4GLAeq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading the data in Google colab\n",
        "from google.colab import files\n",
        "\n",
        "uploaded_1 = files.upload()\n",
        "\n",
        "for fn in uploaded_1.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded_1[fn])))"
      ],
      "metadata": {
        "id": "fDa6S0CsVLqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data file as a dataframe\n",
        "import io\n",
        "weather_df = pd.read_csv(io.BytesIO(uploaded_1['Client1.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "weather_df.shape"
      ],
      "metadata": {
        "id": "SbETjAg-VNtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data = weather_df\n",
        "Data.RainToday = [1 if each==\"Yes\" else 0 for each in Data.RainToday]\n",
        "Data.RainTomorrow = [1 if each==\"Yes\" else 0 for each in Data.RainTomorrow]\n",
        "#Data.head()\n",
        "\n",
        "Data = Data.drop(['Sunshine','Evaporation','Cloud3pm','Cloud9am','RISK_MM','Location','Date','WindGustDir',\n",
        "       'WindDir9am', 'WindDir3pm'],axis=1)\n",
        "Data.shape\n",
        "\n",
        "# replace rest of the nulls with respective means\n",
        "fill_feat = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed','WindSpeed9am', 'WindSpeed3pm',\n",
        "             'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm','Temp9am', 'Temp3pm',\n",
        "             'RainToday', 'RainTomorrow']\n",
        "for i in fill_feat:\n",
        "    Data[i].fillna(np.mean(Data[i]),inplace=True)\n",
        "\n",
        "Data.shape\n",
        "Data.dropna(inplace=True)\n",
        "\n",
        "# Separate the features and labels\n",
        "X = Data.drop('RainTomorrow', axis=1)\n",
        "y = Data['RainTomorrow']\n",
        "\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "# Normalize the features\n",
        "scalar = preprocessing.MinMaxScaler(feature_range=(0, 12))\n",
        "norm_data = scalar.fit_transform(X)\n",
        "X = pd.DataFrame(norm_data, columns=[X.columns])\n",
        "X = pd.DataFrame(X.reset_index(drop=True))\n",
        "\n",
        "original_indices = set(Data.index)\n",
        "current_indices = set(X.index)\n",
        "\n",
        "missing_indices = original_indices - current_indices\n",
        "print(missing_indices)\n",
        "\n",
        "X_single = X\n",
        "y_single = y\n",
        "\n",
        "counter = Counter(y_single)\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "C-JfnO_lVQnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Data Augmentation"
      ],
      "metadata": {
        "id": "mH34SV9AA4bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "X = pd.DataFrame(X.reset_index(drop=True))"
      ],
      "metadata": {
        "id": "FVKBfpnNVQfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(X, y, epochs = 20, batch_size = 128, latent_dim = 13)\n",
        "\n",
        "# Save the generator\n",
        "generator_0 = define_generator(latent_dim)"
      ],
      "metadata": {
        "id": "o3dP5a6VWNJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "# Calculate the class ratio in the balanced dataset\n",
        "class_ratio = sum(y_train == 0) / len(y_train)\n",
        "class_ratio"
      ],
      "metadata": {
        "id": "KC0TR2UXXe_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the generator to create synthetic data\n",
        "synthetic_data = generator_0.predict(np.random.normal(0, 1, (len(X_train), latent_dim)))\n",
        "\n",
        "# Combine the real and synthetic data to create a balanced dataset\n",
        "X_balanced = np.concatenate([X_train, synthetic_data])\n",
        "y_balanced = np.concatenate([y_train, np.zeros(len(X_train))])\n",
        "\n",
        "print(\"X_train\", X_train.shape)\n",
        "print(\"X_balanced\", X_balanced.shape)\n",
        "\n",
        "print(\"X_balanced:\", X_balanced.shape)\n",
        "print(\"y_balanced:\", y_balanced.shape)"
      ],
      "metadata": {
        "id": "AJAlHOTRXiAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Centralized Training"
      ],
      "metadata": {
        "id": "uSNDB485BTO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define data shape and number of classes\n",
        "input_shape = (13,)\n",
        "num_classes = 2\n",
        "num_test_samples = len(X_test)\n",
        "num_train_samples = len(X_train)\n",
        "Batch_size = 64\n",
        "communication_round = 10\n",
        "Learning_rate = 0.001\n",
        "Momentum = 0.9\n",
        "Epochs = 30\n",
        "data_shape = (13,)"
      ],
      "metadata": {
        "id": "nkmXFldfU10j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = Epochs\n",
        "learning_rate = Learning_rate\n",
        "momentum = Momentum\n",
        "batch_size = Batch_size\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01,\n",
        "                                 momentum = momentum,\n",
        "                                 nesterov = False)\n",
        "loss = \"binary_crossentropy\"\n",
        "\n",
        "metrics = [keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "      ]\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "layers.Dense(128, activation='relu', input_shape=(13,)),\n",
        "layers.Dense(64, activation='relu'),\n",
        "layers.Dense(32, activation='relu'),\n",
        "layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=optimizer,\n",
        "              metrics=metrics)\n",
        "\n",
        "model.fit(X_balanced, y_balanced, epochs=Epochs, batch_size=Batch_size)"
      ],
      "metadata": {
        "id": "LAaf7TzfU8aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Evaluation = model.evaluate(X_test, y_test, verbose = 1)"
      ],
      "metadata": {
        "id": "nt84zyK8U_OB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}